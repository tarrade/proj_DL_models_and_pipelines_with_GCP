{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classification example with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages on Google  Cloud Datalab (locally use conda env)\n",
    "### Select in the Python3 Kernel:\n",
    "In the menu bar the of 'Kernel', select   \n",
    "**python3**\n",
    "### Install needed packages\n",
    "copy the command below in a Google Cloud Datalab cell  \n",
    "**!pip install tensorflow==1.12**\n",
    "### Restart the Kernel \n",
    "this is to take into account the new installed packages. Click in the menu bar on:  \n",
    "**Reset Session**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Needed librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import gzip\n",
    "import sys\n",
    "import _pickle as cPickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mnist data, split between train and test sets\n",
    "# on GCP\n",
    "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# with AXA network\n",
    "def load_data(path):\n",
    "    f = gzip.open(path, 'rb')\n",
    "    if sys.version_info < (3,):\n",
    "        data = cPickle.load(f)\n",
    "    else:\n",
    "        data = cPickle.load(f, encoding='bytes')\n",
    "    f.close()\n",
    "    return data\n",
    "(x_train, y_train), (x_test, y_test) = load_data(path='../data/mnist.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data shape (training)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data shape (train)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('uint8'), dtype('uint8'))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtype, x_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 0, 255, 0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(x_train), np.min(x_train), np.max(x_test), np.min(x_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.476806640625"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.nbytes/1024.0**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.86083984375"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.nbytes/1024.0**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0095367431640625"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.nbytes/1024.0**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.057220458984375"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.nbytes/1024.0**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stored the data as TFRecord\n",
    "https://medium.com/coinmonks/storage-efficient-tfrecord-for-images-6dc322b81db4\n",
    "https://www.damienpontifex.com/2017/09/18/convert-and-using-the-mnist-dataset-as-tfrecords/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value:int) -> tf.train.Features.FeatureEntry:\n",
    "    \"\"\"Create a Int64List Feature\n",
    "    \n",
    "    Args:\n",
    "        value: The value to store in the feature\n",
    "    \n",
    "    Returns:\n",
    "        The FeatureEntry\n",
    "    \"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _floatlist_feature(value:str) -> tf.train.Features.FeatureEntry:\n",
    "    \"\"\"Create a FloatList Feature\n",
    "    \n",
    "    Args:\n",
    "        value: The value to store in the feature\n",
    "    \n",
    "    Returns:\n",
    "        The FeatureEntry\n",
    "    \"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value:str) -> tf.train.Features.FeatureEntry:\n",
    "    \"\"\"Create a BytesList Feature\n",
    "    \n",
    "    Args:\n",
    "        value: The value to store in the feature\n",
    "    \n",
    "    Returns:\n",
    "        The FeatureEntry\n",
    "    \"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _data_path(data_directory:str, name:str) -> str:\n",
    "    \"\"\"Construct a full path to a TFRecord file to be stored in the \n",
    "    data_directory. Will also ensure the data directory exists\n",
    "    \n",
    "    Args:\n",
    "        data_directory: The directory where the records will be stored\n",
    "        name:           The name of the TFRecord\n",
    "    \n",
    "    Returns:\n",
    "        The full path to the TFRecord file\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(data_directory):\n",
    "        os.makedirs(data_directory)\n",
    "\n",
    "    return os.path.join(data_directory, f'{name}.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_examples(example_dataset, filename:str):\n",
    "    print(f'Processing {filename} data')\n",
    "    dataset_length = len(example_dataset)\n",
    "    with tf.python_io.TFRecordWriter(filename) as writer:\n",
    "        for index, (image, label) in enumerate(example_dataset):\n",
    "            sys.stdout.write(f\"\\rProcessing sample {index+1} of {dataset_length}\")\n",
    "            sys.stdout.flush()\n",
    "            image_raw = image.tostring()\n",
    "            #print('step 2:',image_raw)\n",
    "            #print('step 1:',image.shape)\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'label': _int64_feature(int(label)),\n",
    "                'image_raw': _bytes_feature(image_raw)# _floatlist_feature(image.reshape(-1)) #\n",
    "            }))\n",
    "            #example = tf.train.Example()\n",
    "            #example.features.feature['label'].int64_list.value.append(int(label))\n",
    "            #img_64 = np.asarray(dict_to_img(drawing, img_sz=64, lw=4, maximize=True)).reshape(-1)\n",
    "            #example.features.feature['image_raw'].int64_list.value.extend(image.reshape(-1))\n",
    "            \n",
    "            writer.write(example.SerializeToString())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to(x_data, y_data, name:str, data_directory:str, num_shards:int=1):\n",
    "    \"\"\"Convert the dataset into TFRecords on disk\n",
    "    \n",
    "    Args:\n",
    "        x_data:         The MNIST data set to convert: data\n",
    "        y_data:         The MNIST data set to convert: label\n",
    "        name:           The name of the data set\n",
    "        data_directory: The directory where records will be stored\n",
    "        num_shards:     The number of files on disk to separate records into\n",
    "    \"\"\"\n",
    "\n",
    "    data_set = list(zip(x_data, y_data))\n",
    "    \n",
    "    if num_shards == 1:\n",
    "        _process_examples(data_set, _data_path(data_directory, name))\n",
    "    else:\n",
    "        sharded_dataset = np.array_split(data_set, num_shards)\n",
    "        for shard, dataset in enumerate(sharded_dataset):\n",
    "            _process_examples(dataset, _data_path(data_directory, f'{name}-{shard+1}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/tarrade/Desktop/Work/Data_Science/Tutorials_Codes/Python/proj_DL_models_and_pipelines_with_GCP/data/test.tfrecords data\n",
      "Processing sample 10000 of 10000\n"
     ]
    }
   ],
   "source": [
    "convert_to(x_test, y_test, 'test', os.path.abspath('../data/'), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/tarrade/Desktop/Work/Data_Science/Tutorials_Codes/Python/proj_DL_models_and_pipelines_with_GCP/data/train.tfrecords data\n",
      "Processing sample 60000 of 60000\n"
     ]
    }
   ],
   "source": [
    "convert_to(x_train, y_train, 'train', os.path.abspath('../data/'), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CLOUDSDK_PYTHON']='/Users/tarrade/anaconda3/bin/python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Cloud SDK 232.0.0\n",
      "bq 2.0.40\n",
      "core 2019.01.27\n",
      "gsutil 4.35\n"
     ]
    }
   ],
   "source": [
    "!gcloud version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Cloud SDK [232.0.0]\r\n",
      "\r\n",
      "Platform: [Mac OS X, x86_64] uname_result(system='Darwin', node='Fabien-Tarrades-MacBook-Pro.local', release='18.2.0', version='Darwin Kernel Version 18.2.0: Thu Dec 20 20:46:53 PST 2018; root:xnu-4903.241.1~1/RELEASE_X86_64', machine='x86_64', processor='i386')\r\n",
      "Python Version: [3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38)  [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]]\r\n",
      "Python Location: [/Users/tarrade/anaconda3/bin/python]\r\n",
      "Site Packages: [Disabled]\r\n",
      "\r\n",
      "Installation Root: [/Users/tarrade/Test/google-cloud-sdk]\r\n",
      "Installed Components:\r\n",
      "  gsutil: [4.35]\r\n",
      "  core: [2019.01.27]\r\n",
      "  bq: [2.0.40]\r\n",
      "System PATH: [/Users/tarrade/anaconda3/envs/env_gcp_dl/bin:/Users/tarrade/Test/google-cloud-sdk/bin:/Users/tarrade/anaconda3/bin:/Users/tarrade/anaconda3/condabin:/Users/tarrade/anaconda/bin:/Users/tarrade/anaconda/bin:/Users/tarrade/anaconda/bin:/Users/tarrade/anaconda/bin:/Users/tarrade/anaconda/bin:/Users/tarrade/miniconda2/bin:/opt/local/bin:/opt/local/sbin:/opt/local/bin:/opt/local/sbin:/usr/local/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/texbin:/opt/X11/bin]\r\n",
      "Python PATH: [/Users/tarrade/Test/google-cloud-sdk/lib/third_party:/Users/tarrade/Test/google-cloud-sdk/lib:/Users/tarrade/anaconda3/lib/python36.zip:/Users/tarrade/anaconda3/lib/python3.6:/Users/tarrade/anaconda3/lib/python3.6:/Users/tarrade/anaconda3/lib/python3.6/lib-dynload]\r\n",
      "Cloud SDK on PATH: [True]\r\n",
      "Kubectl on PATH: [/usr/local/bin/kubectl]\r\n",
      "\r\n",
      "Installation Properties: [/Users/tarrade/Test/google-cloud-sdk/properties]\r\n",
      "User Config Directory: [/Users/tarrade/.config/gcloud]\r\n",
      "Active Configuration Name: [default]\r\n",
      "Active Configuration Path: [/Users/tarrade/.config/gcloud/configurations/config_default]\r\n",
      "\r\n",
      "Account: [fabien.tarrade@gmail.com]\r\n",
      "Project: [ml-productive-pipeline-53122]\r\n",
      "\r\n",
      "Current Properties:\r\n",
      "  [compute]\r\n",
      "    zone: [europe-west1-c]\r\n",
      "    region: [europe-west1]\r\n",
      "  [core]\r\n",
      "    account: [fabien.tarrade@gmail.com]\r\n",
      "    disable_usage_reporting: [False]\r\n",
      "    project: [ml-productive-pipeline-53122]\r\n",
      "\r\n",
      "Logs Directory: [/Users/tarrade/.config/gcloud/logs]\r\n",
      "Last Log File: [/Users/tarrade/.config/gcloud/logs/2019.02.04/21.10.41.487407.log]\r\n",
      "\r\n",
      "git: [b'git version 2.7.0']\r\n",
      "ssh: [b'OpenSSH_7.9p1, LibreSSL 2.7.3']\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!gcloud info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CLOUDSDK_PYTHON']='/Users/tarrade/anaconda/bin/python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://../data/test.tfrecords [Content-Type=application/octet-stream]...\n",
      "Copying file://../data/train.tfrecords [Content-Type=application/octet-stream]...\n",
      "\\ [2 files][ 56.2 MiB/ 56.2 MiB]    4.9 MiB/s                                   \n",
      "Operation completed over 2 objects/56.2 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp ../data/*tfrecords gs://ml-productive-pipeline-53122"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize and reorganize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast uint8 -> float32\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renormalize the data 255 grey variation\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the data 28 x 28 -> 784\n",
    "x_train = x_train.reshape(len(x_train), x_train.shape[1]*x_train.shape[2])\n",
    "x_test = x_test.reshape(len(x_test), x_test.shape[1]*x_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train), np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_input=x_train.shape[1]\n",
    "dim_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "for index, (image, label) in enumerate(zip(x_train[0:5], y_train[0:5])):\n",
    "    plt.subplot(1, 5, index + 1)\n",
    "    plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)\n",
    "    plt.title('Training: %i\\n' % np.argmax(label), fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined some hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "learning_rate = 0.5\n",
    "\n",
    "# number of epoch to train our model\n",
    "EPOCHS = 10\n",
    "\n",
    "# size of our mini batch\n",
    "#BATCH_SIZE = len(x_train)\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# shuffle buffer size\n",
    "SHUFFLE_BUFFER_SIZE = 10 * BATCH_SIZE\n",
    "\n",
    "# prefetch buffer size\n",
    "PREFETCH_BUFFER_SIZE = 1 #tf.contrib.data.AUTOTUNE\n",
    "\n",
    "# number of paralell calls\n",
    "NUM_PARALELL_CALL = 4\n",
    "\n",
    "# hidden layer 1\n",
    "n1=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 10)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE, EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()    \n",
    "    keys_list = [keys for keys in flags_dict]    \n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "    \n",
    "del_all_flags(tf.flags.FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_string('f', '', 'kernel') # just for jupyter notebook and avoir : \"UnrecognizedFlagError: Unknown command line flag 'f'\"\n",
    "tf.app.flags.DEFINE_string('model_dir', '../results/Models/Mnist/ckpt/', 'Dir to save a model and checkpoints')\n",
    "tf.app.flags.DEFINE_string('saved_dir', '../results/Models/Mnist/pb/', 'Dir to save a model for TF serving')\n",
    "tf.app.flags.DEFINE_integer('shuffle_buffer_size', SHUFFLE_BUFFER_SIZE , 'Shuffle buffer size')\n",
    "tf.app.flags.DEFINE_integer('prefetch_buffer_size', PREFETCH_BUFFER_SIZE, 'Prefetch buffer size')\n",
    "tf.app.flags.DEFINE_integer('batch_size', BATCH_SIZE, 'Batch size')\n",
    "tf.app.flags.DEFINE_integer('num_parallel_calls', NUM_PARALELL_CALL, 'Number of paralell calls')\n",
    "FLAGS = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/tarrade/anaconda3/envs/env_gcp_dl/lib/python3.6/site-packages/ipykernel_launcher.py:\n",
      "  --batch_size: Batch size\n",
      "    (default: '128')\n",
      "    (an integer)\n",
      "  --f: kernel\n",
      "    (default: '')\n",
      "  --model_dir: Dir to save a model and checkpoints\n",
      "    (default: '../results/Models/Mnist/ckpt/')\n",
      "  --num_parallel_calls: Number of paralell calls\n",
      "    (default: '4')\n",
      "    (an integer)\n",
      "  --prefetch_buffer_size: Prefetch buffer size\n",
      "    (default: '1')\n",
      "    (an integer)\n",
      "  --saved_dir: Dir to save a model for TF serving\n",
      "    (default: '../results/Models/Mnist/pb/')\n",
      "  --shuffle_buffer_size: Shuffle buffer size\n",
      "    (default: '1280')\n",
      "    (an integer)\n",
      "\n",
      "absl.flags:\n",
      "  --flagfile: Insert flag definitions from the given file into the command line.\n",
      "    (default: '')\n",
      "  --undefok: comma-separated list of flag names that it is okay to specify on\n",
      "    the command line even if the program does not define a flag with that name.\n",
      "    IMPORTANT: flags in this list that have arguments MUST use the --flag=value\n",
      "    format.\n",
      "    (default: '')\n"
     ]
    }
   ],
   "source": [
    "print(FLAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tf.data.Dataset\n",
    "https://www.tensorflow.org/guide/performance/datasets  \n",
    "To summarize, one good order for the different transformations is:\n",
    "- create the dataset\n",
    "- shuffle (with a big enough buffer size https://stackoverflow.com/questions/46444018/meaning-of-buffer-size-in-dataset-map-dataset-prefetch-and-dataset-shuffle)\n",
    "- repeat\n",
    "- map with the actual work (preprocessing, augmentationâ€¦) using multiple parallel calls\n",
    "- batch\n",
    "- prefetch\n",
    "\n",
    "ModeKeys:  \n",
    "https://www.tensorflow.org/api_docs/python/tf/estimator/ModeKeys  \n",
    "- EVAL\n",
    "- PREDICT\n",
    "- TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_dataset_tfrecords_fn(filenames, batch_size=128, mode=tf.estimator.ModeKeys.TRAIN):\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        tf.logging.info(\"input_dataset_fn: PREDICT, {}\".format(mode))\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        tf.logging.info(\"input_dataset_fn: EVAL, {}\".format(mode))\n",
    "    elif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        tf.logging.info(\"input_dataset_fn: TRAIN, {}\".format(mode))\n",
    "    \n",
    "    def _parser(record):\n",
    "        # 1. define a parser\n",
    "        features={\n",
    "            #'label': tf.FixedLenFeature([], tf.int64),\n",
    "            #'image_raw': tf.FixedLenFeature([], tf.train.FloatList)#tf.string)\n",
    "            'label': tf.FixedLenFeature(shape=[], dtype=tf.int64),\n",
    "            # The bytes_list data is parsed into tf.string.\n",
    "            'image_raw': tf.FixedLenFeature(shape=[], dtype=tf.string)\n",
    "        }\n",
    "        print('step 1')\n",
    "        parsed_record = tf.parse_single_example(record, features)\n",
    "        print('step 2')\n",
    "        print(parsed_record)\n",
    "        # 2. Convert the data\n",
    "        label = parsed_record['label']\n",
    "        #image = parsed_record['image_raw']#\n",
    "        image =  tf.cast(tf.decode_raw(parsed_record['image_raw'], out_type=tf.uint8), tf.float64)\n",
    "        print('TEST',label.shape)\n",
    "        print('TEST',image.shape)\n",
    "        # 3. reshape\n",
    "        #tf.reshape(image, [1,784])\n",
    "        #print('---',image.shape())\n",
    "        \n",
    "        # 4. hot emcoding\n",
    "        num_classes=10\n",
    "        #label = tf.keras.utils.to_categorical( label, num_classes)\n",
    "        label=tf.one_hot(label, num_classes)\n",
    "\n",
    "        return image, label\n",
    "        #dataset = tf.data.Dataset.from_tensor_slices((image, label))\n",
    "        #return dataset\n",
    "    \n",
    "    def _normalize(image, label):\n",
    "        \"\"\"Convert image from [0, 255] -> [-0.5, 0.5] floats.\"\"\"\n",
    "        image = image * (1. / 255) - 0.5\n",
    "        return image, label\n",
    "    \n",
    "    def _dense_to_one_hot(labels_dense, num_classes):\n",
    "        \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n",
    "        num_labels = labels_dense.shape[0]\n",
    "        index_offset = numpy.arange(num_labels) * num_classes\n",
    "        labels_one_hot = numpy.zeros((num_labels, num_classes))\n",
    "        labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "        return labels_one_hot\n",
    "    \n",
    "    def _input_fn():\n",
    "        # 1) read data from TFRecordDataset\n",
    "        dataset = (tf.data.TFRecordDataset(filenames).map(_parser))\n",
    "        \n",
    "        # 2) shuffle (with a big enough buffer size)    :        \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            num_epochs = None # loop indefinitely\n",
    "            dataset = dataset.shuffle(buffer_size=FLAGS.shuffle_buffer_size, seed=2)# depends on sample size\n",
    "        else:\n",
    "            num_epochs = 1 # end-of-input after this\n",
    "        print('the number of epoch: num_epoch =', num_epochs)\n",
    "        \n",
    "        # caching data\n",
    "        #dataset = dataset.cache()\n",
    "    \n",
    "        # 3) automatically refill the data queue when empty\n",
    "        dataset = dataset.repeat(num_epochs)\n",
    "\n",
    "        # 4) map\n",
    "        dataset = dataset.map(map_func=_normalize, num_parallel_calls=FLAGS.num_parallel_calls)\n",
    "\n",
    "        # 5) create batches of data\n",
    "        dataset = dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
    "\n",
    "        # 6) prefetch data for faster consumption, based on your system and environment, allows the tf.data runtime to automatically tune the prefetch buffer sizes\n",
    "        dataset = dataset.prefetch(FLAGS.prefetch_buffer_size)\n",
    "\n",
    "        return dataset\n",
    "    return _input_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_dataset_fn: TRAIN, train\n",
      "step 1\n",
      "step 2\n",
      "{'image_raw': <tf.Tensor 'ParseSingleExample/ParseSingleExample:0' shape=() dtype=string>, 'label': <tf.Tensor 'ParseSingleExample/ParseSingleExample:1' shape=() dtype=int64>}\n",
      "TEST ()\n",
      "TEST (?,)\n",
      "the number of epoch: num_epoch = None\n",
      "INFO:tensorflow:input_dataset_fn: EVAL, eval\n",
      "step 1\n",
      "step 2\n",
      "{'image_raw': <tf.Tensor 'ParseSingleExample/ParseSingleExample:0' shape=() dtype=string>, 'label': <tf.Tensor 'ParseSingleExample/ParseSingleExample:1' shape=() dtype=int64>}\n",
      "TEST ()\n",
      "TEST (?,)\n",
      "the number of epoch: num_epoch = 1\n"
     ]
    }
   ],
   "source": [
    "training_dataset = input_dataset_tfrecords_fn(os.path.abspath('../data/train.tfrecords'),  \n",
    "                                    mode=tf.estimator.ModeKeys.TRAIN, \n",
    "                                    batch_size=FLAGS.batch_size)\n",
    "testing_dataset = input_dataset_tfrecords_fn(os.path.abspath('../data/test.tfrecords'), \n",
    "                                   mode=tf.estimator.ModeKeys.EVAL, \n",
    "                                   batch_size=len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration dataset API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = training_dataset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_element\n",
    "features, labels = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration n: 0 execution time: 0.5324680000001081 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 1 execution time: 0.055957000000034895 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 2 execution time: 0.05217799999991257 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 6 \n",
      "\n",
      "iteration n: 3 execution time: 0.04504799999995157 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 4 execution time: 0.04535500000019965 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 5 \n",
      "\n",
      "iteration n: 5 execution time: 0.04520900000011352 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 1 \n",
      "\n",
      "iteration n: 6 execution time: 0.04962000000000444 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 9 \n",
      "\n",
      "iteration n: 7 execution time: 0.050853999999844746 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 8 \n",
      "\n",
      "iteration n: 8 execution time: 0.04601600000000872 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 2 \n",
      "\n",
      "iteration n: 9 execution time: 0.046758999999838124 seconds\n",
      "(128, 784)\n",
      "(128, 10)\n",
      "first label of the batch 3 \n",
      "\n",
      "number of iteration reached\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "n_iter=10 #len(x_train)//BATCH_SIZE\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            start_time = time.clock()\n",
    "            x,y = sess.run([features, labels])\n",
    "            print('iteration n:', n, 'execution time:', time.clock() - start_time, 'seconds')\n",
    "            print(x.shape)\n",
    "            print(y.shape)\n",
    "            print('first label of the batch',np.argmax(y[0]),'\\n')\n",
    "            n+=1\n",
    "            if n>=n_iter:\n",
    "                print('number of iteration reached')\n",
    "                break\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('tf.errors.OutOfRangeError')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = testing_dataset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_element\n",
    "features, labels = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6481220000000576 seconds\n",
      "(10000, 784)\n",
      "(10000, 10)\n",
      "first label of the batch 7 \n",
      "\n",
      "tf.errors.OutOfRangeError\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            start_time = time.clock()\n",
    "            x,y = sess.run([features, labels])\n",
    "            print(time.clock() - start_time, 'seconds')\n",
    "            print(x.shape)\n",
    "            print(y.shape)\n",
    "            print('first label of the batch',np.argmax(y[0]),'\\n')\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('tf.errors.OutOfRangeError')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our model\n",
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = tf.keras.Sequential()\n",
    " \n",
    "    # hidden layer\n",
    "    model.add(tf.keras.layers.Dense(dim_input, \n",
    "                    input_dim=dim_input, \n",
    "                    kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "                    bias_initializer=tf.keras.initializers.Zeros(),\n",
    "                    activation='relu'))\n",
    "    # last layer\n",
    "    model.add(tf.keras.layers.Dense(num_classes, \n",
    "                    kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "                    bias_initializer=tf.keras.initializers.Zeros(),\n",
    "                    activation='softmax'))\n",
    "    \n",
    "    # weight initialisation\n",
    "    # He: keras.initializers.he_normal(seed=None)\n",
    "    # Xavier: keras.initializers.glorot_uniform(seed=None)\n",
    "    # Radom Normal: keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "    # Truncated Normal: keras.initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "    \n",
    "    # optimiser (use tf.train and not tf.keras to use MirrorStrategy)\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/train/Optimizer\n",
    "    optimiser=tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9)\n",
    "    # GD/SGC:   tf.train.GradientDescentOptimizer(learning_rate, use_locking=False, name='GradientDescent') \n",
    "    # Adam:     tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, use_locking=False,name='Adam')\n",
    "    # RMSProp:  tf.train.RMSPropOptimizer(learning_rate, decay=0.9, momentum=0.0, epsilon=1e-10, use_locking=False, centered=False, name='RMSProp')\n",
    "    # Momentum: tf.train.MomentumOptimizer(learning_rate, momentum, use_locking=False, name='Momentum', use_nesterov=False)\n",
    "\n",
    "   \n",
    "    #optimiser=tf.keras.optimizers.Adam(lr=0.01, beta_1=0.9)\n",
    "    # GD/SGC:   keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "    # Adam:     keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    # RMSProp:  keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "    # Momentum: keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.0, nesterov=False)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=optimiser, \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = baseline_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the nuber of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 623,290\n",
      "Trainable params: 623,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check input and output layer names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dense_input']"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_names # Use this name as the dictionary key in the TF input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dense_1']"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Call back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print info during iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UDFPrint(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        _, __, x_train, y_train = self.test_data\n",
    "        loss_train, acc_train = self.model.evaluate(x_train, y_train, verbose=0)\n",
    "        print('Reached epoch {0:3d} cost J = {1:.5f}'.format(epoch, loss_train))\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x_test, y_test, x_train, y_train = self.test_data\n",
    "        loss_train, acc_train = self.model.evaluate(x_train, y_train, verbose=0)\n",
    "        loss_test, acc_test = self.model.evaluate(x_test, y_test, verbose=0)\n",
    "        print(' accurary on the training set {0:.4f}'.format(acc_train))\n",
    "        print(' accurary on the testing set {0:.4f}'.format(acc_test))\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        #print('  ---> starting minibatch', batch)\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        #print('  ---> ending minibatch', batch)\n",
    "        return\n",
    "return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')\n",
    "tbCallBack=tf.keras.callbacks.TensorBoard(log_dir='../results/TensorBoard/Mnist/logs/', \n",
    "                                          histogram_freq=1, \n",
    "                                          write_graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the original weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model using Keras and numpy array  \n",
    "- batch_size \n",
    "  determines the number of samples in each mini batch. Its maximum is the number of all samples, which makes gradient descent accurate, the loss will decrease towards the minimum if the learning rate is small enough, but iterations are slower. Its minimum is 1, resulting in stochastic gradient descent: Fast but the direction of the gradient step is based only on one example, the loss may jump around. batch_size allows to adjust between the two extremes: accurate gradient direction and fast iteration. Also, the maximum value for batch_size may be limited if your model + data set does not fit into the available (GPU) memory.\n",
    "- steps_per_epoch \n",
    "  the number of batch iterations before a training epoch is considered finished. If you have a training set of fixed size you can ignore it but it may be useful if you have a huge data set or if you are generating random data augmentations on the fly, i.e. if your training set has a (generated) infinite size. If you have the time to go through your whole training data set I recommend to skip this parameter.\n",
    "- validation_steps \n",
    "  similar to steps_per_epoch but on the validation data set instead on the training data. If you have the time to go through your whole validation data set I recommend to skip this parameter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Reached epoch   0 cost J = 2.41300\n",
      "Epoch 1/1\n",
      " accurary on the training set 0.9707\n",
      " accurary on the testing set 0.9669\n",
      " - 105s - loss: 0.2304 - acc: 0.9324 - val_loss: 0.1139 - val_acc: 0.9669\n"
     ]
    }
   ],
   "source": [
    "# Set to the original weights for testing other pipelines\n",
    "model.set_weights(initial_weights)\n",
    "\n",
    "# Fit the model\n",
    "hist=model.fit(x_train, \n",
    "               y_train, \n",
    "               validation_data=(x_test, y_test),\n",
    "               callbacks=[UDFPrint((x_test, y_test, x_train, y_train)), tbCallBack],\n",
    "               epochs=EPOCHS, \n",
    "               batch_size=BATCH_SIZE,\n",
    "               verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [0.12068325746208429], 'val_acc': [0.9637], 'loss': [0.2476220144510269], 'acc': [0.9291166666666667]}\n"
     ]
    }
   ],
   "source": [
    "print(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.12068325955718756\n",
      "Test accuracy: 0.9637\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, \n",
    "                       y_test, \n",
    "                       verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.11078246729324262\n",
      "Train accuracy: 0.9693666666666667\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, \n",
    "                       y_train, \n",
    "                       verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "# with keras optimiser we save save the model+weight\n",
    "model.save('../results/Models/Mnist/keras_model.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start in a separte shell with the env activated:\n",
    "tensorboard --logdir your_path/proj_DL_models_and_pipelines_with_GCP/results/TensorBoard/Mnist/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model using Keras annd tf.data.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_input to have 2 dimensions, but got array with shape (60000, 28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-507-e9b0dba40b6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUDFPrint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtbCallBack\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                verbose = 2)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/env_gcp_dl/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/env_gcp_dl/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    144\u001b[0m       \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# Update callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_gcp_dl/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_begin\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_t_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_begin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mcell_name\u001b[0m in \u001b[0;36mon_epoch_begin\u001b[0;34m(self, epoch, logs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_gcp_dl/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_gcp_dl/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     x, y, sample_weights = self._standardize_weights(x, y, sample_weight,\n\u001b[0;32m--> 992\u001b[0;31m                                                      class_weight, batch_size)\n\u001b[0m\u001b[1;32m    993\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_gcp_dl/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         exception_prefix='input')\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_gcp_dl/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    321\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_input to have 2 dimensions, but got array with shape (60000, 28, 28)"
     ]
    }
   ],
   "source": [
    "# Set to the original weights for testing other pipelines\n",
    "model.set_weights(initial_weights)\n",
    "\n",
    "# Fit the model (using data.Dataset)\n",
    "hist=model.fit(training_dataset.make_one_shot_iterator(),\n",
    "               steps_per_epoch=len(x_train) // BATCH_SIZE,\n",
    "               validation_data=testing_dataset.make_one_shot_iterator(),\n",
    "               validation_steps=1, #len(x_test) // BATCH_SIZE,\n",
    "               callbacks=[UDFPrint((x_test, y_test, x_train, y_train)), tbCallBack],\n",
    "               epochs=EPOCHS,\n",
    "               verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [0.11622638255357742], 'val_acc': [0.9649999737739563], 'loss': [0.23683089638749757], 'acc': [0.9307558760683761]}\n"
     ]
    }
   ],
   "source": [
    "print(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1162263597369194\n",
      "Test accuracy: 0.965\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, \n",
    "                       y_test, \n",
    "                       verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.10743331585675478\n",
      "Train accuracy: 0.969\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, \n",
    "                       y_train, \n",
    "                       verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start in a separte shell with the env activated:\n",
    "tensorboard --logdir your_path/proj_DL_models_and_pipelines_with_GCP/results/TensorBoard/Mnist/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model using tf.estimator and tf.data.dataset\n",
    "### Create some helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(tf.train.SessionRunHook):\n",
    "    def begin(self):\n",
    "        self.times = []\n",
    "\n",
    "    def before_run(self, run_context):\n",
    "        self.iter_time_start = time.time()\n",
    "\n",
    "    def after_run(self, run_context, run_values):\n",
    "        self.times.append(time.time() - self.iter_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_hist = TimeHistory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use tf.distribute.startegy work across multiple devices/machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    }
   ],
   "source": [
    "# the tf.distribute.Strategy API is an easy way to distribute your training across multiple devices/machines\n",
    "NUM_GPUS = 2\n",
    "#strategy=None\n",
    "## doesn't work with Keras ?!?\n",
    "strategy = tf.contrib.distribute.OneDeviceStrategy('device:CPU:0')\n",
    "#strategy = tf.contrib.distribute.OneDeviceStrategy('device:GPU:0')\n",
    "#strategy = tf.contrib.distribute.MirroredStrategy(num_gpus=NUM_GPUS)\n",
    "#strategy = tf.contrib.distribute.MirroredStrategy()\n",
    "\n",
    "# config tf.estimator to use a give strategy\n",
    "training_config = tf.estimator.RunConfig(train_distribute=strategy,\n",
    "                                         model_dir=FLAGS.model_dir,\n",
    "                                         save_summary_steps=20,\n",
    "                                         save_checkpoints_steps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transfor keras model to estimator model\n",
    "delete fist the folder for a clean start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: ../results/Models/Mnist/ckpt: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! rm -r ../results/Models/Mnist/ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmdir: /S: No such file or directory\r\n",
      "rmdir: /Q: No such file or directory\r\n",
      "rmdir: ../results/Models/Mnist/ckpt: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rmdir /S /Q \"../results/Models/Mnist/ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../results/Models/Mnist/ckpt/', '_tf_random_seed': None, '_save_summary_steps': 20, '_save_checkpoints_steps': 20, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.one_device_strategy.OneDeviceStrategy object at 0xb38b90b70>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0xb38b90780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n"
     ]
    }
   ],
   "source": [
    "# Set to the original weights for testing other pipelines\n",
    "model.set_weights(initial_weights)\n",
    "\n",
    "# transfor keras model to estimator model\n",
    "estimator_train_model = tf.keras.estimator.model_to_estimator(keras_model=model,\n",
    "                                                              config=training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mkeras\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../results/Models/Mnist/ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir /B \"../results/Models/Mnist/ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train(\n",
    "    input_fn,\n",
    "    hooks=None,\n",
    "    steps=None,\n",
    "    max_steps=None,\n",
    "    saving_listeners=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_input_fn():\n",
    "    return input_dataset_fn(x_train,\n",
    "                            y_train, \n",
    "                            mode=tf.estimator.ModeKeys.TRAIN, \n",
    "                            batch_size=FLAGS.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_dataset_fn: TRAIN, train\n",
      "the number of epoch: num_epoch = None\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='../results/Models/Mnist/ckpt/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('../results/Models/Mnist/ckpt/keras/keras_model.ckpt',)\n",
      "INFO:tensorflow:Warm-starting variable: dense_2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_3/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_3/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3501048, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 20 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 40 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 60 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 80 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 100 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 6.19726\n",
      "INFO:tensorflow:loss = 0.30727625, step = 100 (16.139 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 120 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 140 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 160 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 180 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 200 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 6.47259\n",
      "INFO:tensorflow:loss = 0.20859018, step = 200 (15.448 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 220 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 240 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 260 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 280 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 300 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 6.54135\n",
      "INFO:tensorflow:loss = 0.15372175, step = 300 (15.287 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 320 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 340 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 360 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 380 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 400 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 6.42306\n",
      "INFO:tensorflow:loss = 0.12151894, step = 400 (15.569 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 420 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 440 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 460 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 480 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 500 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 6.48667\n",
      "INFO:tensorflow:loss = 0.0666231, step = 500 (15.417 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 520 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 540 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 560 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 580 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 600 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 6.46395\n",
      "INFO:tensorflow:loss = 0.07367722, step = 600 (15.471 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 620 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 640 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 660 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 680 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 700 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 5.61588\n",
      "INFO:tensorflow:loss = 0.056666635, step = 700 (17.806 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 720 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 740 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 760 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 780 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 800 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 5.53223\n",
      "INFO:tensorflow:loss = 0.03747573, step = 800 (18.078 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 820 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 840 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 860 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 880 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 900 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 5.25429\n",
      "INFO:tensorflow:loss = 0.13040794, step = 900 (19.030 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 920 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 940 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 960 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 980 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ../results/Models/Mnist/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Finalize system.\n",
      "INFO:tensorflow:Loss for final step: 0.08758007.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0xb5df8de48>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model (using estimator.train and data.Dataset)\n",
    "#estimator_train_model.train(input_fn=lambda:input_dataset_fn(x_train, y_train, is_training=True, batch_size=BATCH_SIZE),\n",
    "#                            max_steps=1,\n",
    "#                            hooks=[time_hist])\n",
    "estimator_train_model.train(input_fn=get_train_input_fn,\n",
    "                            #max_steps=1,\n",
    "                            steps=1000,\n",
    "                            hooks=[time_hist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time with the current strategy: 164.70961594581604 seconds\n"
     ]
    }
   ],
   "source": [
    "total_time = sum(time_hist.times)\n",
    "print(f\"total time with the current strategy: {total_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777.1252410794748 images/second\n"
     ]
    }
   ],
   "source": [
    "avg_time_per_batch = np.mean(time_hist.times)\n",
    "print(f\"{BATCH_SIZE/avg_time_per_batch} images/second\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start in a separte shell with the env activated:\n",
    "tensorboard --logdir your_path/proj_DL_models_and_pipelines_with_GCP/results/Models/Mnist/ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the accuracy of our model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "evaluate(\n",
    "    input_fn,\n",
    "    steps=None,\n",
    "    hooks=None,\n",
    "    checkpoint_path=None,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_dataset_fn: TRAIN, train\n",
      "the number of epoch: num_epoch = None\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-24-19:08:19\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../results/Models/Mnist/ckpt/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-24-19:08:36\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.98143333, global_step = 1000, loss = 0.06319532\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: ../results/Models/Mnist/ckpt/model.ckpt-1000\n"
     ]
    }
   ],
   "source": [
    "score=estimator_train_model.evaluate(input_fn=lambda:input_dataset_fn(x_train,y_train, mode=tf.estimator.ModeKeys.TRAIN, batch_size=len(y_train)),\n",
    "                                    steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.98143333, 'loss': 0.06319532, 'global_step': 1000}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.06319532\n",
      "Train accuracy: 0.98143333\n",
      "Train global steps: 1000\n"
     ]
    }
   ],
   "source": [
    "print('Train loss:', score['loss'])\n",
    "print('Train accuracy:', score['accuracy'])\n",
    "print('Train global steps:', score['global_step'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_dataset_fn: EVAL, eval\n",
      "the number of epoch: num_epoch = 1\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-24-14:00:20\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../results/Models/Mnist/ckpt/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-24-14:00:21\n",
      "INFO:tensorflow:Saving dict for global step 10: accuracy = 0.808, global_step = 10, loss = 0.77520794\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10: ../results/Models/Mnist/ckpt/model.ckpt-10\n"
     ]
    }
   ],
   "source": [
    "score=estimator_train_model.evaluate(input_fn=lambda:input_dataset_fn(x_test, y_test,mode=tf.estimator.ModeKeys.EVAL, batch_size=len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.77520794\n",
      "Test accuracy: 0.808\n",
      "Test global steps: 10\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', score['loss'])\n",
    "print('Test accuracy:', score['accuracy'])\n",
    "print('Test global steps:', score['global_step'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating predictions on our trained model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predict(\n",
    "    input_fn,\n",
    "    predict_keys=None,\n",
    "    hooks=None,\n",
    "    checkpoint_path=None,\n",
    "    yield_single_examples=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_dataset_fn: EVAL, eval\n",
      "the number of epoch: num_epoch = 1\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../results/Models/Mnist/ckpt/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions=list(estimator_train_model.predict(input_fn=lambda:input_dataset_fn(x_test, y_test,mode=tf.estimator.ModeKeys.EVAL, batch_size=len(x_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dense_1'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dense_input']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dense_1']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dense/bias',\n",
       " 'dense/bias/Adam',\n",
       " 'dense/bias/Adam_1',\n",
       " 'dense/kernel',\n",
       " 'dense/kernel/Adam',\n",
       " 'dense/kernel/Adam_1',\n",
       " 'dense_1/bias',\n",
       " 'dense_1/bias/Adam',\n",
       " 'dense_1/bias/Adam_1',\n",
       " 'dense_1/kernel',\n",
       " 'dense_1/kernel/Adam',\n",
       " 'dense_1/kernel/Adam_1',\n",
       " 'global_step',\n",
       " 'training/TFOptimizer/beta1_power',\n",
       " 'training/TFOptimizer/beta2_power']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_train_model.get_variable_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual label: 7\n",
      "Predicted label:  7\n",
      "Actual label: 2\n",
      "Predicted label:  2\n",
      "Actual label: 1\n",
      "Predicted label:  1\n",
      "Actual label: 0\n",
      "Predicted label:  0\n",
      "Actual label: 4\n",
      "Predicted label:  4\n",
      "Actual label: 1\n",
      "Predicted label:  1\n",
      "Actual label: 4\n",
      "Predicted label:  4\n",
      "Actual label: 9\n",
      "Predicted label:  9\n",
      "Actual label: 5\n",
      "Predicted label:  4\n",
      "Actual label: 9\n",
      "Predicted label:  9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    prediction_array = predictions[i]['dense_1']\n",
    "    predicted_label = np.argmax(prediction_array)\n",
    "    print('Actual label:', np.argmax(y_test[i]))\n",
    "    print(\"Predicted label: \", predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_train_model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dense/bias',\n",
       " 'dense/bias/Adam',\n",
       " 'dense/bias/Adam_1',\n",
       " 'dense/kernel',\n",
       " 'dense/kernel/Adam',\n",
       " 'dense/kernel/Adam_1',\n",
       " 'dense_1/bias',\n",
       " 'dense_1/bias/Adam',\n",
       " 'dense_1/bias/Adam_1',\n",
       " 'dense_1/kernel',\n",
       " 'dense_1/kernel/Adam',\n",
       " 'dense_1/kernel/Adam_1',\n",
       " 'global_step',\n",
       " 'training/TFOptimizer/beta1_power',\n",
       " 'training/TFOptimizer/beta2_power']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_train_model.get_variable_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn():\n",
    "    \"\"\"Serving input_fn that builds features from placeholders#\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf.estimator.export.ServingInputReceiver\n",
    "    \"\"\"\n",
    "    input_images = tf.placeholder(tf.float32, [None, 784])\n",
    "    features = {'dense_input' : input_images} # this is the dict that is then passed as \"features\" parameter to your model_fn\n",
    "    receiver_tensors = {'dense_input': input_images} # As far as I understand this is needed to map the input to a name you can retrieve later\n",
    "   \n",
    "    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from ../results/Models/Mnist/ckpt/model.ckpt-10\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ../results/Models/Mnist/pb/temp-b'1548343514'/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'../results/Models/Mnist/pb/1548343514'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_train_model.export_saved_model(FLAGS.saved_dir, \n",
    "                                         serving_input_receiver_fn=serving_input_receiver_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results/Models/Mnist/pb/1548343514/saved_model.pb\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../results/Models/Mnist/pb/1548343514/saved_model.pb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\r\n",
      "The given SavedModel SignatureDef contains the following output(s):\r\n",
      "Method name is: \r\n"
     ]
    }
   ],
   "source": [
    "! saved_model_cli show --dir ../results/Models/Mnist/pb/1548343514/ --tag serve --signature_def predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_gcp_dl]",
   "language": "python",
   "name": "conda-env-env_gcp_dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
