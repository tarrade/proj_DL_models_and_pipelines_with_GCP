{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scaling ML using Cloud ML Engine\n",
    "\n",
    "- to run the notebook underlying this presentation, go to [github.com/tarrade/proj_DL_models_and_pipelines_with_GCP](https://github.com/tarrade/proj_DL_models_and_pipelines_with_GCP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Contents\n",
    "\n",
    "2. Data Science Workflow\n",
    "3. Developing code\n",
    "4. Hands-ON Tutorial: Running MNIST on ML-Engine\n",
    "5. Setup Runtime for Notebook\n",
    "6. Load Data from BQ\n",
    "7. Package Model\n",
    "8. Train using ML-Engine\n",
    "9. Deployment\n",
    "10. Predictions\n",
    "11. Recap\n",
    "12. Appendix: Jupyter Slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Shortcut: Run first cells and jump to any part in the notebook\n",
    "\n",
    "> Will only work after initial setup (see below) !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "code_folding": [],
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working direcotory:\tC:\\Users\\C219746\\gcp\\project\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fragment to initalize working with this notebook on the CLOUD\n",
    "# check working directory\n",
    "from utils import chdir_\n",
    "pwd = chdir_()\n",
    "## Import Tensorflow\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "except ModuleNotFoundError:\n",
    "    raise ModuleNotFoundError(\"Install Tensorflow\")\n",
    "tf.__version__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "code_folding": [],
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucket': 'ml-productive-pipeline-53122',\n",
      " 'env-name': 'mnist',\n",
      " 'pkg-name': 'pkg_mnist_fnn',\n",
      " 'project-id': 'ml-productive-pipeline-53122',\n",
      " 'region': 'europe-west1',\n",
      " 'testdatafile': 'data/mnist/json/ml_engine_testdatafile_N4.json',\n",
      " 'tf-version': 1.13}\n"
     ]
    }
   ],
   "source": [
    "## import config:\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "with open(\"config2.yaml\", \"r\", encoding = \"utf8\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "code_folding": [],
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You run Windows -_-\n",
      "\n",
      "This means you are most probably on a Company Laptop and therefore behind a proxy.\n",
      "Set REQUESTS_CA_BUNDLE and HTTPS_PROXY environment variables\n"
     ]
    }
   ],
   "source": [
    "## setup env-variables \n",
    "import os\n",
    "import platform\n",
    "PROJECT = config['project-id'] \n",
    "REGION = config['region'] # Choose an available region for Cloud MLE from https://cloud.google.com/ml-engine/docs/regions.\n",
    "BUCKET = config['bucket'] # REPLACE WITH YOUR BUCKET NAME. Use a regional bucket in the region you selected.\n",
    "PKG_NAME = config['pkg-name']\n",
    "TEST_DATA_JSON = config['testdatafile']\n",
    "\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION \n",
    "os.environ['TFVERSION'] = str(config['tf-version'])  # Tensorflow version 1.4 before\n",
    "os.environ['PKG_NAME'] = PKG_NAME\n",
    "os.environ['TEST_DATA_JSON'] = TEST_DATA_JSON\n",
    "# os.environ['ENV_NAME'] = config['env-name']\n",
    "if platform.system() == 'Windows':\n",
    "    from script.config_client import filepath_ssl_cert\n",
    "    print('You run Windows -_-\\n\\n''This means you are most probably on a Company Laptop and therefore behind a proxy.\\n'\n",
    "         'Set REQUESTS_CA_BUNDLE and HTTPS_PROXY environment variables')\n",
    "    os.environ['REQUESTS_CA_BUNDLE'] = filepath_ssl_cert # 'win-filepath\\to\\axa'\n",
    "    assert os.path.isfile(os.environ['REQUESTS_CA_BUNDLE']), \"SSL-File not found\"\n",
    "    assert os.environ.get(key='HTTPS_PROXY') != None, \"Set a proxy\"\n",
    "    #os.environ['HTTPS_PROXY'] = 'https://C219746:Alles-Ist-Besser2019@sc-wvs-ch-win-pr-01-vip1.ch.doleni.net:8080'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OUTDIR=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained\n",
      "env: DATA=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n"
     ]
    }
   ],
   "source": [
    "# Set new OUTPUT and DATA directory on GS\n",
    "OUTDIR = '/'.join(['gs:/', BUCKET, PKG_NAME, 'trained'])\n",
    "DATA = '/'.join(['gs:/', BUCKET, PKG_NAME, 'data', 'mnist.npz'])\n",
    "%env OUTDIR $OUTDIR\n",
    "%env DATA $DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>gcloud config set project %PROJECT%\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>gcloud config set compute/region %REGION%\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>gcloud config set ml_engine/local_python \"%PYTHON_LOCAL%\"\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\r\n",
      "Updated property [compute/region].\r\n",
      "Updated property [ml_engine/local_python].\r\n"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "gcloud config set project %PROJECT%\n",
    "gcloud config set compute/region %REGION%\n",
    "gcloud config set ml_engine/local_python \"%PYTHON_LOCAL%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Science Workflow (DSP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Goal is to standardise the development of models\n",
    "     - Checklist of necessary technical steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Vision: Achieve an first end-to-end model in production within a *productincrement* of 10 weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Scale out: Scale without having to rewrite your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "// from https://github.com/jupyter/notebook/issues/3024#issuecomment-435630413\n",
       "var marked = require('components/marked/lib/marked');\n",
       "\n",
       "if (marked.Renderer.name !== 'NonExtensibleTableRenderer') {\n",
       "    function tablecell(content, flags) {\n",
       "        var type = flags.header ? 'th' : 'td';\n",
       "        var style = flags.align == null ? '' : ' style=\"text-align: ' + flags.align + '\"';\n",
       "        var start_tag = '<' + type + style + '>';\n",
       "        var end_tag = '</' + type + '>\\n';\n",
       "        return start_tag + content + end_tag;\n",
       "    }\n",
       "\n",
       "    var DefaultRenderer = marked.Renderer;\n",
       "    function NonExtensibleTableRenderer(options) {\n",
       "        DefaultRenderer.call(this, options);\n",
       "        Object.defineProperty(this, 'tablecell', {\n",
       "            get: function () { return tablecell; },\n",
       "            set: function () { } // No-op, sorry for this hack but we must prevent it from being redefined\n",
       "        });\n",
       "    }\n",
       "    NonExtensibleTableRenderer.prototype = Object.create(DefaultRenderer.prototype);\n",
       "    NonExtensibleTableRenderer.prototype.constructor = NonExtensibleTableRenderer;\n",
       "\n",
       "    marked.setOptions({\n",
       "        renderer: new NonExtensibleTableRenderer()\n",
       "    });\n",
       "    // Look away... it has to be done as newer versions of the notebook build a custom\n",
       "    // renderer rather than extending the default.\n",
       "    marked.Renderer = NonExtensibleTableRenderer;\n",
       "}\n",
       "\n",
       "var Jupyter = require('base/js/namespace');\n",
       "Jupyter.notebook.get_cells()\n",
       "   .filter(cell => cell.cell_type === 'markdown' && cell.rendered)\n",
       "   .forEach(mdcell => {\n",
       "       mdcell.unrender();\n",
       "       mdcell.render();\n",
       "   });\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript // some javascript to render markdown tables properly\n",
    "\n",
    "// from https://github.com/jupyter/notebook/issues/3024#issuecomment-435630413\n",
    "var marked = require('components/marked/lib/marked');\n",
    "\n",
    "if (marked.Renderer.name !== 'NonExtensibleTableRenderer') {\n",
    "    function tablecell(content, flags) {\n",
    "        var type = flags.header ? 'th' : 'td';\n",
    "        var style = flags.align == null ? '' : ' style=\"text-align: ' + flags.align + '\"';\n",
    "        var start_tag = '<' + type + style + '>';\n",
    "        var end_tag = '</' + type + '>\\n';\n",
    "        return start_tag + content + end_tag;\n",
    "    }\n",
    "\n",
    "    var DefaultRenderer = marked.Renderer;\n",
    "    function NonExtensibleTableRenderer(options) {\n",
    "        DefaultRenderer.call(this, options);\n",
    "        Object.defineProperty(this, 'tablecell', {\n",
    "            get: function () { return tablecell; },\n",
    "            set: function () { } // No-op, sorry for this hack but we must prevent it from being redefined\n",
    "        });\n",
    "    }\n",
    "    NonExtensibleTableRenderer.prototype = Object.create(DefaultRenderer.prototype);\n",
    "    NonExtensibleTableRenderer.prototype.constructor = NonExtensibleTableRenderer;\n",
    "\n",
    "    marked.setOptions({\n",
    "        renderer: new NonExtensibleTableRenderer()\n",
    "    });\n",
    "    // Look away... it has to be done as newer versions of the notebook build a custom\n",
    "    // renderer rather than extending the default.\n",
    "    marked.Renderer = NonExtensibleTableRenderer;\n",
    "}\n",
    "\n",
    "var Jupyter = require('base/js/namespace');\n",
    "Jupyter.notebook.get_cells()\n",
    "   .filter(cell => cell.cell_type === 'markdown' && cell.rendered)\n",
    "   .forEach(mdcell => {\n",
    "       mdcell.unrender();\n",
    "       mdcell.render();\n",
    "   });"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Science Pipeline (DSP) - Checklist\n",
    "\n",
    "- further [documentation](https://confluence.axa.com/confluence/pages/viewpage.action?pageId=112334644)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![Data Science Process](Images/data_science_circle_steps.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### [Scaling Michelangelo](https://eng.uber.com/scaling-michelangelo/) - Data Science Process at Uber\n",
    "![Data Science Process at Uber](Images/uber_michelangelo_at_scale.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "![Data Science Process](Images/data_science_circle.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "|   Step 1: Preparation                   |      Step 2: Data exploration and model building                   |    Step 3: Model deployment                    \n",
    "|   :------------------                   |      :-------------------------------------------                  |   :-----------------------------------------  \n",
    "| 1.1  Define business and project goal   | 2.1  Define and setup ML project infrastructure                    | 3.1  Model industralization                             \n",
    "| 1.2  Quick data exploration             | 2.2  Data exploration and visualizaiton                            | 3.2  Gather and analyze insightbalancing ...)     \n",
    "| 1.3  ML models strategy                 | 2.3  Build and evaluate a model                                    | -\n",
    "|         -                              | 2.4  Interpretability of ML model                                  | -\n",
    "|        -                                | 2.5  Productionize and deploy the ML models                        | -                                          \n",
    "> steps 1 and 2 can be done *only* locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Developing code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using your own laptop:\n",
    "- Cloud SDK on your laptop (CLI)\n",
    "- your IDE (e.g. PyCharme)\n",
    "- Juypter Notebook\n",
    "- your conda env\n",
    "- `gcloud ml-engine local` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Simple Cloud setup using\n",
    "- [Google Console](https://console.cloud.google.com/) -Compute Engine with 5 GB storage\n",
    "- Cloud Editor\n",
    "- datalab, [Deep Learning VM](https://cloud.google.com/deep-learning-vm/)\n",
    "- env ([runtime](https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list)) by google\n",
    "- `gcloud ml-engine` (`local`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "|Cloud SDK on Laptop | Google Console |\n",
    "|---------------------|----------------|\n",
    "| your machine | Tiny Compute Engine with 5 GB storage |\n",
    "| Your IDE | Code Editor|\n",
    "| Jupyter Notebook | Datalab, [Deep Learning VM](https://cloud.google.com/deep-learning-vm/) |\n",
    "| your conda env | env ([runtime](https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list)) by google |\n",
    "| `gcloud ml-engine local` | `gcloud ml-engine`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your laptop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![laptop-icon-24](Images/laptop-icon-24.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Call your python script (module) in your conda env\n",
    "2. Use `gcloud ml-engine local train`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## AI Platform Notebooks: Deep Learning VM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![Deep Learning VM](Images/deep-learning-overview_2x.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Preconfigured (Deep Learning) VMs for ML prottyping\n",
    "    - only CPUs possible\n",
    "- you use a preconfigured runtime compatible to ML Engine runtimes for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A cluster of machines using ML-Engine service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![CloudMachineLearning.png](Images/CloudMachineLearning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- runs a script \"autonomously\" on the cloud and stops afterwards\n",
    "- offers to run different type of clusters \n",
    "- invoked by `gcloud ml-engine train`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> develop on your laptop if you are comfortable with setting up your environements\n",
    "\n",
    "> otherwise develop on a preconfigured Notebook instance without too many compute attached to it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    ">Migrate to ML-Engine Cluster on GCP to \n",
    ">   - distribute learning on several machines\n",
    ">   - serve model 24/7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hands-ON Tutorial: Running MNIST on ML-Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"Images/gcp_training_options-Modelling.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- deep dive into step 2 and 3 of proposed Data Science process\n",
    "- data exploration is omitted since a curated dataset is used\n",
    "- Some title reference to previously described Data Science Process, e.g. DSP 2.3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Adapted from [Notebook](https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/cloudmle/cloudmle.ipynb) of Google Coursera Course [Serverless Machine Learning with Tensorflow on Google Cloud Platform](https://www.coursera.org/learn/serverless-machine-learning-gcp/). The current code respository is [github/tarrade/tarrade/proj_DL_models_and_pipelines_with_GCP/](https://github.com/tarrade/proj_DL_models_and_pipelines_with_GCP/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://ml4a.github.io/images/figures/mnist-input.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- black and white images are numeric vectors (Feat 1- 784)\n",
    "- ten labels (Figures 0-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- recognise hand-written digits (e.g. on a postal card) \n",
    "- standardise inputs to 0 - 1 range (e.g. using BEAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GCP services used in Tutorial\n",
    "We will look today at following GCP Services-\n",
    "- [BigQuery](https://console.cloud.google.com/bigquery) (BQ)\n",
    "- [Cloudstorage](https://console.cloud.google.com/storage) (Buckets)\n",
    "- [ML Engine](https://console.cloud.google.com/mlengine/)\n",
    "- If time allows: Dataflow using Apache Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils.mnist_utils import plot_mnist_testdata \n",
    "plot_mnist_testdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "ToDo: export in readable yaml format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DSP 2.1: Setup\n",
    "\n",
    "1. ML Engine Runtimes\n",
    "2. Repository Structure\n",
    "3. Configuration Variables\n",
    "    - Environment variables to set\n",
    "    - How to add them to your runtime\n",
    "4. Setup `gcloud` runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    ">Create conda environment\n",
    ">  ```\n",
    ">  conda env create -f environment.yml -n env_gcp_dl\n",
    ">  conda activate env_gcp_dl\n",
    ">  jupyter notebook \n",
    ">  ```\n",
    "> Starts notebook-server with all packages in your current path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Change working directory**\n",
    "\n",
    "- In order to import from `src` functionality later in this notebook, it is necessary to change to the root directory of the notebooks directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_style": "center",
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working direcotory:\tC:\\Users\\C219746\\gcp\\project\n"
     ]
    }
   ],
   "source": [
    "# check working directory\n",
    "import os\n",
    "WORKINGDIR = os.path.normpath(os.getcwd())\n",
    "print(\"Current Working direcotory:\\t{}\".format(WORKINGDIR))\n",
    "folders = WORKINGDIR.split(os.sep)\n",
    "if folders.pop() in ['notebook', 'src', 'talks']:\n",
    "  WORKINGDIR = os.sep.join(folders)\n",
    "  print(\"Changed to New working directory:\\t{dir}\".format(dir=WORKINGDIR))\n",
    "  os.chdir(WORKINGDIR) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ML Engine Runtimes\n",
    "Default ML-Engine Runtimes depend on the Tensorflow Version\n",
    "- [list of runtimes](https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list)\n",
    "- Current Version: `1.13`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#!conda install tensorflow=1.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "TF_VERSION=$(python3 -c 'import tensorflow as tf; print(tf.__version__)')\n",
    "if $TF_VERSION != \"1.13.0\"\n",
    "then\n",
    "    pip install tensorflow==1.13\n",
    "fi\n",
    "    echo \"Found Tensorflow: $TF_VERSION\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- current version of gcp datalab\n",
    "- will be different on Windows machines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Repository structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.04.2019  10:22    <DIR>          .\n",
      "17.04.2019  10:22    <DIR>          ..\n",
      "11.01.2019  11:46    <DIR>          .vscode\n",
      "15.04.2019  22:13               149 config.yaml\n",
      "15.04.2019  21:55               127 config_from_python.yaml\n",
      "12.04.2019  16:37               224 config2.yaml\n",
      "06.03.2019  17:23    <DIR>          data\n",
      "27.02.2019  10:15    <DIR>          doc\n",
      "17.04.2019  10:57    <DIR>          notebook\n",
      "11.01.2019  12:08    <DIR>          results\n",
      "15.04.2019  10:02    <DIR>          script\n",
      "12.04.2019  16:13    <DIR>          src\n",
      "15.04.2019  14:00    <DIR>          trained\n"
     ]
    }
   ],
   "source": [
    "ls | grep \"DIR\\|yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Key Directories containing information\n",
    "```\n",
    ".\n",
    "+-- data\n",
    "+-- src\n",
    "|  +-- models\n",
    "|  +-- packages\n",
    "config.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the next step the contents of [`config.yaml`](config.yaml) will be important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## GCP Environment Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `PROJECT_ID`: unique ID that identifies your project, e.g. **ml-productive-pipeline-12345**\n",
    "- `BUCKET`: BLOB-store ID. Each project has per default an bucket named by the `PROJECT_ID`\n",
    "- `REGION`: Which data center to use\n",
    "\n",
    "> All Cloud-ML-Engine Services are only available in [`europe-west1`](https://cloud.google.com/ml-engine/docs/tensorflow/regions)\n",
    "\n",
    "- all products per Region in europe: [link](https://cloud.google.com/about/locations/?region=europe#region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# #Create config manually and save as yaml:\n",
    "config = {}\n",
    "config['project-id'] = 'presentation-38388'  # # REPLACE WITH YOUR PROJECT ID\n",
    "config['region'] = 'europe-west1' # Choose an available region for Cloud MLE from https://cloud.google.com/ml-engine/docs/regions.\n",
    "config['bucket'] = 'presentation-38388'  # REPLACE WITH YOUR BUCKET NAME. Use a regional bucket in the region you selected.\n",
    "config['pkg-name'] = 'pkg_mnist_fnn'\n",
    "config['tf-version'] = '1.13'\n",
    "config['env-name'] = 'env_gcp_dl'\n",
    "with open(\"config.yaml\", 'w', encoding= 'utf8') as f:\n",
    "      yaml.dump(config, stream=f,  default_flow_style=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**ML-Engine Environment Variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Additional Environment Variables needed for ML-Engine\n",
    "- `PKG_NAME`: Package Name which will contain your model\n",
    "- `TF_VERSION`: Tensorflow Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucket': 'presentation-38388',\n",
      " 'env-name': 'env_gcp_dl',\n",
      " 'pkg-name': 'pkg_mnist_fnn',\n",
      " 'project-id': 'presentation-38388',\n",
      " 'region': 'europe-west1',\n",
      " 'tf-version': '1.13'}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pprint import pprint\n",
    "with open(\"config.yaml\", \"r\", encoding = \"utf8\") as f:\n",
    "    config = yaml.load(f)\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "### Environment variables for project and bucket\n",
    "\n",
    "Note that:\n",
    "1. Your project id is the *unique* string that identifies your project (not the project name). You can find this from the GCP Console dashboard's Home page. My dashboard reads:  \n",
    "     \n",
    "     - Project ID: ml-productive-pipeline-12345\n",
    "     \n",
    "2. Cloud training often involves saving and restoring model files. If you don't have a bucket already, I suggest that you create one from the GCP console (because it will dynamically check whether the bucket name you want is available). A common pattern is to prefix the bucket name by the project id, so that it is unique. Also, for cost reasons, you might want to use a single region bucket.\n",
    "\n",
    "\n",
    "Add all detail in to [config.yaml](../config.yaml) file in main directory. Missing in public repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Adding Environment Variables to your runtime\n",
    "- add variables **persistently**  to the runtime of your kernel from jupyter (or datalab)\n",
    "- use `os.environ` dictionary\n",
    "- behind a proxy, configure globally\n",
    "  - `REQUESTS_CA_BUNDLE`: optional, filepath to your SLL-certificate (works for `request`-package)\n",
    "  - `HTTPS_PROXY`: optional, link to your proxy, possibly includign authentification or ports\n",
    "- possiblity to set `environment variables` for user permanently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You run Windows -_-\n",
      "\n",
      "This means you are most probably on a Company Laptop and therefore behind a proxy.\n",
      "Set REQUESTS_CA_BUNDLE and HTTPS_PROXY environment variables\n"
     ]
    }
   ],
   "source": [
    "## setup env-variables \n",
    "import os\n",
    "import platform\n",
    "PROJECT = config['project-id'] \n",
    "REGION = config['region'] # Choose an available region for Cloud MLE from https://cloud.google.com/ml-engine/docs/regions.\n",
    "BUCKET = config['bucket'] # REPLACE WITH YOUR BUCKET NAME. Use a regional bucket in the region you selected.\n",
    "PKG_NAME = config['pkg-name']\n",
    "#TEST_DATA_JSON = config['testdatafile'] # added later\n",
    "\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = str(config['tf-version'])  # Tensorflow version 1.4 before\n",
    "os.environ['PKG_NAME'] = PKG_NAME\n",
    "#os.environ['TEST_DATA_JSON'] = TEST_DATA_JSON\n",
    "# os.environ['ENV_NAME'] = config['env-name']\n",
    "if platform.system() == 'Windows':\n",
    "    from script.config_client import filepath_ssl_cert\n",
    "    print('You run Windows -_-\\n\\n''This means you are most probably on a Company Laptop and therefore behind a proxy.\\n'\n",
    "         'Set REQUESTS_CA_BUNDLE and HTTPS_PROXY environment variables')\n",
    "    os.environ['REQUESTS_CA_BUNDLE'] = filepath_ssl_cert # 'win-filepath\\to\\axa'\n",
    "    assert os.path.isfile(os.environ['REQUESTS_CA_BUNDLE']), \"SSL-File not found\"\n",
    "    assert os.environ.get(key='HTTPS_PROXY') != None, \"Set a proxy\"\n",
    "    #os.environ['HTTPS_PROXY'] = 'https://C219746:Alles-Ist-Besser2019@sc-wvs-ch-win-pr-01-vip1.ch.doleni.net:8080'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Access Environment Variables**\n",
    "- Now, you can access the environement variable in the terminal where your jupyter, datalab or ipython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Using Tensorflow Version: $TFVERSION\"\n",
      "\"Using Tensorflow Version: 1.13\"\n"
     ]
    }
   ],
   "source": [
    "!echo \"Using Tensorflow Version: $TFVERSION\"\n",
    "!echo \"Using Tensorflow Version: %TFVERSION%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Setup gcloud runtime\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION\n",
    "## ensure we predict locally with our current Python environment\n",
    "gcloud config set ml_engine/local_python `which python`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHON_LOCAL=C:\\Program Files\\Anaconda3\\envs\\mnist\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "local_python = sys.executable\n",
    "%env PYTHON_LOCAL $local_python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>gcloud config set project %PROJECT%\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>gcloud config set compute/region %REGION%\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>gcloud config set ml_engine/local_python \"%PYTHON_LOCAL%\"\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\r\n",
      "Updated property [compute/region].\r\n",
      "Updated property [ml_engine/local_python].\r\n"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "gcloud config set project %PROJECT%\n",
    "gcloud config set compute/region %REGION%\n",
    "gcloud config set ml_engine/local_python \"%PYTHON_LOCAL%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Access Control \n",
    "\n",
    "- sign in and let clients pick up credentials from GCloud SDK (this stores a json with your credentials on your machine)\n",
    "    ```\n",
    "    gcloud auth application-default login\n",
    "    ```\n",
    "\n",
    "- Service Accounts ([Creating and Managing Service Accounts](https://cloud.google.com/iam/docs/creating-managing-service-accounts))\n",
    "  - need be assigned read/write permission to `BUCKET`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Load Data: Bigquery Client (DSP 2.2 )\n",
    "\n",
    "There are several python clients available, see list. Here we use `bigquery` to load some data.\n",
    "\n",
    "Picks up  PROXY_HTTPS, REQUESTS_CA_BUNDLE, PROJECT_ID from environment\n",
    "\n",
    "- set all relevant variables as user environment variables\n",
    "    1. search \"env\" in windows search bar (press windows button)\n",
    "    2. select \"Edit environment variables for your account\"\n",
    "    3. select \"new\" and add the PROXY_HTTPS, REQUESTS_CA_BUNDLE, PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example: Download from public dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Current project in use: presentation-38388\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\google\\auth\\_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state gender  year      name  number\n",
      "0    TX      F  1910      Mary     895\n",
      "1    TX      F  1910      Ruby     314\n",
      "2    TX      F  1910     Annie     277\n",
      "3    TX      F  1910    Willie     260\n",
      "4    TX      F  1910      Ruth     252\n",
      "5    TX      F  1910    Gladys     240\n",
      "6    TX      F  1910     Maria     223\n",
      "7    TX      F  1910   Frances     197\n",
      "8    TX      F  1910  Margaret     194\n",
      "9    TX      F  1910     Helen     189\n"
     ]
    }
   ],
   "source": [
    "# pip install --upgrade google-cloud-bigquery\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "\n",
    "PROJECT_ID = os.environ['PROJECT']\n",
    "print(\"# Current project in use: {}\\n\".format(PROJECT_ID))\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "sql = \"\"\"\n",
    "    SELECT *\n",
    "    FROM `bigquery-public-data.usa_names.usa_1910_current`\n",
    "    WHERE state = 'TX'\n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "df = client.query(sql).to_dataframe()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Download from project table\n",
    "- use `test` Dataset with table `DATA` of project (has to be created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_776</th>\n",
       "      <th>feat_777</th>\n",
       "      <th>feat_778</th>\n",
       "      <th>feat_779</th>\n",
       "      <th>feat_780</th>\n",
       "      <th>feat_781</th>\n",
       "      <th>feat_782</th>\n",
       "      <th>feat_783</th>\n",
       "      <th>feat_784</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  \\\n",
       "0   51       0       0       0       0       0       0       0       0   \n",
       "1   68       0       0       0       0       0       0       0       0   \n",
       "2   75       0       0       0       0       0       0       0       0   \n",
       "3  118       0       0       0       0       0       0       0       0   \n",
       "4  121       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   feat_9  ...  feat_776  feat_777  feat_778  feat_779  feat_780  feat_781  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   feat_782  feat_783  feat_784  label  \n",
       "0         0         0         0      0  \n",
       "1         0         0         0      0  \n",
       "2         0         0         0      0  \n",
       "3         0         0         0      0  \n",
       "4         0         0         0      0  \n",
       "\n",
       "[5 rows x 786 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    SELECT *\n",
    "    FROM `{project}.test.DATA`\n",
    "    LIMIT 15\n",
    "\"\"\".format(project=PROJECT)\n",
    "df = client.query(sql).to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6903</td>\n",
       "      <td>7877</td>\n",
       "      <td>6990</td>\n",
       "      <td>7141</td>\n",
       "      <td>6824</td>\n",
       "      <td>6313</td>\n",
       "      <td>6876</td>\n",
       "      <td>7293</td>\n",
       "      <td>6825</td>\n",
       "      <td>6958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2     3     4     5     6     7     8     9\n",
       "count  6903  7877  6990  7141  6824  6313  6876  7293  6825  6958"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    SELECT COUNT(label) as count\n",
    "    FROM `{project}.test.DATA`\n",
    "    GROUP BY label\n",
    "\"\"\".format(project=PROJECT)\n",
    "df = client.query(sql).to_dataframe()\n",
    "df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Downloading the entire table to pandas\n",
    "- BQ Query Default limit of128MB maximum reponse size, see [quotas](https://cloud.google.com/bigquery/quotas), does not allow to download entire Table\n",
    "- [`bigquery_storage`](https://cloud.google.com/bigquery/docs/bigquery-storage-python-pandas#install_the_client_libraries) client has to be used to download large datasets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "!pip install --upgrade google-cloud-bigquery[pandas]\n",
    "!pip install --upgrade google-cloud-bigquery-storage[fastavro,pandas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials: <google.oauth2.credentials.Credentials object at 0x00000123CCEBA668>\n",
      "PROJECT: presentation-38388\n"
     ]
    }
   ],
   "source": [
    "import google.auth\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import bigquery_storage_v1beta1\n",
    "\n",
    "# Explicitly create a credentials object. This allows you to use the same\n",
    "# credentials for both the BigQuery and BigQuery Storage clients, avoiding\n",
    "# unnecessary API calls to fetch duplicate authentication tokens.\n",
    "credentials, _ = google.auth.default(\n",
    "    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    ")\n",
    "print(\"Credentials: {}\".format(credentials))\n",
    "print(\"PROJECT: {}\".format(PROJECT))\n",
    "\n",
    "# Make clients.\n",
    "client = bigquery.Client(\n",
    "    credentials=credentials,\n",
    "    project=PROJECT\n",
    ")\n",
    "bqstorageclient = bigquery_storage_v1beta1.BigQueryStorageClient(\n",
    "    credentials=credentials\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Download to pandas dataframe\n",
    "- can take very long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Download a table.\n",
    "table = bigquery.TableReference.from_string(\n",
    "    \"{project}.test.DATA\".format(project=PROJECT)\n",
    ")\n",
    "rows = client.list_rows(\n",
    "    table,\n",
    "    #selected_fields=[ \n",
    "    #    bigquery.SchemaField(\"label\", \"INTEGER\")\n",
    "    #],\n",
    ")\n",
    "df = rows.to_dataframe(bqstorage_client=bqstorageclient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_776</th>\n",
       "      <th>feat_777</th>\n",
       "      <th>feat_778</th>\n",
       "      <th>feat_779</th>\n",
       "      <th>feat_780</th>\n",
       "      <th>feat_781</th>\n",
       "      <th>feat_782</th>\n",
       "      <th>feat_783</th>\n",
       "      <th>feat_784</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  \\\n",
       "0   51       0       0       0       0       0       0       0       0   \n",
       "1   68       0       0       0       0       0       0       0       0   \n",
       "2   75       0       0       0       0       0       0       0       0   \n",
       "3  118       0       0       0       0       0       0       0       0   \n",
       "4  121       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   feat_9  ...  feat_776  feat_777  feat_778  feat_779  feat_780  feat_781  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   feat_782  feat_783  feat_784  label  \n",
       "0         0         0         0      0  \n",
       "1         0         0         0      0  \n",
       "2         0         0         0      0  \n",
       "3         0         0         0      0  \n",
       "4         0         0         0      0  \n",
       "\n",
       "[5 rows x 786 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(file='data/mnist/raw/mnist_all', allow_pickle=True, arr=df.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model: Packaging model (DSP 2.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Take your code and put into a standard Python package structure, see  [Recommended package structure](https://cloud.google.com/ml-engine/docs/tensorflow/packaging-trainer#project-structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Key-Idea: \n",
    " - define entry point which can be called\n",
    " - write all tasks as a function (callable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " \n",
    "Why a package?\n",
    " - can be called from other scripts `import model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `model.py`\n",
    "\n",
    "load most recent version, if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%load src/pkg_mnist_fnn/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Imports, Helper Functions\n",
    "```python\n",
    "# First try to start Cloud ML uing MNIST example.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from .utils import load_data\n",
    "##########################################################################\n",
    "#Factored into config:\n",
    "IMAGE_SHAPE = (28,28)\n",
    "N_PIXEL = 28 * 28\n",
    "NUM_LABELS = 10\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "##########################################################################\n",
    "def parse_images(x):\n",
    "    return x.reshape(len(x), -1).astype('float32')\n",
    "\n",
    "\n",
    "def parse_labels(y):\n",
    "    return y.astype('int32')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Input-Function used when Model is trained\n",
    "```python\n",
    "def numpy_input_fn(images: np.ndarray,\n",
    "                   labels: np.ndarray,\n",
    "                   mode=tf.estimator.ModeKeys.EVAL):\n",
    "    \"\"\"\n",
    "    Return depending on the `mode`-key an Interator which can be use to feed into\n",
    "    the Estimator-Model. \n",
    "\n",
    "    Alternative if a `tf.data.Dataset` named `dataset` would be created:\n",
    "    `dataset.make_one_shot_iterator().get_next()`\n",
    "    \"\"\"\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        _epochs = EPOCHS\n",
    "        _shuffle = True\n",
    "        _num_threads = 2  # This leads to doubling the number of epochs\n",
    "    else:\n",
    "        _epochs = 1\n",
    "        _shuffle = False\n",
    "        _num_threads = 1\n",
    "\n",
    "    return tf.estimator.inputs.numpy_input_fn(\n",
    "        {'x': images},\n",
    "        y=labels,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_epochs=_epochs, # Boolean, if True shuffles the queue. \n",
    "                            # Avoid shuffle at prediction time.\n",
    "        # Boolean, if True shuffles the queue. Avoid shuffle at prediction\n",
    "        shuffle=_shuffle,\n",
    "        queue_capacity=1000, # Integer, number of threads used for reading\n",
    "        # and enqueueing. To have predicted order of reading and enqueueing, \n",
    "        # such as in prediction and evaluation mode, num_threads should be 1.\n",
    "        num_threads=_num_threads\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Input-Function used when Model is served\n",
    "```python\n",
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "        'x': tf.placeholder(tf.float32, shape=[None, N_PIXEL])\n",
    "    }\n",
    "    features = feature_placeholders\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "         features=features, \n",
    "         receiver_tensors=feature_placeholders,\n",
    "         receiver_tensors_alternatives=None\n",
    "         )\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Entrypoint (main function)\n",
    "```python\n",
    "def train_and_evaluate(args):\n",
    "    \"\"\"\n",
    "    Utility function for distributed training on ML-Engine\n",
    "    www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate \n",
    "    \"\"\"\n",
    "    # Load Data in Memoery\n",
    "    (x_train, y_train), (x_test, y_test) = load_data(\n",
    "        rel_path=args['data_path'])\n",
    "  \n",
    "    x_train = parse_images(x_train)\n",
    "    x_test = parse_images(x_test)\n",
    "\n",
    "    y_train = parse_labels(y_train)\n",
    "    y_test = parse_labels(y_test)\n",
    "\n",
    "    model = tf.estimator.DNNClassifier(\n",
    "        hidden_units=[256, 128, 64],\n",
    "        feature_columns=[tf.feature_column.numeric_column(\n",
    "            'x', shape=[N_PIXEL, ])],\n",
    "        model_dir=args['output_dir'],\n",
    "        n_classes=10,\n",
    "        optimizer=tf.train.AdamOptimizer,\n",
    "        # activation_fn=,\n",
    "        dropout=0.2,\n",
    "        batch_norm=False,\n",
    "        loss_reduction='weighted_sum',\n",
    "        warm_start_from=None,\n",
    "        config = None\n",
    "    )   \n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "    # ... see next slide\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "    # ... see previous slide\n",
    "\n",
    "    model = tf.estimator.DNNClassifier(\n",
    "    # see previous slide\n",
    "    )   \n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=numpy_input_fn(\n",
    "            x_train, y_train, mode=tf.estimator.ModeKeys.TRAIN),\n",
    "        max_steps=args['train_steps'],\n",
    "        hooks = None\n",
    "    )\n",
    "    exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=numpy_input_fn(\n",
    "            x_test, y_test, mode=tf.estimator.ModeKeys.EVAL),\n",
    "        steps=None,\n",
    "        start_delay_secs=args['eval_delay_secs'],\n",
    "        throttle_secs=args['min_eval_frequency'],\n",
    "        exporters=exporter\n",
    "    )\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=model, train_spec=train_spec, eval_spec=eval_spec)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `task.py`\n",
    "\n",
    "load most recent file using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%load src/pkg_mnist_fnn/task.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "\"\"\"\n",
    "Parse arguments and call main function\n",
    "\"\"\"\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "\n",
    "from .model import train_and_evaluate\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--data_path',\n",
    "        help='GCS or local path to training data',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--output_dir',\n",
    "        help='GCS location to write checkpoints and export models',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--train_batch_size',\n",
    "        help='Batch size for training steps',\n",
    "        type=int,\n",
    "        default='128'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--train_steps',\n",
    "        help='Steps to run the training job for',\n",
    "        type=int,\n",
    "        default='200'\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "    parser.add_argument(\n",
    "        '--hidden_units',\n",
    "        help='List of hidden layer sizes to use for DNN feature columns',\n",
    "        nargs='+',\n",
    "        type=int,\n",
    "        default=[128, 64, 32]\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--job_dir',\n",
    "        help='this model ignores this field, but it is required by gcloud',\n",
    "        default='junk'\n",
    "    )\n",
    "    # Eval arguments\n",
    "    parser.add_argument(\n",
    "        '--eval_delay_secs',\n",
    "        help='How long to wait before running first evaluation',\n",
    "        default=1,\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--min_eval_frequency',\n",
    "        help='Seconds between evaluations',\n",
    "        default=10,\n",
    "        type=int\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args().__dict__\n",
    "\n",
    "    OUTDIR = args['output_dir']\n",
    "    # #######################################\n",
    "    # # Train and Evaluate (use TensorBoard to visualize)\n",
    "    train_and_evaluate(args)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Train using ML-Engine on (DSP 2.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Modeling and ML-Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![gcp_training_options-overview.png](Images/gcp_training_options-overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Environment Variables with absolut paths to relevant folders: \n",
    "    - `PKG_NAME`: Self-Contained Package to be exported into `site-packages` in `venv`\n",
    "    - `DATA`, `OUTDIR`: Datafolder and where to store store checkpoints (logs,  weights, graph)\n",
    "    - `PWD`: where your project folder lies\n",
    "    - `JOBNAME`: ID for ML-Engine\n",
    "    - `BUCKET`: ID of Bucket\n",
    "    - `TIER`: Type of Cluster\n",
    "     \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Adding Code snippets\n",
    "\n",
    "![gcp_training_options-overview.png](Images/gcp_training_options-overview-code.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Schematic Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![GCP for Data Scientists](Images/gcp_scheme_parts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Contents ML-Engine Section\n",
    "\n",
    "- Training\n",
    "    - local (on your machine)\n",
    "    - on cluster (submitting a job)\n",
    "- Hyperparameter search (on cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training on your local maschine with your *python env*\n",
    "\n",
    "- Set local folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Data Directory:\t C:\\Users\\C219746\\gcp\\project\\data\\mnist\\raw\\mnist.npz\n",
      "Local Output Dir:\t C:\\Users\\C219746\\gcp\\project\\trained\\pkg_mnist_fnn\n"
     ]
    }
   ],
   "source": [
    "data_local = os.path.join(os.getcwd(),'data', 'mnist', 'raw', 'mnist.npz')\n",
    "OUTDIR_local = os.path.join(os.getcwd(),'trained', PKG_NAME)\n",
    "os.environ['OUTDIR_LOCAL'] = OUTDIR_local\n",
    "os.environ['DATA_LOCAL'] = data_local\n",
    "\n",
    "print(\"Local Data Directory:\\t {}\".format(os.environ['DATA_LOCAL']))\n",
    "print(\"Local Output Dir:\\t {}\".format(os.environ['OUTDIR_LOCAL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.rmtree(OUTDIR_local, ignore_errors=True)\n",
    "os.makedirs(name= OUTDIR_local, exist_ok=True)\n",
    "os.listdir(OUTDIR_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Running the Python `module` without gcp ml-engine\n",
    "\n",
    "- Entry point is defined in `task.py`\n",
    "  - parses command line arguments \n",
    "- conda env has to be active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -m src.${PKG_NAME}.task \\\n",
    "   --data_path=$DATA_LOCAL \\\n",
    "   --output_dir=$OUTDIR_LOCAL \\\n",
    "   --train_steps=1000 \\\n",
    "   --job_dir=tmp\n",
    "echo \"Saved Model, ckpts, exported model to: $OUTDIR_LOCAL\"\n",
    "ls $OUTDIR_LOCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>python -m src.%PKG_NAME%.task ^\n",
      "More?    --data_path=%DATA_LOCAL% ^\n",
      "More?    --output_dir=%OUTDIR_LOCAL% ^\n",
      "More?    --train_steps=1500 ^\n",
      "More?    --job_dir=tmp\n",
      "Current Working direcotory:\tC:\\Users\\C219746\\gcp\\project\r\n",
      "('Arguments:\\n'\r\n",
      " \"{'data_path': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\data\\\\\\\\mnist\\\\\\\\raw\\\\\\\\mnist.npz', \"\r\n",
      " \"'output_dir': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\trained\\\\\\\\pkg_mnist_fnn', \"\r\n",
      " \"'train_batch_size': 128, 'train_steps': 1500, 'hidden_units': '128 32 4', \"\r\n",
      " \"'job_dir': 'tmp', 'eval_delay_secs': 1, 'min_eval_frequency': 5}\")\r\n",
      "('Arguments:\\n'\r\n",
      " \"{'data_path': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\data\\\\\\\\mnist\\\\\\\\raw\\\\\\\\mnist.npz', \"\r\n",
      " \"'output_dir': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\trained\\\\\\\\pkg_mnist_fnn', \"\r\n",
      " \"'train_batch_size': 128, 'train_steps': 1500, 'hidden_units': [128, 32, 4], \"\r\n",
      " \"'job_dir': 'tmp', 'eval_delay_secs': 1, 'min_eval_frequency': 5}\")\r\n",
      "Save output to: C:\\Users\\C219746\\gcp\\project\\trained\\pkg_mnist_fnn\\\r\n",
      "## load data, specified path to try: C:\\Users\\C219746\\gcp\\project\\data\\mnist\\raw\\mnist.npz\r\n",
      "Loaded data from C:\\Users\\C219746\\gcp\\project\\data\\mnist\\raw\\mnist.npz\r\n",
      "## start training and evaluation\r\n",
      "### save model, ckpts, etc. to: C:\\Users\\C219746\\gcp\\project\\trained\\pkg_mnist_fnn\\\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>echo \"Saved Model, ckpts, exported model to: %OUTDIR%\"\n",
      "\"Saved Model, ckpts, exported model to: %OUTDIR%\"\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>dir %OUTDIR_LOCAL%\n",
      " Volume in drive C is Windows\r\n",
      " Volume Serial Number is 1CB1-4182\r\n",
      "\r\n",
      " Directory of C:\\Users\\C219746\\gcp\\project\\trained\\pkg_mnist_fnn\r\n",
      "\r\n",
      "17.04.2019  11:39    <DIR>          .\r\n",
      "17.04.2019  11:39    <DIR>          ..\r\n",
      "17.04.2019  11:39               266 checkpoint\r\n",
      "17.04.2019  11:39    <DIR>          eval\r\n",
      "17.04.2019  11:39           769'041 events.out.tfevents.1555493936.C054018\r\n",
      "17.04.2019  11:39    <DIR>          export\r\n",
      "17.04.2019  11:38           476'925 graph.pbtxt\r\n",
      "17.04.2019  11:38                16 model.ckpt-0.data-00000-of-00002\r\n",
      "17.04.2019  11:38         1'257'480 model.ckpt-0.data-00001-of-00002\r\n",
      "17.04.2019  11:38             1'018 model.ckpt-0.index\r\n",
      "17.04.2019  11:38           217'827 model.ckpt-0.meta\r\n",
      "17.04.2019  11:39                16 model.ckpt-1200.data-00000-of-00002\r\n",
      "17.04.2019  11:39         1'257'480 model.ckpt-1200.data-00001-of-00002\r\n",
      "17.04.2019  11:39             1'018 model.ckpt-1200.index\r\n",
      "17.04.2019  11:39           217'827 model.ckpt-1200.meta\r\n",
      "17.04.2019  11:39                16 model.ckpt-1500.data-00000-of-00002\r\n",
      "17.04.2019  11:39         1'257'480 model.ckpt-1500.data-00001-of-00002\r\n",
      "17.04.2019  11:39             1'018 model.ckpt-1500.index\r\n",
      "17.04.2019  11:39           217'827 model.ckpt-1500.meta\r\n",
      "17.04.2019  11:39                16 model.ckpt-400.data-00000-of-00002\r\n",
      "17.04.2019  11:39         1'257'480 model.ckpt-400.data-00001-of-00002\r\n",
      "17.04.2019  11:39             1'018 model.ckpt-400.index\r\n",
      "17.04.2019  11:39           217'827 model.ckpt-400.meta\r\n",
      "17.04.2019  11:39                16 model.ckpt-800.data-00000-of-00002\r\n",
      "17.04.2019  11:39         1'257'480 model.ckpt-800.data-00001-of-00002\r\n",
      "17.04.2019  11:39             1'018 model.ckpt-800.index\r\n",
      "17.04.2019  11:39           217'827 model.ckpt-800.meta\r\n",
      "              23 File(s)      8'627'937 bytes\r\n",
      "               4 Dir(s)  141'848'936'448 bytes free\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Colocations handled automatically by placer.\r\n",
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\r\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "To construct input pipelines, use the `tf.data` module.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "To construct input pipelines, use the `tf.data` module.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use tf.cast instead.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\r\n",
      "2019-04-17 11:38:57.284758: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2019-04-17 11:38:57.287955: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 4. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "To construct input pipelines, use the `tf.data` module.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use standard file APIs to check for files with this prefix.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\saved_model\\signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\r\n",
      "WARNING:tensorflow:Export includes no default signature!\r\n",
      "WARNING:tensorflow:Export includes no default signature!\r\n",
      "WARNING:tensorflow:Export includes no default signature!\r\n",
      "WARNING:tensorflow:Export includes no default signature!\r\n"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "python -m src.%PKG_NAME%.task ^\n",
    "   --data_path=%DATA_LOCAL% ^\n",
    "   --output_dir=%OUTDIR_LOCAL% ^\n",
    "   --train_steps=1500 ^\n",
    "   --job_dir=tmp\n",
    "echo \"Saved Model, ckpts, exported model to: %OUTDIR%\"\n",
    "dir %OUTDIR_LOCAL% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Call hidden units parameter\n",
    "- change model architecture\n",
    "- here previous model is deleted -> later several model will be compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(OUTDIR_local, ignore_errors=True)\n",
    "os.makedirs(name= OUTDIR_local, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "cell_style": "center",
    "hidden": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working direcotory:\t/home/enryh/proj_DL_models_and_pipelines_with_GCP\n",
      "Arguments:\n",
      "{'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_151816', 'train_batch_size': 128, 'train_steps': 1000, 'hidden_units': '128 64 32', 'job_dir': 'tmp', 'eval_delay_secs': 1, 'min_eval_frequency': 5}\n",
      "Arguments:\n",
      "{'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190322_151816', 'train_batch_size': 128, 'train_steps': 1000, 'hidden_units': [128, 64, 32], 'job_dir': 'tmp', 'eval_delay_secs': 1, 'min_eval_frequency': 5}\n",
      "Save output to: gs://ml-productive-pipeline-53122/mnist_190322_151816/\n",
      "## load data, specified path to try: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "1\n",
      "2\n",
      "Loaded data from gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "## start training and evaluation\n",
      "### save model, ckpts, etc. to: gs://ml-productive-pipeline-53122/mnist_190322_151816/\n",
      "Saved Model, ckpts, exported model to: gs://ml-productive-pipeline-53122/mnist_190322_151816\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -m src.${PKG_NAME}.task \\\n",
    "   --data_path    $DATA_LOCAL \\\n",
    "   --output_dir   $OUTDIR_LOCAL \\\n",
    "   --train_steps  1000 \\\n",
    "   --job_dir      tmp  \\\n",
    "   --train_batch_size   128 \\\n",
    "   --hidden_units \"128 64 32\"\n",
    "echo \"Saved Model, ckpts, exported model to: $OUTDIR_LOCAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>python -m src.%PKG_NAME%.task ^\n",
      "More?    --data_path=%DATA_LOCAL% ^\n",
      "More?    --output_dir=%OUTDIR_LOCAL% ^\n",
      "More?    --train_steps=1500 ^\n",
      "More?    --train_batch_size 128  ^\n",
      "More?    --hidden_units \"128 64 32\" ^\n",
      "More?    --job_dir=tmp\n",
      "Current Working direcotory:\tC:\\Users\\C219746\\gcp\\project\r\n",
      "('Arguments:\\n'\r\n",
      " \"{'data_path': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\data\\\\\\\\mnist\\\\\\\\raw\\\\\\\\mnist.npz', \"\r\n",
      " \"'output_dir': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\trained\\\\\\\\pkg_mnist_fnn', \"\r\n",
      " \"'train_batch_size': 128, 'train_steps': 1500, 'hidden_units': '128 64 32', \"\r\n",
      " \"'job_dir': 'tmp', 'eval_delay_secs': 1, 'min_eval_frequency': 5}\")\r\n",
      "('Arguments:\\n'\r\n",
      " \"{'data_path': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\data\\\\\\\\mnist\\\\\\\\raw\\\\\\\\mnist.npz', \"\r\n",
      " \"'output_dir': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\trained\\\\\\\\pkg_mnist_fnn', \"\r\n",
      " \"'train_batch_size': 128, 'train_steps': 1500, 'hidden_units': [128, 64, 32], \"\r\n",
      " \"'job_dir': 'tmp', 'eval_delay_secs': 1, 'min_eval_frequency': 5}\")\r\n",
      "Save output to: C:\\Users\\C219746\\gcp\\project\\trained\\pkg_mnist_fnn\\\r\n",
      "## load data, specified path to try: C:\\Users\\C219746\\gcp\\project\\data\\mnist\\raw\\mnist.npz\r\n",
      "Loaded data from C:\\Users\\C219746\\gcp\\project\\data\\mnist\\raw\\mnist.npz\r\n",
      "## start training and evaluation\r\n",
      "### save model, ckpts, etc. to: C:\\Users\\C219746\\gcp\\project\\trained\\pkg_mnist_fnn\\\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>echo \"Saved Model, ckpts, exported model to: %OUTDIR%\"\n",
      "\"Saved Model, ckpts, exported model to: %OUTDIR%\"\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>dir %OUTDIR_LOCAL%\n",
      " Volume in drive C is Windows\r\n",
      " Volume Serial Number is 1CB1-4182\r\n",
      "\r\n",
      " Directory of C:\\Users\\C219746\\gcp\\project\\trained\\pkg_mnist_fnn\r\n",
      "\r\n",
      "17.04.2019  11:41    <DIR>          .\r\n",
      "17.04.2019  11:41    <DIR>          ..\r\n",
      "17.04.2019  11:41               266 checkpoint\r\n",
      "17.04.2019  11:41    <DIR>          eval\r\n",
      "17.04.2019  11:41           829'281 events.out.tfevents.1555494061.C054018\r\n",
      "17.04.2019  11:41    <DIR>          export\r\n",
      "17.04.2019  11:41           479'494 graph.pbtxt\r\n",
      "17.04.2019  11:41                16 model.ckpt-0.data-00000-of-00002\r\n",
      "17.04.2019  11:41         1'333'752 model.ckpt-0.data-00001-of-00002\r\n",
      "17.04.2019  11:41             1'021 model.ckpt-0.index\r\n",
      "17.04.2019  11:41           218'915 model.ckpt-0.meta\r\n",
      "17.04.2019  11:41                16 model.ckpt-1200.data-00000-of-00002\r\n",
      "17.04.2019  11:41         1'333'752 model.ckpt-1200.data-00001-of-00002\r\n",
      "17.04.2019  11:41             1'021 model.ckpt-1200.index\r\n",
      "17.04.2019  11:41           218'915 model.ckpt-1200.meta\r\n",
      "17.04.2019  11:41                16 model.ckpt-1500.data-00000-of-00002\r\n",
      "17.04.2019  11:41         1'333'752 model.ckpt-1500.data-00001-of-00002\r\n",
      "17.04.2019  11:41             1'021 model.ckpt-1500.index\r\n",
      "17.04.2019  11:41           218'915 model.ckpt-1500.meta\r\n",
      "17.04.2019  11:41                16 model.ckpt-400.data-00000-of-00002\r\n",
      "17.04.2019  11:41         1'333'752 model.ckpt-400.data-00001-of-00002\r\n",
      "17.04.2019  11:41             1'021 model.ckpt-400.index\r\n",
      "17.04.2019  11:41           218'915 model.ckpt-400.meta\r\n",
      "17.04.2019  11:41                16 model.ckpt-800.data-00000-of-00002\r\n",
      "17.04.2019  11:41         1'333'752 model.ckpt-800.data-00001-of-00002\r\n",
      "17.04.2019  11:41             1'021 model.ckpt-800.index\r\n",
      "17.04.2019  11:41           218'915 model.ckpt-800.meta\r\n",
      "              23 File(s)      9'077'561 bytes\r\n",
      "               4 Dir(s)  141'848'707'072 bytes free\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Colocations handled automatically by placer.\r\n",
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\r\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "To construct input pipelines, use the `tf.data` module.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "To construct input pipelines, use the `tf.data` module.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use tf.cast instead.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\r\n",
      "2019-04-17 11:41:01.848640: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2019-04-17 11:41:01.850082: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 4. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "To construct input pipelines, use the `tf.data` module.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use standard file APIs to check for files with this prefix.\r\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\env_gcp_dl\\lib\\site-packages\\tensorflow\\python\\saved_model\\signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\r\n",
      "WARNING:tensorflow:Export includes no default signature!\r\n",
      "WARNING:tensorflow:Export includes no default signature!\r\n",
      "WARNING:tensorflow:Export includes no default signature!\r\n"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "python -m src.%PKG_NAME%.task ^\n",
    "   --data_path=%DATA_LOCAL% ^\n",
    "   --output_dir=%OUTDIR_LOCAL% ^\n",
    "   --train_steps=1500 ^\n",
    "   --train_batch_size 128  ^\n",
    "   --hidden_units \"128 64 32\" ^\n",
    "   --job_dir=tmp\n",
    "echo \"Saved Model, ckpts, exported model to: %OUTDIR%\"\n",
    "dir %OUTDIR_LOCAL%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1555494081'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.normpath(\"{}/export/exporter\".format(OUTDIR_local)))[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**And we would be ready to deploy**\n",
    "\n",
    "... but of course not without looking at performance metrics or predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training using `gcloud ml-engine local train`\n",
    "\n",
    "- continue training using `ml-engine local`\n",
    "- needs full-paths for out-dir: Add `$PWD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(OUTDIR_local, ignore_errors=True)\n",
    "os.makedirs(name= OUTDIR_local, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ml-engine local train \\\n",
    "   --module-name=${PKG_NAME}.task \\\n",
    "   --package-path=src/${PKG_NAME} \\\n",
    "   -- \\\n",
    "   --data_path=$DATA_LOCAL \\d\n",
    "   --output_dir=$OUTDIR_LOCAL \\\n",
    "   --train_steps=5500 \\\n",
    "   --job_dir=./tmp # not needed, but necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>gcloud ml-engine local train ^\n",
      "More?    --module-name=%PKG_NAME%.task ^\n",
      "More?    --package-path=src\\%PKG_NAME% ^\n",
      "More?    -- ^\n",
      "More?    --data_path=%DATA_LOCAL% ^\n",
      "More?    --output_dir=%OUTDIR_LOCAL% ^\n",
      "More?    --train_steps=1700 ^\n",
      "More?    --job_dir=.\\tmp \n",
      "('Arguments:\\n'\r\n",
      " \"{'data_path': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\data\\\\\\\\mnist\\\\\\\\raw\\\\\\\\mnist.npz', \"\r\n",
      " \"'output_dir': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\trained\\\\\\\\pkg_mnist_fnn', \"\r\n",
      " \"'train_batch_size': 128, 'train_steps': 1700, 'hidden_units': '128 32 4', \"\r\n",
      " \"'job_dir': '.\\\\\\\\tmp', 'eval_delay_secs': 1, 'min_eval_frequency': 5}\")\r\n",
      "('Arguments:\\n'\r\n",
      " \"{'data_path': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\data\\\\\\\\mnist\\\\\\\\raw\\\\\\\\mnist.npz', \"\r\n",
      " \"'output_dir': \"\r\n",
      " \"'C:\\\\\\\\Users\\\\\\\\C219746\\\\\\\\gcp\\\\\\\\project\\\\\\\\trained\\\\\\\\pkg_mnist_fnn', \"\r\n",
      " \"'train_batch_size': 128, 'train_steps': 1700, 'hidden_units': [128, 32, 4], \"\r\n",
      " \"'job_dir': '.\\\\\\\\tmp', 'eval_delay_secs': 1, 'min_eval_frequency': 5}\")\r\n",
      "Save output to: C:\\Users\\C219746\\gcp\\project\\trained\\pkg_mnist_fnn\\\r\n",
      "## load data, specified path to try: C:\\Users\\C219746\\gcp\\project\\data\\mnist\\raw\\mnist.npz\r\n",
      "Loaded data from C:\\Users\\C219746\\gcp\\project\\data\\mnist\\raw\\mnist.npz\r\n",
      "## start training and evaluation\r\n",
      "### save model, ckpts, etc. to: C:\\Users\\C219746\\gcp\\project\\trained\\pkg_mnist_fnn\\\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>dir %OUTDIR_LOCAL%\n",
      " Volume in drive C is Windows\r\n",
      " Volume Serial Number is 1CB1-4182\r\n",
      "\r\n",
      " Directory of C:\\Users\\C219746\\gcp\\project\\trained\\pkg_mnist_fnn\r\n",
      "\r\n",
      "17.04.2019  11:42    <DIR>          .\r\n",
      "17.04.2019  11:42    <DIR>          ..\r\n",
      "17.04.2019  11:42               269 checkpoint\r\n",
      "17.04.2019  11:42    <DIR>          eval\r\n",
      "17.04.2019  11:42           772'033 events.out.tfevents.1555494129.C054018\r\n",
      "17.04.2019  11:42           716'959 events.out.tfevents.1555494170.C054018\r\n",
      "17.04.2019  11:42    <DIR>          export\r\n",
      "17.04.2019  11:42           476'925 graph.pbtxt\r\n",
      "17.04.2019  11:42                16 model.ckpt-1200.data-00000-of-00002\r\n",
      "17.04.2019  11:42         1'257'480 model.ckpt-1200.data-00001-of-00002\r\n",
      "17.04.2019  11:42             1'018 model.ckpt-1200.index\r\n",
      "17.04.2019  11:42           217'827 model.ckpt-1200.meta\r\n",
      "17.04.2019  11:42                16 model.ckpt-1500.data-00000-of-00002\r\n",
      "17.04.2019  11:42         1'257'480 model.ckpt-1500.data-00001-of-00002\r\n",
      "17.04.2019  11:42             1'018 model.ckpt-1500.index\r\n",
      "17.04.2019  11:42           217'827 model.ckpt-1500.meta\r\n",
      "17.04.2019  11:42                16 model.ckpt-1700.data-00000-of-00002\r\n",
      "17.04.2019  11:42         1'257'480 model.ckpt-1700.data-00001-of-00002\r\n",
      "17.04.2019  11:42             1'018 model.ckpt-1700.index\r\n",
      "17.04.2019  11:42           217'827 model.ckpt-1700.meta\r\n",
      "17.04.2019  11:42                16 model.ckpt-400.data-00000-of-00002\r\n",
      "17.04.2019  11:42         1'257'480 model.ckpt-400.data-00001-of-00002\r\n",
      "17.04.2019  11:42             1'018 model.ckpt-400.index\r\n",
      "17.04.2019  11:42           217'827 model.ckpt-400.meta\r\n",
      "17.04.2019  11:42                16 model.ckpt-800.data-00000-of-00002\r\n",
      "17.04.2019  11:42         1'257'480 model.ckpt-800.data-00001-of-00002\r\n",
      "17.04.2019  11:42             1'018 model.ckpt-800.index\r\n",
      "17.04.2019  11:42           217'827 model.ckpt-800.meta\r\n",
      "              24 File(s)      9'347'891 bytes\r\n",
      "               4 Dir(s)  141'848'547'328 bytes free\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "gcloud ml-engine local train ^\n",
    "   --module-name=%PKG_NAME%.task ^\n",
    "   --package-path=src\\%PKG_NAME% ^\n",
    "   -- ^\n",
    "   --data_path=%DATA_LOCAL% ^\n",
    "   --output_dir=%OUTDIR_LOCAL% ^\n",
    "   --train_steps=1700 ^\n",
    "   --job_dir=.\\tmp \n",
    "dir %OUTDIR_LOCAL% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!gcloud ml-engine local train  --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training Cloud using `gcloud ml-engine train`\n",
    "\n",
    "- a copy of the data is in [Google Storage](https://console.cloud.google.com/storage) (buckets)\n",
    "- `gcloud ml-engine` output is saved to `OUTDIR`in Google Storage \n",
    "  - checkpoints (logs)\n",
    "  - model graph and weights\n",
    "- data is copied to Google Storage (see [console](https://console.cloud.google.com/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs using 10000 steps: 21.3\n",
      "For ten epochs specify 4688 steps\n"
     ]
    }
   ],
   "source": [
    "# 10 epochs in global steps:\n",
    "steps = 10000\n",
    "batch_size = 128\n",
    "n_train = 60000\n",
    "print(\"Number of epochs using {} steps: {:.1f}\".format(steps, steps * batch_size / n_train))\n",
    "steps = int(60000 / 128 * 10) + 1\n",
    "print(\"For ten epochs specify {} steps\".format(steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##### Check: Does this account for parallel processes in input fct?\n",
    "- If global steps is done on two processes, the number doubles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBNAME=mnist_190417_132839\n",
      "env: OUTDIR=gs://presentation-38388/mnist_190417_132839\n",
      "env: DATA=gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz\n"
     ]
    }
   ],
   "source": [
    "#Set JOBNAME\n",
    "import datetime\n",
    "JOBNAME = 'mnist_' + datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "%env JOBNAME {JOBNAME}\n",
    "# Set new OUTPUT and DATA directory in GS\n",
    "OUTDIR = '/'.join(['gs:/', BUCKET, JOBNAME])\n",
    "DATA = '/'.join(['gs:/', BUCKET, PKG_NAME, 'data', 'mnist.npz'])\n",
    "%env OUTDIR $OUTDIR\n",
    "%env DATA $DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTDIR on GS: gs://presentation-38388/mnist_190417_132839\n",
      "DATA on GS: gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz\n"
     ]
    }
   ],
   "source": [
    "print(\"OUTDIR on GS: {}\".format(OUTDIR))\n",
    "print(\"DATA on GS: {}\".format(DATA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Data Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil -m cp ${PWD}/data/mnist/raw/mnist.npz ${DATA}\n",
    "gsutil ls ${DATA}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>gsutil -m cp %cd%\\data\\mnist\\raw\\mnist.npz %DATA%\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://C:\\Users\\C219746\\gcp\\project\\data\\mnist\\raw\\mnist.npz [Content-Type=application/octet-stream]...\r\n",
      "/ [0/1 files][    0.0 B/ 11.0 MiB]   0% Done                                    \r",
      "-\r",
      "- [0/1 files][  7.7 MiB/ 11.0 MiB]  70% Done                                    \r",
      "\\\r",
      "\\ [1/1 files][ 11.0 MiB/ 11.0 MiB] 100% Done                                    \r",
      "\r\n",
      "Operation completed over 1 objects/11.0 MiB.                                     \r\n"
     ]
    }
   ],
   "source": [
    "%%cmd \n",
    "gsutil -m cp %cd%\\data\\mnist\\raw\\mnist.npz %DATA%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls \"%DATA%\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!gsutil ls $DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ml-engine on cluster\n",
    "- set `JOBNAME` and decide which [tier](https://cloud.google.com/ml-engine/docs/tensorflow/machine-types#scale_tiers) to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBNAME=mnist_190417_132744\n",
      "env: TIER=STANDARD_1\n"
     ]
    }
   ],
   "source": [
    "%env TIER STANDARD_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $OUTDIR $DATA $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=$PKG_NAME.task \\\n",
    "   --package-path=${PWD}/src/$PKG_NAME \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=$TIER \\\n",
    "   --python-version 3.5 \\\n",
    "   --runtime-version=$TFVERSION \\\n",
    "   -- \\\n",
    "   --data_path=$DATA \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --train_steps=5000 \\\n",
    "   --job_dir=$OUTDIR/jobs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>echo \"OUT: %OUTDIR%, Region: %REGION%, JOBNAME: %JOBNAME%\"\n",
      "\"OUT: gs://presentation-38388/mnist_190417_132839, Region: europe-west1, JOBNAME: mnist_190417_132839\"\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>gsutil -m rm -rf %OUTDIR%\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>gcloud ml-engine jobs submit training %JOBNAME% ^\n",
      "More?    --region=%REGION% ^\n",
      "More?    --module-name=%PKG_NAME%.task ^\n",
      "More?    --package-path=src\\%PKG_NAME% ^\n",
      "More?    --staging-bucket=gs://%BUCKET% ^\n",
      "More?    --scale-tier=%TIER% ^\n",
      "More?    --python-version 3.5 ^\n",
      "More?    --runtime-version=%TFVERSION% ^\n",
      "More?    -- ^\n",
      "More?    --data_path=%DATA% ^\n",
      "More?    --output_dir=%OUTDIR% ^\n",
      "More?    --train_steps=5000 ^\n",
      "More?    --job_dir=%OUTDIR%/jobs \n",
      "jobId: mnist_190417_132839\r\n",
      "state: QUEUED\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\r\n",
      "Job [mnist_190417_132839] submitted successfully.\r\n",
      "Your job is still active. You may view the status of your job with the command\r\n",
      "\r\n",
      "  $ gcloud ml-engine jobs describe mnist_190417_132839\r\n",
      "\r\n",
      "or continue streaming the logs with the command\r\n",
      "\r\n",
      "  $ gcloud ml-engine jobs stream-logs mnist_190417_132839\r\n"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "echo \"OUT: %OUTDIR%, Region: %REGION%, JOBNAME: %JOBNAME%\"\n",
    "gsutil -m rm -rf %OUTDIR%\n",
    "\n",
    "gcloud ml-engine jobs submit training %JOBNAME% ^\n",
    "   --region=%REGION% ^\n",
    "   --module-name=%PKG_NAME%.task ^\n",
    "   --package-path=src\\%PKG_NAME% ^\n",
    "   --staging-bucket=gs://%BUCKET% ^\n",
    "   --scale-tier=%TIER% ^\n",
    "   --python-version 3.5 ^\n",
    "   --runtime-version=%TFVERSION% ^\n",
    "   -- ^\n",
    "   --data_path=%DATA% ^\n",
    "   --output_dir=%OUTDIR% ^\n",
    "   --train_steps=5000 ^\n",
    "   --job_dir=%OUTDIR%/jobs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fetch logs from ml-engine job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2019-04-17T11:29:00Z'\n",
      "etag: 8ycvfVFWx0E=\n",
      "jobId: mnist_190417_132839\n",
      "state: PREPARING\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --data_path=gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz\n",
      "  - --output_dir=gs://presentation-38388/mnist_190417_132839\n",
      "  - --train_steps=5000\n",
      "  - --job_dir=gs://presentation-38388/mnist_190417_132839/jobs\n",
      "  packageUris:\n",
      "  - gs://presentation-38388/mnist_190417_132839/14c524dda3f31f75ef6f3dd39f24768a630b2aeb2b3fda2e04302897944f93de/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "  pythonModule: pkg_mnist_fnn.task\n",
      "  pythonVersion: '3.5'\n",
      "  region: europe-west1\n",
      "  runtimeVersion: '1.13'\n",
      "  scaleTier: STANDARD_1\n",
      "trainingOutput: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/ml/jobs/mnist_190417_132839?project=presentation-38388\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml.googleapis.com%2Fjob_id%2Fmnist_190417_132839&project=presentation-38388\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine jobs describe %JOBNAME%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo $JOBNAME\n",
    "gcloud ml-engine jobs describe $JOBNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud ml-engine jobs stream-logs $JOBNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-04-12 16:13:38 +0200\tservice\t\tValidating job requirements...\n",
      "INFO\t2019-04-12 16:13:38 +0200\tservice\t\tJob creation request has been successfully validated.\n",
      "INFO\t2019-04-12 16:13:39 +0200\tservice\t\tJob mnist_190412_153749 is queued.\n",
      "INFO\t2019-04-12 16:13:40 +0200\tservice\t\tWaiting for job to be provisioned.\n",
      "INFO\t2019-04-12 16:16:46 +0200\tservice\t\tWaiting for training program to start.\n",
      "INFO\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\tRunning task with arguments: --cluster={\"master\": [\"cmle-training-master-6fd0bbea02-0:2222\"], \"ps\": [\"cmle-training-ps-6fd0bbea02-0:2222\", \"cmle-training-ps-6fd0bbea02-1:2222\", \"cmle-training-ps-6fd0bbea02-2:2222\"], \"worker\": [\"cmle-training-worker-6fd0bbea02-0:2222\", \"cmle-training-worker-6fd0bbea02-1:2222\", \"cmle-training-worker-6fd0bbea02-2:2222\", \"cmle-training-worker-6fd0bbea02-3:2222\"]} --task={\"type\": \"worker\", \"index\": 1} --job={\n",
      "INFO\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\t  \"scale_tier\": \"STANDARD_1\",\n",
      "INFO\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\t  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\"],\n",
      "INFO\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\t  \"python_module\": \"pkg_mnist_fnn.task\",\n",
      "INFO\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\t  \"args\": [\"--data_path\\u003dgs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\", \"--output_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749\", \"--train_steps\\u003d1000\", \"--job_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\"],\n",
      "INFO\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\t  \"region\": \"europe-west1\",\n",
      "INFO\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\t  \"runtime_version\": \"1.13\",\n",
      "INFO\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\t  \"python_version\": \"3.5\"\n",
      "INFO\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\t}\n",
      "WARNING\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:23 +0200\tworker-replica-1\t\tColocations handled automatically by placer.\n",
      "INFO\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\tRunning task with arguments: --cluster={\"master\": [\"cmle-training-master-6fd0bbea02-0:2222\"], \"ps\": [\"cmle-training-ps-6fd0bbea02-0:2222\", \"cmle-training-ps-6fd0bbea02-1:2222\", \"cmle-training-ps-6fd0bbea02-2:2222\"], \"worker\": [\"cmle-training-worker-6fd0bbea02-0:2222\", \"cmle-training-worker-6fd0bbea02-1:2222\", \"cmle-training-worker-6fd0bbea02-2:2222\", \"cmle-training-worker-6fd0bbea02-3:2222\"]} --task={\"type\": \"worker\", \"index\": 0} --job={\n",
      "INFO\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\t  \"scale_tier\": \"STANDARD_1\",\n",
      "INFO\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\t  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\"],\n",
      "INFO\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\t  \"python_module\": \"pkg_mnist_fnn.task\",\n",
      "INFO\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\t  \"args\": [\"--data_path\\u003dgs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\", \"--output_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749\", \"--train_steps\\u003d1000\", \"--job_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\"],\n",
      "INFO\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\t  \"region\": \"europe-west1\",\n",
      "INFO\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\t  \"runtime_version\": \"1.13\",\n",
      "INFO\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\t  \"python_version\": \"3.5\"\n",
      "INFO\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\t}\n",
      "WARNING\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:24 +0200\tworker-replica-0\t\tColocations handled automatically by placer.\n",
      "INFO\t2019-04-12 16:18:25 +0200\tworker-replica-1\t\tRunning module pkg_mnist_fnn.task.\n",
      "INFO\t2019-04-12 16:18:25 +0200\tworker-replica-1\t\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:25 +0200\tworker-replica-1\t\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:25 +0200\tworker-replica-0\t\tRunning module pkg_mnist_fnn.task.\n",
      "INFO\t2019-04-12 16:18:25 +0200\tworker-replica-0\t\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:25 +0200\tworker-replica-0\t\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:27 +0200\tworker-replica-1\t\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:27 +0200\tworker-replica-1\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:27 +0200\tworker-replica-0\t\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:27 +0200\tworker-replica-0\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:27 +0200\tworker-replica-1\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:27 +0200\tworker-replica-0\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:27 +0200\tworker-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:27 +0200\tworker-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:27 +0200\tmaster-replica-0\t\tRunning task with arguments: --cluster={\"master\": [\"cmle-training-master-6fd0bbea02-0:2222\"], \"ps\": [\"cmle-training-ps-6fd0bbea02-0:2222\", \"cmle-training-ps-6fd0bbea02-1:2222\", \"cmle-training-ps-6fd0bbea02-2:2222\"], \"worker\": [\"cmle-training-worker-6fd0bbea02-0:2222\", \"cmle-training-worker-6fd0bbea02-1:2222\", \"cmle-training-worker-6fd0bbea02-2:2222\", \"cmle-training-worker-6fd0bbea02-3:2222\"]} --task={\"type\": \"master\", \"index\": 0} --job={\n",
      "INFO\t2019-04-12 16:18:27 +0200\tmaster-replica-0\t\t  \"scale_tier\": \"STANDARD_1\",\n",
      "INFO\t2019-04-12 16:18:27 +0200\tmaster-replica-0\t\t  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\"],\n",
      "INFO\t2019-04-12 16:18:27 +0200\tmaster-replica-0\t\t  \"python_module\": \"pkg_mnist_fnn.task\",\n",
      "INFO\t2019-04-12 16:18:27 +0200\tmaster-replica-0\t\t  \"args\": [\"--data_path\\u003dgs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\", \"--output_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749\", \"--train_steps\\u003d1000\", \"--job_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\"],\n",
      "INFO\t2019-04-12 16:18:27 +0200\tmaster-replica-0\t\t  \"region\": \"europe-west1\",\n",
      "INFO\t2019-04-12 16:18:27 +0200\tmaster-replica-0\t\t  \"runtime_version\": \"1.13\",\n",
      "INFO\t2019-04-12 16:18:27 +0200\tmaster-replica-0\t\t  \"python_version\": \"3.5\"\n",
      "INFO\t2019-04-12 16:18:27 +0200\tmaster-replica-0\t\t}\n",
      "INFO\t2019-04-12 16:18:28 +0200\tps-replica-1\t\tRunning task with arguments: --cluster={\"master\": [\"cmle-training-master-6fd0bbea02-0:2222\"], \"ps\": [\"cmle-training-ps-6fd0bbea02-0:2222\", \"cmle-training-ps-6fd0bbea02-1:2222\", \"cmle-training-ps-6fd0bbea02-2:2222\"], \"worker\": [\"cmle-training-worker-6fd0bbea02-0:2222\", \"cmle-training-worker-6fd0bbea02-1:2222\", \"cmle-training-worker-6fd0bbea02-2:2222\", \"cmle-training-worker-6fd0bbea02-3:2222\"]} --task={\"type\": \"ps\", \"index\": 1} --job={\n",
      "INFO\t2019-04-12 16:18:28 +0200\tps-replica-1\t\t  \"scale_tier\": \"STANDARD_1\",\n",
      "INFO\t2019-04-12 16:18:28 +0200\tps-replica-1\t\t  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\"],\n",
      "INFO\t2019-04-12 16:18:28 +0200\tps-replica-1\t\t  \"python_module\": \"pkg_mnist_fnn.task\",\n",
      "INFO\t2019-04-12 16:18:28 +0200\tps-replica-1\t\t  \"args\": [\"--data_path\\u003dgs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\", \"--output_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749\", \"--train_steps\\u003d1000\", \"--job_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\"],\n",
      "INFO\t2019-04-12 16:18:28 +0200\tps-replica-1\t\t  \"region\": \"europe-west1\",\n",
      "INFO\t2019-04-12 16:18:28 +0200\tps-replica-1\t\t  \"runtime_version\": \"1.13\",\n",
      "INFO\t2019-04-12 16:18:28 +0200\tps-replica-1\t\t  \"python_version\": \"3.5\"\n",
      "INFO\t2019-04-12 16:18:28 +0200\tps-replica-1\t\t}\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-1\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-1\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "WARNING\t2019-04-12 16:18:28 +0200\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:28 +0200\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:28 +0200\tmaster-replica-0\t\tColocations handled automatically by placer.\n",
      "WARNING\t2019-04-12 16:18:28 +0200\tps-replica-1\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:28 +0200\tps-replica-1\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:28 +0200\tps-replica-1\t\tColocations handled automatically by placer.\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-1\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-1\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-1\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-1\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-1\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-1\t\tRunning command: pip3 install --user pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:28 +0200\tworker-replica-0\t\tRunning command: pip3 install --user pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:29 +0200\tworker-replica-1\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:29 +0200\tps-replica-1\t\tRunning module pkg_mnist_fnn.task.\n",
      "INFO\t2019-04-12 16:18:29 +0200\tps-replica-1\t\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:29 +0200\tps-replica-1\t\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:29 +0200\tworker-replica-0\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:29 +0200\tmaster-replica-0\t\tRunning module pkg_mnist_fnn.task.\n",
      "INFO\t2019-04-12 16:18:29 +0200\tmaster-replica-0\t\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:29 +0200\tmaster-replica-0\t\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:29 +0200\tworker-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:29 +0200\tworker-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:29 +0200\tworker-replica-1\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:29 +0200\tworker-replica-1\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:29 +0200\tworker-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:29 +0200\tworker-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:29 +0200\tworker-replica-0\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:29 +0200\tworker-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\t  Found existing installation: pkg-mnist-fnn 0.0.0\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\t    Uninstalling pkg-mnist-fnn-0.0.0:\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\t      Successfully uninstalled pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-1\t\tRunning command: python3 -m pkg_mnist_fnn.task --data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz --output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749 --train_steps=1000 --job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\t  Found existing installation: pkg-mnist-fnn 0.0.0\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\t    Uninstalling pkg-mnist-fnn-0.0.0:\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\t      Successfully uninstalled pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:30 +0200\tworker-replica-0\t\tRunning command: python3 -m pkg_mnist_fnn.task --data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz --output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749 --train_steps=1000 --job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\n",
      "INFO\t2019-04-12 16:18:31 +0200\tps-replica-1\t\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:31 +0200\tps-replica-1\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:31 +0200\tmaster-replica-0\t\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:31 +0200\tmaster-replica-0\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:31 +0200\tps-replica-1\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:32 +0200\tmaster-replica-0\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:32 +0200\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:32 +0200\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:32 +0200\tmaster-replica-0\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:32 +0200\tmaster-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:32 +0200\tps-replica-1\t\tRunning command: pip3 install --user pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:33 +0200\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:33 +0200\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:33 +0200\tmaster-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:33 +0200\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:33 +0200\tmaster-replica-0\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:33 +0200\tmaster-replica-0\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:33 +0200\tmaster-replica-0\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:33 +0200\tps-replica-1\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:33 +0200\tmaster-replica-0\t\tRunning command: pip3 install --user pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:33 +0200\tps-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:33 +0200\tps-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:33 +0200\tps-replica-1\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:33 +0200\tps-replica-1\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:34 +0200\tmaster-replica-0\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tTF_CONFIG environment variable: {'environment': 'cloud', 'job': {'args': ['--data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', '--output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749', '--train_steps=1000', '--job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs'], 'region': 'europe-west1', 'scale_tier': 'STANDARD_1', 'runtime_version': '1.13', 'python_version': '3.5', 'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz'], 'python_module': 'pkg_mnist_fnn.task'}, 'task': {'cloud': 'qe913eccfb8ab063b-ml', 'type': 'worker', 'index': 1}, 'cluster': {'ps': ['cmle-training-ps-6fd0bbea02-0:2222', 'cmle-training-ps-6fd0bbea02-1:2222', 'cmle-training-ps-6fd0bbea02-2:2222'], 'worker': ['cmle-training-worker-6fd0bbea02-0:2222', 'cmle-training-worker-6fd0bbea02-1:2222', 'cmle-training-worker-6fd0bbea02-2:2222', 'cmle-training-worker-6fd0bbea02-3:2222'], 'master': ['cmle-training-master-6fd0bbea02-0:2222']}}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tUsing config: {'_train_distribute': None, '_eval_distribute': None, '_num_worker_replicas': 5, '_save_summary_steps': 100, '_protocol': None, '_device_fn': None, '_experimental_distribute': None, '_tf_random_seed': None, '_keep_checkpoint_max': 5, '_log_step_count_steps': 100, '_save_checkpoints_secs': None, '_num_ps_replicas': 3, '_task_type': 'worker', '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tdevice_filters: \"/job:worker/task:1\"\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tallow_soft_placement: true\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tgraph_options {\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\t  rewrite_options {\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\t  }\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\t}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\t, '_keep_checkpoint_every_n_hours': 1, '_is_chief': False, '_save_checkpoints_steps': 400, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f07abb07b70>, '_evaluation_master': '', '_model_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/', '_task_id': 1, '_master': 'grpc://cmle-training-worker-6fd0bbea02-1:2222', '_global_id_in_cluster': 2}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tNot using Distribute Coordinator.\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tStart Tensorflow server.\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tCPU Frequency: 2300000000 Hz\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tXLA service 0x4a912e0 executing computations on platform Host. Devices:\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\t  StreamExecutor device (0): <undefined>, <undefined>\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tInitialize GrpcChannelCache for job master -> {0 -> cmle-training-master-6fd0bbea02-0:2222}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tInitialize GrpcChannelCache for job ps -> {0 -> cmle-training-ps-6fd0bbea02-0:2222, 1 -> cmle-training-ps-6fd0bbea02-1:2222, 2 -> cmle-training-ps-6fd0bbea02-2:2222}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tInitialize GrpcChannelCache for job worker -> {0 -> cmle-training-worker-6fd0bbea02-0:2222, 1 -> localhost:2222, 2 -> cmle-training-worker-6fd0bbea02-2:2222, 3 -> cmle-training-worker-6fd0bbea02-3:2222}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tStarted server with target: grpc://localhost:2222\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-1\t\tWaiting 10 secs before starting training.\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tTF_CONFIG environment variable: {'job': {'scale_tier': 'STANDARD_1', 'region': 'europe-west1', 'python_module': 'pkg_mnist_fnn.task', 'args': ['--data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', '--output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749', '--train_steps=1000', '--job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs'], 'python_version': '3.5', 'runtime_version': '1.13', 'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz']}, 'environment': 'cloud', 'cluster': {'ps': ['cmle-training-ps-6fd0bbea02-0:2222', 'cmle-training-ps-6fd0bbea02-1:2222', 'cmle-training-ps-6fd0bbea02-2:2222'], 'worker': ['cmle-training-worker-6fd0bbea02-0:2222', 'cmle-training-worker-6fd0bbea02-1:2222', 'cmle-training-worker-6fd0bbea02-2:2222', 'cmle-training-worker-6fd0bbea02-3:2222'], 'master': ['cmle-training-master-6fd0bbea02-0:2222']}, 'task': {'index': 0, 'cloud': 'qe913eccfb8ab063b-ml', 'type': 'worker'}}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tUsing config: {'_is_chief': False, '_save_checkpoints_steps': 400, '_keep_checkpoint_every_n_hours': 1, '_keep_checkpoint_max': 5, '_service': None, '_save_summary_steps': 100, '_protocol': None, '_train_distribute': None, '_evaluation_master': '', '_save_checkpoints_secs': None, '_experimental_distribute': None, '_tf_random_seed': None, '_task_type': 'worker', '_num_ps_replicas': 3, '_model_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/', '_task_id': 0, '_log_step_count_steps': 100, '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tdevice_filters: \"/job:worker/task:0\"\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tallow_soft_placement: true\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tgraph_options {\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\t  rewrite_options {\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\t  }\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\t}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\t, '_eval_distribute': None, '_device_fn': None, '_num_worker_replicas': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fac5fe2fd30>, '_master': 'grpc://cmle-training-worker-6fd0bbea02-0:2222', '_global_id_in_cluster': 1}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tNot using Distribute Coordinator.\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tStart Tensorflow server.\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tCPU Frequency: 2300000000 Hz\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tXLA service 0x3f47950 executing computations on platform Host. Devices:\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\t  StreamExecutor device (0): <undefined>, <undefined>\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tInitialize GrpcChannelCache for job master -> {0 -> cmle-training-master-6fd0bbea02-0:2222}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tInitialize GrpcChannelCache for job ps -> {0 -> cmle-training-ps-6fd0bbea02-0:2222, 1 -> cmle-training-ps-6fd0bbea02-1:2222, 2 -> cmle-training-ps-6fd0bbea02-2:2222}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tInitialize GrpcChannelCache for job worker -> {0 -> localhost:2222, 1 -> cmle-training-worker-6fd0bbea02-1:2222, 2 -> cmle-training-worker-6fd0bbea02-2:2222, 3 -> cmle-training-worker-6fd0bbea02-3:2222}\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tStarted server with target: grpc://localhost:2222\n",
      "INFO\t2019-04-12 16:18:34 +0200\tworker-replica-0\t\tWaiting 5 secs before starting training.\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\t  Found existing installation: pkg-mnist-fnn 0.0.0\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\t    Uninstalling pkg-mnist-fnn-0.0.0:\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\t      Successfully uninstalled pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:34 +0200\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:34 +0200\tps-replica-1\t\tRunning command: python3 -m pkg_mnist_fnn.task --data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz --output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749 --train_steps=1000 --job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\n",
      "INFO\t2019-04-12 16:18:34 +0200\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:34 +0200\tmaster-replica-0\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:34 +0200\tmaster-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:35 +0200\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:35 +0200\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:35 +0200\tmaster-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:35 +0200\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:35 +0200\tmaster-replica-0\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:35 +0200\tmaster-replica-0\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:35 +0200\tmaster-replica-0\t\t  Found existing installation: pkg-mnist-fnn 0.0.0\n",
      "INFO\t2019-04-12 16:18:36 +0200\tmaster-replica-0\t\t    Uninstalling pkg-mnist-fnn-0.0.0:\n",
      "INFO\t2019-04-12 16:18:36 +0200\tmaster-replica-0\t\t      Successfully uninstalled pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:36 +0200\tmaster-replica-0\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:36 +0200\tmaster-replica-0\t\tRunning command: python3 -m pkg_mnist_fnn.task --data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz --output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749 --train_steps=1000 --job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\n",
      "INFO\t2019-04-12 16:18:36 +0200\tps-replica-2\t\tRunning task with arguments: --cluster={\"master\": [\"cmle-training-master-6fd0bbea02-0:2222\"], \"ps\": [\"cmle-training-ps-6fd0bbea02-0:2222\", \"cmle-training-ps-6fd0bbea02-1:2222\", \"cmle-training-ps-6fd0bbea02-2:2222\"], \"worker\": [\"cmle-training-worker-6fd0bbea02-0:2222\", \"cmle-training-worker-6fd0bbea02-1:2222\", \"cmle-training-worker-6fd0bbea02-2:2222\", \"cmle-training-worker-6fd0bbea02-3:2222\"]} --task={\"type\": \"ps\", \"index\": 2} --job={\n",
      "INFO\t2019-04-12 16:18:36 +0200\tps-replica-2\t\t  \"scale_tier\": \"STANDARD_1\",\n",
      "INFO\t2019-04-12 16:18:36 +0200\tps-replica-2\t\t  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\"],\n",
      "INFO\t2019-04-12 16:18:36 +0200\tps-replica-2\t\t  \"python_module\": \"pkg_mnist_fnn.task\",\n",
      "INFO\t2019-04-12 16:18:36 +0200\tps-replica-2\t\t  \"args\": [\"--data_path\\u003dgs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\", \"--output_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749\", \"--train_steps\\u003d1000\", \"--job_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\"],\n",
      "INFO\t2019-04-12 16:18:36 +0200\tps-replica-2\t\t  \"region\": \"europe-west1\",\n",
      "INFO\t2019-04-12 16:18:36 +0200\tps-replica-2\t\t  \"runtime_version\": \"1.13\",\n",
      "INFO\t2019-04-12 16:18:36 +0200\tps-replica-2\t\t  \"python_version\": \"3.5\"\n",
      "INFO\t2019-04-12 16:18:36 +0200\tps-replica-2\t\t}\n",
      "WARNING\t2019-04-12 16:18:36 +0200\tps-replica-2\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:36 +0200\tps-replica-2\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:36 +0200\tps-replica-2\t\tColocations handled automatically by placer.\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tTF_CONFIG environment variable: {'task': {'index': 1, 'cloud': 'qe913eccfb8ab063b-ml', 'type': 'ps'}, 'cluster': {'master': ['cmle-training-master-6fd0bbea02-0:2222'], 'ps': ['cmle-training-ps-6fd0bbea02-0:2222', 'cmle-training-ps-6fd0bbea02-1:2222', 'cmle-training-ps-6fd0bbea02-2:2222'], 'worker': ['cmle-training-worker-6fd0bbea02-0:2222', 'cmle-training-worker-6fd0bbea02-1:2222', 'cmle-training-worker-6fd0bbea02-2:2222', 'cmle-training-worker-6fd0bbea02-3:2222']}, 'environment': 'cloud', 'job': {'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz'], 'region': 'europe-west1', 'python_module': 'pkg_mnist_fnn.task', 'args': ['--data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', '--output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749', '--train_steps=1000', '--job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs'], 'runtime_version': '1.13', 'scale_tier': 'STANDARD_1', 'python_version': '3.5'}}\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tUsing config: {'_save_summary_steps': 100, '_model_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/', '_eval_distribute': None, '_log_step_count_steps': 100, '_task_id': 1, '_task_type': 'ps', '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tdevice_filters: \"/job:worker\"\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tdevice_filters: \"/job:chief\"\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tdevice_filters: \"/job:master\"\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tallow_soft_placement: true\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tgraph_options {\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\t  rewrite_options {\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\t  }\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\t}\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\t, '_keep_checkpoint_every_n_hours': 1, '_protocol': None, '_tf_random_seed': None, '_train_distribute': None, '_save_checkpoints_steps': 400, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc23ad2fe48>, '_num_ps_replicas': 3, '_experimental_distribute': None, '_evaluation_master': '', '_num_worker_replicas': 5, '_keep_checkpoint_max': 5, '_is_chief': False, '_device_fn': None, '_master': 'grpc://cmle-training-ps-6fd0bbea02-1:2222', '_global_id_in_cluster': 6, '_save_checkpoints_secs': None, '_service': None}\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tNot using Distribute Coordinator.\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tStart Tensorflow server.\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tCPU Frequency: 2300000000 Hz\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tXLA service 0x465af00 executing computations on platform Host. Devices:\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\t  StreamExecutor device (0): <undefined>, <undefined>\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tInitialize GrpcChannelCache for job master -> {0 -> cmle-training-master-6fd0bbea02-0:2222}\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tInitialize GrpcChannelCache for job ps -> {0 -> cmle-training-ps-6fd0bbea02-0:2222, 1 -> localhost:2222, 2 -> cmle-training-ps-6fd0bbea02-2:2222}\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tInitialize GrpcChannelCache for job worker -> {0 -> cmle-training-worker-6fd0bbea02-0:2222, 1 -> cmle-training-worker-6fd0bbea02-1:2222, 2 -> cmle-training-worker-6fd0bbea02-2:2222, 3 -> cmle-training-worker-6fd0bbea02-3:2222}\n",
      "INFO\t2019-04-12 16:18:37 +0200\tps-replica-1\t\tStarted server with target: grpc://localhost:2222\n",
      "INFO\t2019-04-12 16:18:38 +0200\tps-replica-2\t\tRunning module pkg_mnist_fnn.task.\n",
      "INFO\t2019-04-12 16:18:38 +0200\tps-replica-2\t\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:38 +0200\tps-replica-2\t\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tTF_CONFIG environment variable: {'cluster': {'ps': ['cmle-training-ps-6fd0bbea02-0:2222', 'cmle-training-ps-6fd0bbea02-1:2222', 'cmle-training-ps-6fd0bbea02-2:2222'], 'worker': ['cmle-training-worker-6fd0bbea02-0:2222', 'cmle-training-worker-6fd0bbea02-1:2222', 'cmle-training-worker-6fd0bbea02-2:2222', 'cmle-training-worker-6fd0bbea02-3:2222'], 'master': ['cmle-training-master-6fd0bbea02-0:2222']}, 'job': {'scale_tier': 'STANDARD_1', 'runtime_version': '1.13', 'args': ['--data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', '--output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749', '--train_steps=1000', '--job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs'], 'python_module': 'pkg_mnist_fnn.task', 'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz'], 'region': 'europe-west1', 'python_version': '3.5'}, 'task': {'cloud': 'qe913eccfb8ab063b-ml', 'index': 0, 'type': 'master'}, 'environment': 'cloud'}\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tUsing config: {'_protocol': None, '_num_ps_replicas': 3, '_keep_checkpoint_every_n_hours': 1, '_save_summary_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faa29ec3a20>, '_num_worker_replicas': 5, '_task_id': 0, '_evaluation_master': '', '_task_type': 'master', '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tdevice_filters: \"/job:master\"\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tallow_soft_placement: true\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tgraph_options {\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\t  rewrite_options {\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\t  }\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\t}\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\t, '_experimental_distribute': None, '_log_step_count_steps': 100, '_save_checkpoints_steps': 400, '_global_id_in_cluster': 0, '_eval_distribute': None, '_tf_random_seed': None, '_save_checkpoints_secs': None, '_device_fn': None, '_service': None, '_train_distribute': None, '_is_chief': True, '_keep_checkpoint_max': 5, '_model_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/', '_master': 'grpc://cmle-training-master-6fd0bbea02-0:2222'}\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tNot using Distribute Coordinator.\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tStart Tensorflow server.\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tCPU Frequency: 2300000000 Hz\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tXLA service 0x57d7a50 executing computations on platform Host. Devices:\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\t  StreamExecutor device (0): <undefined>, <undefined>\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tInitialize GrpcChannelCache for job master -> {0 -> localhost:2222}\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tInitialize GrpcChannelCache for job ps -> {0 -> cmle-training-ps-6fd0bbea02-0:2222, 1 -> cmle-training-ps-6fd0bbea02-1:2222, 2 -> cmle-training-ps-6fd0bbea02-2:2222}\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tInitialize GrpcChannelCache for job worker -> {0 -> cmle-training-worker-6fd0bbea02-0:2222, 1 -> cmle-training-worker-6fd0bbea02-1:2222, 2 -> cmle-training-worker-6fd0bbea02-2:2222, 3 -> cmle-training-worker-6fd0bbea02-3:2222}\n",
      "INFO\t2019-04-12 16:18:39 +0200\tmaster-replica-0\t\tStarted server with target: grpc://localhost:2222\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tColocations handled automatically by placer.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tenqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tenqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tCalling model_fn.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tUse tf.cast instead.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:39 +0200\tworker-replica-0\t\tPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-2\t\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-2\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps pkg_mnist_fnn-0.0.0.tar.gz\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tColocations handled automatically by placer.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tenqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tenqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tCalling model_fn.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tUse tf.cast instead.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO\t2019-04-12 16:18:40 +0200\tworker-replica-0\t\tDone calling model_fn.\n",
      "INFO\t2019-04-12 16:18:40 +0200\tworker-replica-0\t\tCreate CheckpointSaverHook.\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-2\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-0\t\tRunning task with arguments: --cluster={\"master\": [\"cmle-training-master-6fd0bbea02-0:2222\"], \"ps\": [\"cmle-training-ps-6fd0bbea02-0:2222\", \"cmle-training-ps-6fd0bbea02-1:2222\", \"cmle-training-ps-6fd0bbea02-2:2222\"], \"worker\": [\"cmle-training-worker-6fd0bbea02-0:2222\", \"cmle-training-worker-6fd0bbea02-1:2222\", \"cmle-training-worker-6fd0bbea02-2:2222\", \"cmle-training-worker-6fd0bbea02-3:2222\"]} --task={\"type\": \"ps\", \"index\": 0} --job={\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-0\t\t  \"scale_tier\": \"STANDARD_1\",\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-0\t\t  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\"],\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-0\t\t  \"python_module\": \"pkg_mnist_fnn.task\",\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-0\t\t  \"args\": [\"--data_path\\u003dgs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\", \"--output_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749\", \"--train_steps\\u003d1000\", \"--job_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\"],\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-0\t\t  \"region\": \"europe-west1\",\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-0\t\t  \"runtime_version\": \"1.13\",\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-0\t\t  \"python_version\": \"3.5\"\n",
      "INFO\t2019-04-12 16:18:40 +0200\tps-replica-0\t\t}\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tps-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tps-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:40 +0200\tps-replica-0\t\tColocations handled automatically by placer.\n",
      "INFO\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tDone calling model_fn.\n",
      "INFO\t2019-04-12 16:18:40 +0200\tmaster-replica-0\t\tCreate CheckpointSaverHook.\n",
      "INFO\t2019-04-12 16:18:41 +0200\tps-replica-2\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:41 +0200\tps-replica-2\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:41 +0200\tps-replica-2\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:41 +0200\tps-replica-2\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:42 +0200\tps-replica-0\t\tRunning module pkg_mnist_fnn.task.\n",
      "INFO\t2019-04-12 16:18:42 +0200\tps-replica-0\t\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:42 +0200\tps-replica-0\t\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\tRunning task with arguments: --cluster={\"master\": [\"cmle-training-master-6fd0bbea02-0:2222\"], \"ps\": [\"cmle-training-ps-6fd0bbea02-0:2222\", \"cmle-training-ps-6fd0bbea02-1:2222\", \"cmle-training-ps-6fd0bbea02-2:2222\"], \"worker\": [\"cmle-training-worker-6fd0bbea02-0:2222\", \"cmle-training-worker-6fd0bbea02-1:2222\", \"cmle-training-worker-6fd0bbea02-2:2222\", \"cmle-training-worker-6fd0bbea02-3:2222\"]} --task={\"type\": \"worker\", \"index\": 3} --job={\n",
      "INFO\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\t  \"scale_tier\": \"STANDARD_1\",\n",
      "INFO\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\t  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\"],\n",
      "INFO\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\t  \"python_module\": \"pkg_mnist_fnn.task\",\n",
      "INFO\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\t  \"args\": [\"--data_path\\u003dgs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\", \"--output_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749\", \"--train_steps\\u003d1000\", \"--job_dir\\u003dgs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\"],\n",
      "INFO\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\t  \"region\": \"europe-west1\",\n",
      "INFO\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\t  \"runtime_version\": \"1.13\",\n",
      "INFO\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\t  \"python_version\": \"3.5\"\n",
      "INFO\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\t}\n",
      "WARNING\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:42 +0200\tworker-replica-3\t\tColocations handled automatically by placer.\n",
      "INFO\t2019-04-12 16:18:42 +0200\tps-replica-2\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:42 +0200\tps-replica-2\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:42 +0200\tworker-replica-0\t\tGraph was finalized.\n",
      "INFO\t2019-04-12 16:18:43 +0200\tps-replica-2\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:43 +0200\tps-replica-2\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:43 +0200\tps-replica-2\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:43 +0200\tps-replica-2\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:43 +0200\tps-replica-2\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:43 +0200\tmaster-replica-0\t\tGraph was finalized.\n",
      "INFO\t2019-04-12 16:18:43 +0200\tps-replica-2\t\tRunning command: pip3 install --user pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:43 +0200\tworker-replica-3\t\tRunning module pkg_mnist_fnn.task.\n",
      "INFO\t2019-04-12 16:18:43 +0200\tworker-replica-3\t\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:43 +0200\tworker-replica-3\t\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:43 +0200\tps-replica-2\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:43 +0200\tps-replica-0\t\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:43 +0200\tps-replica-0\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:44 +0200\tps-replica-2\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:44 +0200\tps-replica-2\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:44 +0200\tps-replica-2\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:44 +0200\tps-replica-2\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:44 +0200\tps-replica-0\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:44 +0200\tps-replica-2\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:44 +0200\tps-replica-2\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tColocations handled automatically by placer.\n",
      "INFO\t2019-04-12 16:18:44 +0200\tps-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tenqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tenqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tCalling model_fn.\n",
      "INFO\t2019-04-12 16:18:44 +0200\tps-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tUse tf.cast instead.\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:18:44 +0200\tworker-replica-1\t\tPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-0\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-2\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-2\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-2\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-0\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-0\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-0\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:45 +0200\tworker-replica-1\t\tDone calling model_fn.\n",
      "INFO\t2019-04-12 16:18:45 +0200\tworker-replica-1\t\tCreate CheckpointSaverHook.\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-2\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-2\t\t  Found existing installation: pkg-mnist-fnn 0.0.0\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-2\t\t    Uninstalling pkg-mnist-fnn-0.0.0:\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-2\t\t      Successfully uninstalled pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:45 +0200\tworker-replica-3\t\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:45 +0200\tworker-replica-3\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-2\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-0\t\tRunning command: pip3 install --user pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:45 +0200\tworker-replica-1\t\tGraph was finalized.\n",
      "INFO\t2019-04-12 16:18:45 +0200\tps-replica-2\t\tRunning command: python3 -m pkg_mnist_fnn.task --data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz --output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749 --train_steps=1000 --job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\n",
      "INFO\t2019-04-12 16:18:46 +0200\tworker-replica-3\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:46 +0200\tps-replica-0\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:46 +0200\tworker-replica-3\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:46 +0200\tworker-replica-3\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:46 +0200\tworker-replica-3\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:46 +0200\tworker-replica-3\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:46 +0200\tps-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:46 +0200\tps-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:46 +0200\tps-replica-0\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:46 +0200\tps-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:46 +0200\tworker-replica-3\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:46 +0200\tworker-replica-3\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:47 +0200\tworker-replica-3\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:47 +0200\tworker-replica-3\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:47 +0200\tworker-replica-3\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:47 +0200\tworker-replica-3\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:47 +0200\tworker-replica-3\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:47 +0200\tps-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:47 +0200\tps-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:47 +0200\tworker-replica-3\t\tRunning command: pip3 install --user pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:47 +0200\tps-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:47 +0200\tps-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:47 +0200\tps-replica-0\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:47 +0200\tps-replica-0\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:47 +0200\tps-replica-0\t\t  Found existing installation: pkg-mnist-fnn 0.0.0\n",
      "INFO\t2019-04-12 16:18:47 +0200\tps-replica-0\t\t    Uninstalling pkg-mnist-fnn-0.0.0:\n",
      "INFO\t2019-04-12 16:18:47 +0200\tps-replica-0\t\t      Successfully uninstalled pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:47 +0200\tps-replica-0\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:47 +0200\tworker-replica-3\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-04-12 16:18:48 +0200\tps-replica-0\t\tRunning command: python3 -m pkg_mnist_fnn.task --data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz --output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749 --train_steps=1000 --job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\n",
      "INFO\t2019-04-12 16:18:48 +0200\tworker-replica-3\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:48 +0200\tworker-replica-3\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:48 +0200\tworker-replica-3\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:48 +0200\tworker-replica-3\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-04-12 16:18:48 +0200\tworker-replica-3\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-04-12 16:18:48 +0200\tworker-replica-3\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-04-12 16:18:48 +0200\tworker-replica-3\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-04-12 16:18:48 +0200\tworker-replica-3\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-04-12 16:18:48 +0200\tworker-replica-3\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:49 +0200\tworker-replica-3\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-04-12 16:18:49 +0200\tworker-replica-3\t\t  Found existing installation: pkg-mnist-fnn 0.0.0\n",
      "INFO\t2019-04-12 16:18:49 +0200\tworker-replica-3\t\t    Uninstalling pkg-mnist-fnn-0.0.0:\n",
      "INFO\t2019-04-12 16:18:49 +0200\tworker-replica-3\t\t      Successfully uninstalled pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:49 +0200\tworker-replica-3\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-04-12 16:18:49 +0200\tworker-replica-3\t\tRunning command: python3 -m pkg_mnist_fnn.task --data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz --output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749 --train_steps=1000 --job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tTF_CONFIG environment variable: {'task': {'index': 2, 'type': 'ps', 'cloud': 'qe913eccfb8ab063b-ml'}, 'environment': 'cloud', 'cluster': {'worker': ['cmle-training-worker-6fd0bbea02-0:2222', 'cmle-training-worker-6fd0bbea02-1:2222', 'cmle-training-worker-6fd0bbea02-2:2222', 'cmle-training-worker-6fd0bbea02-3:2222'], 'ps': ['cmle-training-ps-6fd0bbea02-0:2222', 'cmle-training-ps-6fd0bbea02-1:2222', 'cmle-training-ps-6fd0bbea02-2:2222'], 'master': ['cmle-training-master-6fd0bbea02-0:2222']}, 'job': {'python_version': '3.5', 'python_module': 'pkg_mnist_fnn.task', 'scale_tier': 'STANDARD_1', 'runtime_version': '1.13', 'region': 'europe-west1', 'args': ['--data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', '--output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749', '--train_steps=1000', '--job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs'], 'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz']}}\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tUsing config: {'_num_ps_replicas': 3, '_num_worker_replicas': 5, '_is_chief': False, '_save_checkpoints_secs': None, '_save_checkpoints_steps': 400, '_master': 'grpc://cmle-training-ps-6fd0bbea02-2:2222', '_model_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/', '_device_fn': None, '_protocol': None, '_evaluation_master': '', '_experimental_distribute': None, '_eval_distribute': None, '_keep_checkpoint_every_n_hours': 1, '_global_id_in_cluster': 7, '_task_id': 2, '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8a490a47f0>, '_save_summary_steps': 100, '_service': None, '_train_distribute': None, '_tf_random_seed': None, '_log_step_count_steps': 100, '_task_type': 'ps', '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tdevice_filters: \"/job:worker\"\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tdevice_filters: \"/job:chief\"\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tdevice_filters: \"/job:master\"\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tallow_soft_placement: true\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tgraph_options {\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\t  rewrite_options {\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\t  }\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\t}\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\t}\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tNot using Distribute Coordinator.\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tStart Tensorflow server.\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tCPU Frequency: 2300000000 Hz\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tXLA service 0x3d43390 executing computations on platform Host. Devices:\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\t  StreamExecutor device (0): <undefined>, <undefined>\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tInitialize GrpcChannelCache for job master -> {0 -> cmle-training-master-6fd0bbea02-0:2222}\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tInitialize GrpcChannelCache for job ps -> {0 -> cmle-training-ps-6fd0bbea02-0:2222, 1 -> cmle-training-ps-6fd0bbea02-1:2222, 2 -> localhost:2222}\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tInitialize GrpcChannelCache for job worker -> {0 -> cmle-training-worker-6fd0bbea02-0:2222, 1 -> cmle-training-worker-6fd0bbea02-1:2222, 2 -> cmle-training-worker-6fd0bbea02-2:2222, 3 -> cmle-training-worker-6fd0bbea02-3:2222}\n",
      "INFO\t2019-04-12 16:18:49 +0200\tps-replica-2\t\tStarted server with target: grpc://localhost:2222\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tTF_CONFIG environment variable: {'task': {'cloud': 'qe913eccfb8ab063b-ml', 'index': 0, 'type': 'ps'}, 'cluster': {'worker': ['cmle-training-worker-6fd0bbea02-0:2222', 'cmle-training-worker-6fd0bbea02-1:2222', 'cmle-training-worker-6fd0bbea02-2:2222', 'cmle-training-worker-6fd0bbea02-3:2222'], 'ps': ['cmle-training-ps-6fd0bbea02-0:2222', 'cmle-training-ps-6fd0bbea02-1:2222', 'cmle-training-ps-6fd0bbea02-2:2222'], 'master': ['cmle-training-master-6fd0bbea02-0:2222']}, 'job': {'args': ['--data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', '--output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749', '--train_steps=1000', '--job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs'], 'region': 'europe-west1', 'runtime_version': '1.13', 'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz'], 'python_module': 'pkg_mnist_fnn.task', 'scale_tier': 'STANDARD_1', 'python_version': '3.5'}, 'environment': 'cloud'}\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tUsing config: {'_master': 'grpc://cmle-training-ps-6fd0bbea02-0:2222', '_num_worker_replicas': 5, '_task_id': 0, '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tdevice_filters: \"/job:worker\"\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tdevice_filters: \"/job:chief\"\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tdevice_filters: \"/job:master\"\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tallow_soft_placement: true\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tgraph_options {\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\t  rewrite_options {\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\t  }\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\t}\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\t, '_task_type': 'ps', '_service': None, '_keep_checkpoint_every_n_hours': 1, '_save_summary_steps': 100, '_eval_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7feef75ffbe0>, '_evaluation_master': '', '_save_checkpoints_secs': None, '_train_distribute': None, '_log_step_count_steps': 100, '_is_chief': False, '_save_checkpoints_steps': 400, '_device_fn': None, '_experimental_distribute': None, '_global_id_in_cluster': 5, '_tf_random_seed': None, '_num_ps_replicas': 3, '_keep_checkpoint_max': 5, '_protocol': None, '_model_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/'}\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tNot using Distribute Coordinator.\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tStart Tensorflow server.\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tCPU Frequency: 2300000000 Hz\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tXLA service 0x55536d0 executing computations on platform Host. Devices:\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\t  StreamExecutor device (0): <undefined>, <undefined>\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tInitialize GrpcChannelCache for job master -> {0 -> cmle-training-master-6fd0bbea02-0:2222}\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tInitialize GrpcChannelCache for job ps -> {0 -> localhost:2222, 1 -> cmle-training-ps-6fd0bbea02-1:2222, 2 -> cmle-training-ps-6fd0bbea02-2:2222}\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tInitialize GrpcChannelCache for job worker -> {0 -> cmle-training-worker-6fd0bbea02-0:2222, 1 -> cmle-training-worker-6fd0bbea02-1:2222, 2 -> cmle-training-worker-6fd0bbea02-2:2222, 3 -> cmle-training-worker-6fd0bbea02-3:2222}\n",
      "INFO\t2019-04-12 16:18:51 +0200\tps-replica-0\t\tStarted server with target: grpc://localhost:2222\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tTF_CONFIG environment variable: {'job': {'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190412_153749/d6bd0ee1b20bb83619a7dfa465bb48426b64d8203319f0c5e3ac4a716292df0a/pkg_mnist_fnn-0.0.0.tar.gz'], 'region': 'europe-west1', 'python_module': 'pkg_mnist_fnn.task', 'args': ['--data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', '--output_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749', '--train_steps=1000', '--job_dir=gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs'], 'python_version': '3.5', 'runtime_version': '1.13', 'scale_tier': 'STANDARD_1'}, 'environment': 'cloud', 'cluster': {'master': ['cmle-training-master-6fd0bbea02-0:2222'], 'ps': ['cmle-training-ps-6fd0bbea02-0:2222', 'cmle-training-ps-6fd0bbea02-1:2222', 'cmle-training-ps-6fd0bbea02-2:2222'], 'worker': ['cmle-training-worker-6fd0bbea02-0:2222', 'cmle-training-worker-6fd0bbea02-1:2222', 'cmle-training-worker-6fd0bbea02-2:2222', 'cmle-training-worker-6fd0bbea02-3:2222']}, 'task': {'cloud': 'qe913eccfb8ab063b-ml', 'type': 'worker', 'index': 3}}\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tUsing config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4898bfab38>, '_eval_distribute': None, '_model_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/', '_tf_random_seed': None, '_num_ps_replicas': 3, '_protocol': None, '_num_worker_replicas': 5, '_train_distribute': None, '_task_type': 'worker', '_service': None, '_global_id_in_cluster': 4, '_keep_checkpoint_every_n_hours': 1, '_task_id': 3, '_evaluation_master': '', '_log_step_count_steps': 100, '_experimental_distribute': None, '_is_chief': False, '_save_checkpoints_secs': None, '_master': 'grpc://cmle-training-worker-6fd0bbea02-3:2222', '_keep_checkpoint_max': 5, '_device_fn': None, '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tdevice_filters: \"/job:worker/task:3\"\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tallow_soft_placement: true\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tgraph_options {\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\t  rewrite_options {\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\t  }\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\t}\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\t, '_save_summary_steps': 100, '_save_checkpoints_steps': 400}\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tNot using Distribute Coordinator.\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tStart Tensorflow server.\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tCPU Frequency: 2300000000 Hz\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tXLA service 0x3fd8090 executing computations on platform Host. Devices:\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\t  StreamExecutor device (0): <undefined>, <undefined>\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tInitialize GrpcChannelCache for job master -> {0 -> cmle-training-master-6fd0bbea02-0:2222}\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tInitialize GrpcChannelCache for job ps -> {0 -> cmle-training-ps-6fd0bbea02-0:2222, 1 -> cmle-training-ps-6fd0bbea02-1:2222, 2 -> cmle-training-ps-6fd0bbea02-2:2222}\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tInitialize GrpcChannelCache for job worker -> {0 -> cmle-training-worker-6fd0bbea02-0:2222, 1 -> cmle-training-worker-6fd0bbea02-1:2222, 2 -> cmle-training-worker-6fd0bbea02-2:2222, 3 -> localhost:2222}\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tStarted server with target: grpc://localhost:2222\n",
      "INFO\t2019-04-12 16:18:52 +0200\tworker-replica-3\t\tWaiting 20 secs before starting training.\n",
      "INFO\t2019-04-12 16:18:55 +0200\tworker-replica-1\t\tCreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n",
      "INFO\t2019-04-12 16:18:55 +0200\tworker-replica-1\t\tCreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "INFO\t2019-04-12 16:18:56 +0200\tworker-replica-0\t\tCreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n",
      "INFO\t2019-04-12 16:18:56 +0200\tworker-replica-0\t\tCreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "INFO\t2019-04-12 16:19:04 +0200\tmaster-replica-0\t\tCreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n",
      "INFO\t2019-04-12 16:19:04 +0200\tmaster-replica-0\t\tCreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "INFO\t2019-04-12 16:19:05 +0200\tworker-replica-1\t\tCreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "INFO\t2019-04-12 16:19:06 +0200\tworker-replica-0\t\tCreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tColocations handled automatically by placer.\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tenqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tenqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:19:12 +0200\tworker-replica-3\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-04-12 16:19:13 +0200\tworker-replica-3\t\tCalling model_fn.\n",
      "WARNING\t2019-04-12 16:19:13 +0200\tworker-replica-3\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:19:13 +0200\tworker-replica-3\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:19:13 +0200\tworker-replica-3\t\tUse tf.cast instead.\n",
      "WARNING\t2019-04-12 16:19:13 +0200\tworker-replica-3\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:19:13 +0200\tworker-replica-3\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:19:13 +0200\tworker-replica-3\t\tPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO\t2019-04-12 16:19:13 +0200\tworker-replica-3\t\tDone calling model_fn.\n",
      "INFO\t2019-04-12 16:19:13 +0200\tworker-replica-3\t\tCreate CheckpointSaverHook.\n",
      "INFO\t2019-04-12 16:19:13 +0200\tworker-replica-3\t\tGraph was finalized.\n",
      "INFO\t2019-04-12 16:19:14 +0200\tmaster-replica-0\t\tCreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "INFO\t2019-04-12 16:19:14 +0200\tmaster-replica-0\t\tStart master session 2a25f093cd1877cd with config: device_filters: \"/job:ps\" device_filters: \"/job:master\" gpu_options { } allow_soft_placement: true graph_options { rewrite_options { meta_optimizer_iterations: ONE } }\n",
      "INFO\t2019-04-12 16:19:14 +0200\tworker-replica-1\t\tStart master session 8c0509f64cefc812 with config: device_filters: \"/job:ps\" device_filters: \"/job:worker/task:1\" gpu_options { } allow_soft_placement: true graph_options { rewrite_options { meta_optimizer_iterations: ONE } }\n",
      "INFO\t2019-04-12 16:19:14 +0200\tmaster-replica-0\t\tRunning local_init_op.\n",
      "INFO\t2019-04-12 16:19:14 +0200\tworker-replica-1\t\tRunning local_init_op.\n",
      "INFO\t2019-04-12 16:19:14 +0200\tmaster-replica-0\t\tDone running local_init_op.\n",
      "INFO\t2019-04-12 16:19:14 +0200\tworker-replica-3\t\tStart master session 11710010415a2106 with config: device_filters: \"/job:ps\" device_filters: \"/job:worker/task:3\" gpu_options { } allow_soft_placement: true graph_options { rewrite_options { meta_optimizer_iterations: ONE } }\n",
      "INFO\t2019-04-12 16:19:14 +0200\tworker-replica-1\t\tDone running local_init_op.\n",
      "WARNING\t2019-04-12 16:19:14 +0200\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:19:14 +0200\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:19:14 +0200\tmaster-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "WARNING\t2019-04-12 16:19:15 +0200\tworker-replica-1\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:19:15 +0200\tworker-replica-1\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:19:15 +0200\tworker-replica-1\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-04-12 16:19:15 +0200\tworker-replica-0\t\tStart master session 2e2cf98c9665ece2 with config: device_filters: \"/job:ps\" device_filters: \"/job:worker/task:0\" gpu_options { } allow_soft_placement: true graph_options { rewrite_options { meta_optimizer_iterations: ONE } }\n",
      "INFO\t2019-04-12 16:19:15 +0200\tworker-replica-3\t\tRunning local_init_op.\n",
      "INFO\t2019-04-12 16:19:15 +0200\tworker-replica-3\t\tDone running local_init_op.\n",
      "INFO\t2019-04-12 16:19:15 +0200\tworker-replica-0\t\tRunning local_init_op.\n",
      "WARNING\t2019-04-12 16:19:15 +0200\tworker-replica-3\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:19:15 +0200\tworker-replica-3\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:19:15 +0200\tworker-replica-3\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-04-12 16:19:15 +0200\tworker-replica-0\t\tDone running local_init_op.\n",
      "WARNING\t2019-04-12 16:19:15 +0200\tworker-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:19:15 +0200\tworker-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:19:15 +0200\tworker-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-04-12 16:19:15 +0200\tworker-replica-1\t\tloss = 6070.0254, step = 0\n",
      "INFO\t2019-04-12 16:19:15 +0200\tworker-replica-3\t\tloss = 4008.1248, step = 1\n",
      "INFO\t2019-04-12 16:19:15 +0200\tworker-replica-0\t\tloss = 1838.0073, step = 7\n",
      "INFO\t2019-04-12 16:19:15 +0200\tworker-replica-0\t\tglobal_step/sec: 262.216\n",
      "INFO\t2019-04-12 16:19:16 +0200\tworker-replica-1\t\tloss = 306.47083, step = 221 (0.975 sec)\n",
      "INFO\t2019-04-12 16:19:16 +0200\tworker-replica-0\t\tglobal_step/sec: 311.923\n",
      "INFO\t2019-04-12 16:19:16 +0200\tworker-replica-3\t\tloss = 306.78598, step = 297 (1.109 sec)\n",
      "INFO\t2019-04-12 16:19:16 +0200\tworker-replica-0\t\tglobal_step/sec: 307.463\n",
      "INFO\t2019-04-12 16:19:16 +0200\tworker-replica-0\t\tloss = 293.81055, step = 439 (1.526 sec)\n",
      "INFO\t2019-04-12 16:19:16 +0200\tworker-replica-0\t\tglobal_step/sec: 288.177\n",
      "INFO\t2019-04-12 16:19:16 +0200\tworker-replica-1\t\tloss = 310.63556, step = 468 (0.826 sec)\n",
      "INFO\t2019-04-12 16:19:17 +0200\tworker-replica-0\t\tglobal_step/sec: 314.457\n",
      "INFO\t2019-04-12 16:19:17 +0200\tworker-replica-3\t\tloss = 294.56342, step = 587 (0.962 sec)\n",
      "INFO\t2019-04-12 16:19:17 +0200\tworker-replica-0\t\tglobal_step/sec: 315.897\n",
      "INFO\t2019-04-12 16:19:17 +0200\tworker-replica-1\t\tloss = 282.3244, step = 731 (0.840 sec)\n",
      "INFO\t2019-04-12 16:19:17 +0200\tworker-replica-0\t\tglobal_step/sec: 317.1\n",
      "INFO\t2019-04-12 16:19:17 +0200\tworker-replica-0\t\tloss = 277.44867, step = 789 (1.106 sec)\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-0\t\tglobal_step/sec: 292.684\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\tloss = 274.37057, step = 887 (0.975 sec)\n",
      "INFO\t2019-04-12 16:19:18 +0200\tmaster-replica-0\t\tSaving checkpoints for 0 into gs://ml-productive-pipeline-53122/mnist_190412_153749/model.ckpt.\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-0\t\tglobal_step/sec: 323.354\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\tloss = 257.42102, step = 991 (0.832 sec)\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\tLoss for final step: 295.44537.\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\tArguments:\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\t{'min_eval_frequency': 5, 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749', 'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs', 'train_steps': 1000, 'eval_delay_secs': 1, 'train_batch_size': 128, 'hidden_units': '128 32 4', 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz'}\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\tArguments:\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\t{'min_eval_frequency': 5, 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749', 'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs', 'train_steps': 1000, 'eval_delay_secs': 1, 'train_batch_size': 128, 'hidden_units': [128, 32, 4], 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz'}\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\tSave output to: gs://ml-productive-pipeline-53122/mnist_190412_153749/\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\t## load data, specified path to try: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\tLoaded data from gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\t## start training and evaluation\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-3\t\t### save model, ckpts, etc. to: gs://ml-productive-pipeline-53122/mnist_190412_153749/\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\tLoss for final step: 261.01215.\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\tArguments:\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\t{'train_batch_size': 128, 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'min_eval_frequency': 5, 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749', 'train_steps': 1000, 'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs', 'hidden_units': '128 32 4', 'eval_delay_secs': 1}\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\tArguments:\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\t{'train_batch_size': 128, 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'min_eval_frequency': 5, 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749', 'train_steps': 1000, 'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs', 'hidden_units': [128, 32, 4], 'eval_delay_secs': 1}\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\tSave output to: gs://ml-productive-pipeline-53122/mnist_190412_153749/\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\t## load data, specified path to try: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\tLoaded data from gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\t## start training and evaluation\n",
      "INFO\t2019-04-12 16:19:18 +0200\tworker-replica-1\t\t### save model, ckpts, etc. to: gs://ml-productive-pipeline-53122/mnist_190412_153749/\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-3\t\tModule completed; cleaning up.\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-3\t\tClean up finished.\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-3\t\tTask completed successfully.\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-1\t\tModule completed; cleaning up.\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-1\t\tClean up finished.\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-1\t\tTask completed successfully.\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-0\t\tLoss for final step: 292.49524.\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-0\t\tArguments:\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-0\t\t{'train_steps': 1000, 'hidden_units': '128 32 4', 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'min_eval_frequency': 5, 'eval_delay_secs': 1, 'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs', 'train_batch_size': 128, 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749'}\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-0\t\tArguments:\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-0\t\t{'train_steps': 1000, 'hidden_units': [128, 32, 4], 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'min_eval_frequency': 5, 'eval_delay_secs': 1, 'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs', 'train_batch_size': 128, 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749'}\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-0\t\tSave output to: gs://ml-productive-pipeline-53122/mnist_190412_153749/\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-0\t\t## load data, specified path to try: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-0\t\tLoaded data from gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-0\t\t## start training and evaluation\n",
      "INFO\t2019-04-12 16:19:19 +0200\tworker-replica-0\t\t### save model, ckpts, etc. to: gs://ml-productive-pipeline-53122/mnist_190412_153749/\n",
      "INFO\t2019-04-12 16:19:20 +0200\tworker-replica-0\t\tModule completed; cleaning up.\n",
      "INFO\t2019-04-12 16:19:20 +0200\tworker-replica-0\t\tClean up finished.\n",
      "INFO\t2019-04-12 16:19:20 +0200\tworker-replica-0\t\tTask completed successfully.\n",
      "INFO\t2019-04-12 16:19:40 +0200\tmaster-replica-0\t\tSaving checkpoints for 1005 into gs://ml-productive-pipeline-53122/mnist_190412_153749/model.ckpt.\n",
      "INFO\t2019-04-12 16:20:02 +0200\tmaster-replica-0\t\tCalling model_fn.\n",
      "INFO\t2019-04-12 16:20:02 +0200\tmaster-replica-0\t\tDone calling model_fn.\n",
      "INFO\t2019-04-12 16:20:02 +0200\tmaster-replica-0\t\tStarting evaluation at 2019-04-12T14:20:02Z\n",
      "INFO\t2019-04-12 16:20:02 +0200\tmaster-replica-0\t\tGraph was finalized.\n",
      "WARNING\t2019-04-12 16:20:02 +0200\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:20:02 +0200\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:20:02 +0200\tmaster-replica-0\t\tUse standard file APIs to check for files with this prefix.\n",
      "INFO\t2019-04-12 16:20:02 +0200\tmaster-replica-0\t\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190412_153749/model.ckpt-1005\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tRunning local_init_op.\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tDone running local_init_op.\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tEvaluation [10/100]\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tEvaluation [20/100]\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tEvaluation [30/100]\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tEvaluation [40/100]\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tEvaluation [50/100]\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tEvaluation [60/100]\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tEvaluation [70/100]\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tFinished evaluation at 2019-04-12-14:20:06\n",
      "INFO\t2019-04-12 16:20:06 +0200\tmaster-replica-0\t\tSaving dict for global step 1005: accuracy = 0.2071, average_loss = 1.9944633, global_step = 1005, loss = 252.4637\n",
      "INFO\t2019-04-12 16:20:10 +0200\tmaster-replica-0\t\tSaving 'checkpoint_path' summary for global step 1005: gs://ml-productive-pipeline-53122/mnist_190412_153749/model.ckpt-1005\n",
      "INFO\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tCalling model_fn.\n",
      "INFO\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tDone calling model_fn.\n",
      "WARNING\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-04-12 16:20:15 +0200\tmaster-replica-0\t\tExport includes no default signature!\n",
      "INFO\t2019-04-12 16:20:16 +0200\tmaster-replica-0\t\tRestoring parameters from gs://ml-productive-pipeline-53122/mnist_190412_153749/model.ckpt-1005\n",
      "INFO\t2019-04-12 16:20:17 +0200\tmaster-replica-0\t\tAssets added to graph.\n",
      "INFO\t2019-04-12 16:20:17 +0200\tmaster-replica-0\t\tNo assets to write.\n",
      "INFO\t2019-04-12 16:20:31 +0200\tmaster-replica-0\t\tSavedModel written to: gs://ml-productive-pipeline-53122/mnist_190412_153749/export/exporter/temp-b'1555078811'/saved_model.pb\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\tloss = 268.05585, step = 1004\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\tLoss for final step: 268.05585.\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\tArguments:\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\t{'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs', 'eval_delay_secs': 1, 'min_eval_frequency': 5, 'train_steps': 1000, 'train_batch_size': 128, 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'hidden_units': '128 32 4', 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749'}\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\tArguments:\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\t{'job_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749/jobs', 'eval_delay_secs': 1, 'min_eval_frequency': 5, 'train_steps': 1000, 'train_batch_size': 128, 'data_path': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz', 'hidden_units': [128, 32, 4], 'output_dir': 'gs://ml-productive-pipeline-53122/mnist_190412_153749'}\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\tSave output to: gs://ml-productive-pipeline-53122/mnist_190412_153749/\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\t## load data, specified path to try: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\tLoaded data from gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\t## start training and evaluation\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\t### save model, ckpts, etc. to: gs://ml-productive-pipeline-53122/mnist_190412_153749/\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\tModule completed; cleaning up.\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\tClean up finished.\n",
      "INFO\t2019-04-12 16:20:37 +0200\tmaster-replica-0\t\tTask completed successfully.\n",
      "INFO\t2019-04-12 16:20:53 +0200\tservice\t\tTearing down training program.\n",
      "INFO\t2019-04-12 16:20:55 +0200\tps-replica-0\t\tTerminated by service. If the job is supposed to continue running, it will be restarted on other VM shortly.\n",
      "INFO\t2019-04-12 16:20:55 +0200\tps-replica-0\t\tModule completed; cleaning up.\n",
      "INFO\t2019-04-12 16:20:55 +0200\tps-replica-0\t\tClean up finished.\n",
      "INFO\t2019-04-12 16:20:55 +0200\tps-replica-1\t\tTerminated by service. If the job is supposed to continue running, it will be restarted on other VM shortly.\n",
      "INFO\t2019-04-12 16:20:55 +0200\tps-replica-1\t\tModule completed; cleaning up.\n",
      "INFO\t2019-04-12 16:20:55 +0200\tps-replica-1\t\tClean up finished.\n",
      "INFO\t2019-04-12 16:20:55 +0200\tps-replica-2\t\tTerminated by service. If the job is supposed to continue running, it will be restarted on other VM shortly.\n",
      "INFO\t2019-04-12 16:20:55 +0200\tps-replica-2\t\tModule completed; cleaning up.\n",
      "INFO\t2019-04-12 16:20:55 +0200\tps-replica-2\t\tClean up finished.\n",
      "INFO\t2019-04-12 16:21:47 +0200\tservice\t\tFinished tearing down training program.\n",
      "INFO\t2019-04-12 16:21:48 +0200\tservice\t\tJob completed successfully.\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine jobs stream-logs %JOBNAME%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Don't be concerned if the notebook appears stalled (with a blue progress bar) or returns with an error about being unable to refresh auth tokens. This is a long-lived Cloud job and work is going on in the cloud. \n",
    "\n",
    "**Use the Cloud Console link to monitor the job and do NOT proceed until the job is done.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Check out results in the logs, see [example](https://cloud.google.com/solutions/machine-learning/recommendation-system-tensorflow-train-cloud-ml-engine#results_of_tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ML-Engine with Hyperparameter search\n",
    "- Bayesian approach to find optimal hyperparameters, see \n",
    "    > Golovin et.al (2017): Google Vizier: A Service for Black-Box Optimization\n",
    "- consecutive search, here\n",
    "    - 2 trials in parallel\n",
    "    - a total of 30 trials\n",
    "- see `hyperp_config.yaml`:\n",
    "    - `train_batch_size`\n",
    "    - `hidden_units`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Configure Search in  `hyperp_config.yaml`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hyperp_config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile hyperp_config.yaml\n",
    "trainingInput:\n",
    "  scaleTier: STANDARD_1\n",
    "  hyperparameters:\n",
    "    goal: MAXIMIZE\n",
    "    hyperparameterMetricTag: accuracy\n",
    "    maxTrials: 30\n",
    "    maxParallelTrials: 2\n",
    "    params:\n",
    "      - parameterName: train_batch_size\n",
    "        type: INTEGER\n",
    "        minValue: 64\n",
    "        maxValue: 512\n",
    "        scaleType: UNIT_LOG_SCALE\n",
    "      - parameterName: hidden_units\n",
    "        type: CATEGORICAL\n",
    "        categoricalValues: [\"128 64 32\", \"256 128 64\", \"512 256 128 64\", \"256 128 64 32\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%load hyperp_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Create unique jobname: `JOBNAME_HYPER`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBNAME_HYPER=mnist_190417_132255_hyper\n",
      "env: OUTDIR_HYPER=gs://presentation-38388/mnist_190417_132255_hyper\n",
      "env: DATA=gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz\n",
      "env: TIER=STANDARD_1\n"
     ]
    }
   ],
   "source": [
    "# Set JOBNAME environment variable\n",
    "import datetime\n",
    "JOBNAME_HYPER = \"mnist_{}_hyper\".format(datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\"))\n",
    "%env JOBNAME_HYPER {JOBNAME_HYPER}\n",
    "# Set new OUTPUT and DATA directory in GS\n",
    "OUTDIR_HYPER = '/'.join(['gs:/', BUCKET, JOBNAME_HYPER])\n",
    "DATA = '/'.join(['gs:/', BUCKET, PKG_NAME, 'data', 'mnist.npz'])\n",
    "%env OUTDIR_HYPER $OUTDIR_HYPER\n",
    "%env DATA $DATA\n",
    "%env TIER STANDARD_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Start Bayesian Hyperparameter Search:\n",
    "\n",
    "- add `config` parameter with `hyperp_config.yaml` as argument:\n",
    "- one can add other parameter to `hyperp_config.yaml`, see [docs on submitting](https://cloud.google.com/ml-engine/docs/tensorflow/training-jobs#formatting_your_configuration_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>echo %OUTDIR_HYPER %DATA% %REGION% %JOBNAME_HYPER%\n",
      "%OUTDIR_HYPER gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz europe-west1 mnist_190417_132255_hyper\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>gcloud ml-engine jobs submit training %JOBNAME_HYPER% ^\n",
      "More?    --region %REGION% ^\n",
      "More?    --module-name %PKG_NAME%.task ^\n",
      "More?    --package-path %cd%/src/%PKG_NAME% ^\n",
      "More?    --staging-bucket gs://%BUCKET% ^\n",
      "More?    --scale-tier %TIER% ^\n",
      "More?    --python-version 3.5 ^\n",
      "More?    --runtime-version %TFVERSION% ^\n",
      "More?    --config hyperp_config.yaml ^\n",
      "More?    -- ^\n",
      "More?    --data_path %DATA% ^\n",
      "More?    --output_dir %OUTDIR_HYPER% ^\n",
      "More?    --train_steps 5000 ^\n",
      "More?    --job_dir %OUTDIR_HYPER%/jobs\n",
      "jobId: mnist_190417_132255_hyper\r\n",
      "state: QUEUED\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [mnist_190417_132255_hyper] submitted successfully.\r\n",
      "Your job is still active. You may view the status of your job with the command\r\n",
      "\r\n",
      "  $ gcloud ml-engine jobs describe mnist_190417_132255_hyper\r\n",
      "\r\n",
      "or continue streaming the logs with the command\r\n",
      "\r\n",
      "  $ gcloud ml-engine jobs stream-logs mnist_190417_132255_hyper\r\n"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "echo %OUTDIR_HYPER %DATA% %REGION% %JOBNAME_HYPER%\n",
    "gcloud ml-engine jobs submit training %JOBNAME_HYPER% ^\n",
    "   --region %REGION% ^\n",
    "   --module-name %PKG_NAME%.task ^\n",
    "   --package-path %cd%/src/%PKG_NAME% ^\n",
    "   --staging-bucket gs://%BUCKET% ^\n",
    "   --scale-tier %TIER% ^\n",
    "   --python-version 3.5 ^\n",
    "   --runtime-version %TFVERSION% ^\n",
    "   --config hyperp_config.yaml ^\n",
    "   -- ^\n",
    "   --data_path %DATA% ^\n",
    "   --output_dir %OUTDIR_HYPER% ^\n",
    "   --train_steps 5000 ^\n",
    "   --job_dir %OUTDIR_HYPER%/jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ml-productive-pipeline-53122/mnist_190322_155703 gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz europe-west1 mnist_190322_155703\n",
      "jobId: mnist_190322_155703\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [mnist_190322_155703] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe mnist_190322_155703\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs mnist_190322_155703\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $OUTDIR_HYPER $DATA $REGION $JOBNAME_HYPER\n",
    "gcloud ml-engine jobs submit training $JOBNAME_HYPER \\\n",
    "   --region $REGION \\\n",
    "   --module-name $PKG_NAME.task \\\n",
    "   --package-path ${PWD}/src/$PKG_NAME \\\n",
    "   --staging-bucket gs://$BUCKET \\\n",
    "   --scale-tier $TIER \\\n",
    "   --python-version 3.5 \\\n",
    "   --runtime-version $TFVERSION \\\n",
    "   --config hyperp_config.yaml \\\n",
    "   -- \\\n",
    "   --data_path $DATA \\\n",
    "   --output_dir $OUTDIR_HYPER \\\n",
    "   --train_steps 5000 \\\n",
    "   --job_dir $OUTDIR/jobs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!gcloud ml-engine jobs stream-logs %JOBNAME_HYPER%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Get results from job using API\n",
    "\n",
    "See [client documentation on ml-engine](https://cloud.google.com/ml-engine/docs/tensorflow/python-client-library#putting_it_all_together) and [` ml.projects().jobs().get()`](https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs/get) method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Using `requests-package` behind a proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jobs': [{'jobId': 'mnist_190417_132839',\n",
       "   'trainingInput': {'scaleTier': 'STANDARD_1',\n",
       "    'packageUris': ['gs://presentation-38388/mnist_190417_132839/14c524dda3f31f75ef6f3dd39f24768a630b2aeb2b3fda2e04302897944f93de/pkg_mnist_fnn-0.0.0.tar.gz'],\n",
       "    'pythonModule': 'pkg_mnist_fnn.task',\n",
       "    'args': ['--data_path=gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz',\n",
       "     '--output_dir=gs://presentation-38388/mnist_190417_132839',\n",
       "     '--train_steps=5000',\n",
       "     '--job_dir=gs://presentation-38388/mnist_190417_132839/jobs'],\n",
       "    'region': 'europe-west1',\n",
       "    'runtimeVersion': '1.13',\n",
       "    'pythonVersion': '3.5'},\n",
       "   'createTime': '2019-04-17T11:29:00Z',\n",
       "   'state': 'PREPARING',\n",
       "   'trainingOutput': {},\n",
       "   'etag': '8ycvfVFWx0E='},\n",
       "  {'jobId': 'mnist_190417_132255_hyper',\n",
       "   'trainingInput': {'scaleTier': 'STANDARD_1',\n",
       "    'packageUris': ['gs://presentation-38388/mnist_190417_132255_hyper/e040cabea9dacc4c96fc2ca72275897d6d1fbbc4002ec960345d46bc99e1e235/pkg_mnist_fnn-0.0.0.tar.gz'],\n",
       "    'pythonModule': 'pkg_mnist_fnn.task',\n",
       "    'args': ['--data_path',\n",
       "     'gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz',\n",
       "     '--output_dir',\n",
       "     'gs://presentation-38388/mnist_190417_132255_hyper',\n",
       "     '--train_steps',\n",
       "     '5000',\n",
       "     '--job_dir',\n",
       "     'gs://presentation-38388/mnist_190417_132255_hyper/jobs'],\n",
       "    'hyperparameters': {'goal': 'MAXIMIZE',\n",
       "     'params': [{'parameterName': 'train_batch_size',\n",
       "       'minValue': 64,\n",
       "       'maxValue': 512,\n",
       "       'type': 'INTEGER',\n",
       "       'scaleType': 'UNIT_LOG_SCALE'},\n",
       "      {'parameterName': 'hidden_units',\n",
       "       'type': 'CATEGORICAL',\n",
       "       'categoricalValues': ['128 64 32',\n",
       "        '256 128 64',\n",
       "        '512 256 128 64',\n",
       "        '256 128 64 32']}],\n",
       "     'maxTrials': 30,\n",
       "     'maxParallelTrials': 2,\n",
       "     'hyperparameterMetricTag': 'accuracy'},\n",
       "    'region': 'europe-west1',\n",
       "    'runtimeVersion': '1.13',\n",
       "    'pythonVersion': '3.5'},\n",
       "   'createTime': '2019-04-17T11:27:01Z',\n",
       "   'startTime': '2019-04-17T11:27:03Z',\n",
       "   'state': 'RUNNING',\n",
       "   'trainingOutput': {'isHyperparameterTuningJob': True},\n",
       "   'etag': 'arKOktDT7TY='},\n",
       "  {'jobId': 'mnist_190417_132034_hyper',\n",
       "   'trainingInput': {'scaleTier': 'STANDARD_1',\n",
       "    'packageUris': ['gs://presentation-38388/mnist_190417_132034_hyper/67c6a97d6639cdff9516ea73bedd40c50c098c8ae308633535dd112ab91ad36a/pkg_mnist_fnn-0.0.0.tar.gz'],\n",
       "    'pythonModule': 'pkg_mnist_fnn.task',\n",
       "    'args': ['--data_path',\n",
       "     'gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz',\n",
       "     '--output_dir',\n",
       "     'gs://presentation-38388/mnist_190417_132034_hyper',\n",
       "     '--train_steps',\n",
       "     '5000',\n",
       "     '--job_dir',\n",
       "     'gs://presentation-38388/mnist_190417_132034_hyper/jobs'],\n",
       "    'hyperparameters': {'goal': 'MAXIMIZE',\n",
       "     'params': [{'parameterName': 'train_batch_size',\n",
       "       'minValue': 64,\n",
       "       'maxValue': 512,\n",
       "       'type': 'INTEGER',\n",
       "       'scaleType': 'UNIT_LOG_SCALE'},\n",
       "      {'parameterName': 'hidden_units',\n",
       "       'type': 'CATEGORICAL',\n",
       "       'categoricalValues': ['128 64 32',\n",
       "        '256 128 64',\n",
       "        '512 256 128 64',\n",
       "        '256 128 64 32']}],\n",
       "     'maxTrials': 30,\n",
       "     'maxParallelTrials': 2,\n",
       "     'hyperparameterMetricTag': 'accuracy'},\n",
       "    'region': 'europe-west1',\n",
       "    'runtimeVersion': '1.13',\n",
       "    'pythonVersion': '3.5'},\n",
       "   'createTime': '2019-04-17T11:21:45Z',\n",
       "   'startTime': '2019-04-17T11:21:47Z',\n",
       "   'state': 'RUNNING',\n",
       "   'trainingOutput': {'isHyperparameterTuningJob': True},\n",
       "   'etag': 'gHZ6SlaRolM='},\n",
       "  {'jobId': 'mnist_190417_120216',\n",
       "   'trainingInput': {'scaleTier': 'STANDARD_1',\n",
       "    'packageUris': ['gs://presentation-38388/mnist_190417_120216/a1ece7005c9d14b2f3750d6cd83d414e8a2c1fa1d1af087cfe2b6b24fca500da/pkg_mnist_fnn-0.0.0.tar.gz'],\n",
       "    'pythonModule': 'pkg_mnist_fnn.task',\n",
       "    'args': ['--data_path',\n",
       "     'gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz',\n",
       "     '--output_dir',\n",
       "     'gs://presentation-38388/mnist_190417_114545',\n",
       "     '--train_steps',\n",
       "     '5000',\n",
       "     '--job_dir',\n",
       "     'gs://presentation-38388/mnist_190417_114545/jobs'],\n",
       "    'hyperparameters': {'goal': 'MAXIMIZE',\n",
       "     'params': [{'parameterName': 'train_batch_size',\n",
       "       'minValue': 64,\n",
       "       'maxValue': 512,\n",
       "       'type': 'INTEGER',\n",
       "       'scaleType': 'UNIT_LOG_SCALE'},\n",
       "      {'parameterName': 'hidden_units',\n",
       "       'type': 'CATEGORICAL',\n",
       "       'categoricalValues': ['128 64 32',\n",
       "        '256 128 64',\n",
       "        '512 256 128 64',\n",
       "        '256 128 64 32']}],\n",
       "     'maxTrials': 30,\n",
       "     'maxParallelTrials': 2,\n",
       "     'hyperparameterMetricTag': 'accuracy'},\n",
       "    'region': 'europe-west1',\n",
       "    'runtimeVersion': '1.13',\n",
       "    'pythonVersion': '3.5'},\n",
       "   'createTime': '2019-04-17T10:02:27Z',\n",
       "   'startTime': '2019-04-17T10:02:30Z',\n",
       "   'endTime': '2019-04-17T10:53:53Z',\n",
       "   'state': 'SUCCEEDED',\n",
       "   'trainingOutput': {'completedTrialCount': '30',\n",
       "    'trials': [{'trialId': '3',\n",
       "      'hyperparameters': {'hidden_units': '512 256 128 64',\n",
       "       'train_batch_size': '66'},\n",
       "      'finalMetric': {'trainingStep': '5006',\n",
       "       'objectiveValue': 0.9745000004768372}},\n",
       "     {'trialId': '1',\n",
       "      'hyperparameters': {'train_batch_size': '134',\n",
       "       'hidden_units': '512 256 128 64'},\n",
       "      'finalMetric': {'trainingStep': '5007',\n",
       "       'objectiveValue': 0.9736999869346619}},\n",
       "     {'trialId': '16',\n",
       "      'hyperparameters': {'train_batch_size': '360',\n",
       "       'hidden_units': '512 256 128 64'},\n",
       "      'finalMetric': {'trainingStep': '5007',\n",
       "       'objectiveValue': 0.9735000133514404}},\n",
       "     {'trialId': '23',\n",
       "      'hyperparameters': {'hidden_units': '512 256 128 64',\n",
       "       'train_batch_size': '160'},\n",
       "      'finalMetric': {'trainingStep': '5007',\n",
       "       'objectiveValue': 0.9732999801635742}},\n",
       "     {'trialId': '19',\n",
       "      'hyperparameters': {'hidden_units': '512 256 128 64',\n",
       "       'train_batch_size': '389'},\n",
       "      'finalMetric': {'trainingStep': '5006',\n",
       "       'objectiveValue': 0.972100019454956}},\n",
       "     {'trialId': '17',\n",
       "      'hyperparameters': {'hidden_units': '512 256 128 64',\n",
       "       'train_batch_size': '228'},\n",
       "      'finalMetric': {'trainingStep': '5007',\n",
       "       'objectiveValue': 0.9714000225067139}},\n",
       "     {'trialId': '4',\n",
       "      'hyperparameters': {'train_batch_size': '89',\n",
       "       'hidden_units': '512 256 128 64'},\n",
       "      'finalMetric': {'trainingStep': '5006',\n",
       "       'objectiveValue': 0.9704999923706055}},\n",
       "     {'trialId': '25',\n",
       "      'hyperparameters': {'train_batch_size': '171',\n",
       "       'hidden_units': '512 256 128 64'},\n",
       "      'finalMetric': {'trainingStep': '5007',\n",
       "       'objectiveValue': 0.9700999855995178}},\n",
       "     {'trialId': '5',\n",
       "      'hyperparameters': {'train_batch_size': '386',\n",
       "       'hidden_units': '512 256 128 64'},\n",
       "      'finalMetric': {'trainingStep': '5005',\n",
       "       'objectiveValue': 0.9681000113487244}},\n",
       "     {'trialId': '30',\n",
       "      'hyperparameters': {'train_batch_size': '123',\n",
       "       'hidden_units': '512 256 128 64'},\n",
       "      'finalMetric': {'trainingStep': '5006',\n",
       "       'objectiveValue': 0.9675999879837036}},\n",
       "     {'trialId': '13',\n",
       "      'hyperparameters': {'hidden_units': '256 128 64',\n",
       "       'train_batch_size': '485'},\n",
       "      'finalMetric': {'trainingStep': '5006',\n",
       "       'objectiveValue': 0.9664999842643738}},\n",
       "     {'trialId': '8',\n",
       "      'hyperparameters': {'hidden_units': '256 128 64 32',\n",
       "       'train_batch_size': '413'},\n",
       "      'finalMetric': {'trainingStep': '5006',\n",
       "       'objectiveValue': 0.9656999707221985}},\n",
       "     {'trialId': '2',\n",
       "      'hyperparameters': {'hidden_units': '256 128 64',\n",
       "       'train_batch_size': '433'},\n",
       "      'finalMetric': {'trainingStep': '5004',\n",
       "       'objectiveValue': 0.9650999903678894}},\n",
       "     {'trialId': '15',\n",
       "      'hyperparameters': {'hidden_units': '256 128 64',\n",
       "       'train_batch_size': '196'},\n",
       "      'finalMetric': {'trainingStep': '5006',\n",
       "       'objectiveValue': 0.9649999737739563}},\n",
       "     {'trialId': '28',\n",
       "      'hyperparameters': {'train_batch_size': '457',\n",
       "       'hidden_units': '256 128 64'},\n",
       "      'finalMetric': {'trainingStep': '5005',\n",
       "       'objectiveValue': 0.9646999835968018}},\n",
       "     {'trialId': '10',\n",
       "      'hyperparameters': {'hidden_units': '256 128 64',\n",
       "       'train_batch_size': '132'},\n",
       "      'finalMetric': {'trainingStep': '5006',\n",
       "       'objectiveValue': 0.9646000266075134}},\n",
       "     {'trialId': '7',\n",
       "      'hyperparameters': {'train_batch_size': '222',\n",
       "       'hidden_units': '256 128 64'},\n",
       "      'finalMetric': {'trainingStep': '5007',\n",
       "       'objectiveValue': 0.9638000130653381}},\n",
       "     {'trialId': '27',\n",
       "      'hyperparameters': {'hidden_units': '256 128 64 32',\n",
       "       'train_batch_size': '314'},\n",
       "      'finalMetric': {'trainingStep': '5006',\n",
       "       'objectiveValue': 0.9631999731063843}},\n",
       "     {'trialId': '26',\n",
       "      'hyperparameters': {'train_batch_size': '311',\n",
       "       'hidden_units': '256 128 64'},\n",
       "      'finalMetric': {'trainingStep': '5007',\n",
       "       'objectiveValue': 0.9621999859809875}},\n",
       "     {'trialId': '21',\n",
       "      'hyperparameters': {'train_batch_size': '132',\n",
       "       'hidden_units': '256 128 64'},\n",
       "      'finalMetric': {'trainingStep': '5005',\n",
       "       'objectiveValue': 0.960099995136261}},\n",
       "     {'trialId': '18',\n",
       "      'hyperparameters': {'train_batch_size': '443',\n",
       "       'hidden_units': '256 128 64 32'},\n",
       "      'finalMetric': {'trainingStep': '5007',\n",
       "       'objectiveValue': 0.9592999815940857}},\n",
       "     {'trialId': '24',\n",
       "      'hyperparameters': {'hidden_units': '128 64 32',\n",
       "       'train_batch_size': '459'},\n",
       "      'finalMetric': {'trainingStep': '5006',\n",
       "       'objectiveValue': 0.955299973487854}},\n",
       "     {'trialId': '11',\n",
       "      'hyperparameters': {'train_batch_size': '262',\n",
       "       'hidden_units': '128 64 32'},\n",
       "      'finalMetric': {'trainingStep': '5005',\n",
       "       'objectiveValue': 0.9528999924659729}},\n",
       "     {'trialId': '9',\n",
       "      'hyperparameters': {'train_batch_size': '414',\n",
       "       'hidden_units': '128 64 32'},\n",
       "      'finalMetric': {'trainingStep': '5005',\n",
       "       'objectiveValue': 0.9513000249862671}},\n",
       "     {'trialId': '14',\n",
       "      'hyperparameters': {'hidden_units': '128 64 32',\n",
       "       'train_batch_size': '242'},\n",
       "      'finalMetric': {'trainingStep': '5007',\n",
       "       'objectiveValue': 0.9498000144958496}},\n",
       "     {'trialId': '12',\n",
       "      'hyperparameters': {'hidden_units': '128 64 32',\n",
       "       'train_batch_size': '277'},\n",
       "      'finalMetric': {'trainingStep': '5005',\n",
       "       'objectiveValue': 0.949400007724762}},\n",
       "     {'trialId': '22',\n",
       "      'hyperparameters': {'hidden_units': '128 64 32',\n",
       "       'train_batch_size': '277'},\n",
       "      'finalMetric': {'trainingStep': '5006',\n",
       "       'objectiveValue': 0.9487000107765198}},\n",
       "     {'trialId': '29',\n",
       "      'hyperparameters': {'hidden_units': '128 64 32',\n",
       "       'train_batch_size': '327'},\n",
       "      'finalMetric': {'trainingStep': '5005',\n",
       "       'objectiveValue': 0.9456999897956848}},\n",
       "     {'trialId': '6',\n",
       "      'hyperparameters': {'hidden_units': '128 64 32',\n",
       "       'train_batch_size': '242'},\n",
       "      'finalMetric': {'trainingStep': '5006',\n",
       "       'objectiveValue': 0.9440000057220459}},\n",
       "     {'trialId': '20',\n",
       "      'hyperparameters': {'hidden_units': '128 64 32',\n",
       "       'train_batch_size': '239'},\n",
       "      'finalMetric': {'trainingStep': '5007',\n",
       "       'objectiveValue': 0.9433000087738037}}],\n",
       "    'consumedMLUnits': 21.3,\n",
       "    'isHyperparameterTuningJob': True},\n",
       "   'etag': 'O1vGW7R4L6o='},\n",
       "  {'jobId': 'mnist_190417_114545',\n",
       "   'trainingInput': {'scaleTier': 'STANDARD_1',\n",
       "    'packageUris': ['gs://presentation-38388/mnist_190417_114545/374e20c3ed25bc2671c5e6c613eaea6c17f430a09e482f05b1459a25b96d1178/pkg_mnist_fnn-0.0.0.tar.gz'],\n",
       "    'pythonModule': 'pkg_mnist_fnn.task',\n",
       "    'args': ['--data_path=gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz',\n",
       "     '--output_dir=gs://presentation-38388/mnist_190417_114545',\n",
       "     '--train_steps=5000',\n",
       "     '--job_dir=gs://presentation-38388/mnist_190417_114545/jobs'],\n",
       "    'region': 'europe-west1',\n",
       "    'runtimeVersion': '1.13',\n",
       "    'pythonVersion': '3.5'},\n",
       "   'createTime': '2019-04-17T09:48:19Z',\n",
       "   'startTime': '2019-04-17T09:54:47Z',\n",
       "   'endTime': '2019-04-17T09:56:18Z',\n",
       "   'state': 'SUCCEEDED',\n",
       "   'trainingOutput': {'consumedMLUnits': 0.71},\n",
       "   'etag': 'v8Xyn4nvLWs='}]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://ml.googleapis.com/v1/projects/{project}/jobs'.format(project=PROJECT)\n",
    "headers = {\n",
    "   'Content-Type': 'application/json',\n",
    "   'Authorization':  'Bearer {}'.format(subprocess.run('gcloud auth print-access-token', shell=True, check=True, \n",
    "                                                       stdout=subprocess.PIPE).stdout.decode().replace('\\r\\n', ''))\n",
    "}\n",
    "json_response = requests.get(url=url, headers=headers)\n",
    "json.loads(json_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Content-Type': 'application/json', 'Authorization': 'Bearer ya29.Gl3uBoEElHq8NKHx3jZEifwvgiUEJj3mcCL2HOxvUZurh_vFGxl03BJG1lXByEeDEFLXKAyneQYtJI_uROTDfiBMRjnPD353f1bqqNd3730UJwEN5BJ-XgMHgu3ZM6Q'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'jobId': 'mnist_190417_132255_hyper',\n",
       " 'trainingInput': {'scaleTier': 'STANDARD_1',\n",
       "  'packageUris': ['gs://presentation-38388/mnist_190417_132255_hyper/e040cabea9dacc4c96fc2ca72275897d6d1fbbc4002ec960345d46bc99e1e235/pkg_mnist_fnn-0.0.0.tar.gz'],\n",
       "  'pythonModule': 'pkg_mnist_fnn.task',\n",
       "  'args': ['--data_path',\n",
       "   'gs://presentation-38388/pkg_mnist_fnn/data/mnist.npz',\n",
       "   '--output_dir',\n",
       "   'gs://presentation-38388/mnist_190417_132255_hyper',\n",
       "   '--train_steps',\n",
       "   '5000',\n",
       "   '--job_dir',\n",
       "   'gs://presentation-38388/mnist_190417_132255_hyper/jobs'],\n",
       "  'hyperparameters': {'goal': 'MAXIMIZE',\n",
       "   'params': [{'parameterName': 'train_batch_size',\n",
       "     'minValue': 64,\n",
       "     'maxValue': 512,\n",
       "     'type': 'INTEGER',\n",
       "     'scaleType': 'UNIT_LOG_SCALE'},\n",
       "    {'parameterName': 'hidden_units',\n",
       "     'type': 'CATEGORICAL',\n",
       "     'categoricalValues': ['128 64 32',\n",
       "      '256 128 64',\n",
       "      '512 256 128 64',\n",
       "      '256 128 64 32']}],\n",
       "   'maxTrials': 30,\n",
       "   'maxParallelTrials': 2,\n",
       "   'hyperparameterMetricTag': 'accuracy'},\n",
       "  'region': 'europe-west1',\n",
       "  'runtimeVersion': '1.13',\n",
       "  'pythonVersion': '3.5'},\n",
       " 'createTime': '2019-04-17T11:27:01Z',\n",
       " 'startTime': '2019-04-17T11:27:03Z',\n",
       " 'state': 'RUNNING',\n",
       " 'trainingOutput': {'isHyperparameterTuningJob': True},\n",
       " 'etag': 'arKOktDT7TY='}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobname = os.environ['JOBNAME_HYPER']\n",
    "url = 'https://ml.googleapis.com/v1/projects/{project}/jobs/{jobname}'.format(project=PROJECT, jobname=jobname)\n",
    "headers = {\n",
    "   'Content-Type': 'application/json',\n",
    "   'Authorization':  'Bearer {}'.format(subprocess.run('gcloud auth print-access-token', shell=True, check=True, \n",
    "                                                       stdout=subprocess.PIPE).stdout.decode().replace('\\r\\n', ''))\n",
    "}\n",
    "print(headers)\n",
    "json_response = requests.get(url=url, headers=headers)\n",
    "json.loads(json_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Using `googleapiclient.discorvery`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "import httplib2\n",
    "# Store your full project ID in a variable in the format the API needs.\n",
    "# Build a representation of the Cloud ML API.\n",
    "ml = discovery.build('ml', 'v1', http= httplib2.Http(disable_ssl_certificate_validation=True)) #, credentials=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ml.projects().jobs().list(parent='projects/{}'.format(PROJECT)).execute() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "jobname = os.environ['JOBNAME'] \n",
    "request = ml.projects().jobs().get(\n",
    "    name='projects/{project}/jobs/{jobname}'.format(\n",
    "        project=PROJECT, jobname=jobname))\n",
    "request.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'createTime': '2019-03-22T14:57:15Z',\n",
      " 'endTime': '2019-03-22T15:29:36Z',\n",
      " 'etag': 'D7kQj0eIfWQ=',\n",
      " 'jobId': 'mnist_190322_155703',\n",
      " 'startTime': '2019-03-22T14:57:18Z',\n",
      " 'state': 'SUCCEEDED',\n",
      " 'trainingInput': {'args': ['--data_path',\n",
      "                            'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/mnist.npz',\n",
      "                            '--output_dir',\n",
      "                            'gs://ml-productive-pipeline-53122/mnist_190322_155703',\n",
      "                            '--train_steps',\n",
      "                            '5000',\n",
      "                            '--job_dir',\n",
      "                            'gs://ml-productive-pipeline-53122/mnist_190322_155703/jobs'],\n",
      "                   'hyperparameters': {'goal': 'MAXIMIZE',\n",
      "                                       'hyperparameterMetricTag': 'accuracy',\n",
      "                                       'maxParallelTrials': 2,\n",
      "                                       'maxTrials': 4,\n",
      "                                       'params': [{'maxValue': 512,\n",
      "                                                   'minValue': 64,\n",
      "                                                   'parameterName': 'train_batch_size',\n",
      "                                                   'scaleType': 'UNIT_LOG_SCALE',\n",
      "                                                   'type': 'INTEGER'},\n",
      "                                                  {'categoricalValues': ['128 '\n",
      "                                                                         '64 '\n",
      "                                                                         '32',\n",
      "                                                                         '256 '\n",
      "                                                                         '128 '\n",
      "                                                                         '64',\n",
      "                                                                         '512 '\n",
      "                                                                         '256 '\n",
      "                                                                         '128 '\n",
      "                                                                         '64'],\n",
      "                                                   'parameterName': 'hidden_units',\n",
      "                                                   'type': 'CATEGORICAL'}]},\n",
      "                   'packageUris': ['gs://ml-productive-pipeline-53122/mnist_190322_155703/adb63fafb740578b3a12be3fedcaf4540dccab8f92df245e2cc946abe2bfbaa5/pkg_mnist_fnn-0.0.0.tar.gz'],\n",
      "                   'pythonModule': 'pkg_mnist_fnn.task',\n",
      "                   'pythonVersion': '3.5',\n",
      "                   'region': 'europe-west1',\n",
      "                   'runtimeVersion': '1.12'},\n",
      " 'trainingOutput': {'completedTrialCount': '4',\n",
      "                    'consumedMLUnits': 0.43,\n",
      "                    'isHyperparameterTuningJob': True,\n",
      "                    'trials': [{'finalMetric': {'objectiveValue': 0.9684000015258789,\n",
      "                                                'trainingStep': '4688'},\n",
      "                                'hyperparameters': {'hidden_units': '256 128 '\n",
      "                                                                    '64',\n",
      "                                                    'train_batch_size': '165'},\n",
      "                                'trialId': '2'},\n",
      "                               {'finalMetric': {'objectiveValue': 0.9670000076293945,\n",
      "                                                'trainingStep': '4688'},\n",
      "                                'hyperparameters': {'hidden_units': '512 256 '\n",
      "                                                                    '128 64',\n",
      "                                                    'train_batch_size': '195'},\n",
      "                                'trialId': '3'},\n",
      "                               {'finalMetric': {'objectiveValue': 0.9657999873161316,\n",
      "                                                'trainingStep': '4688'},\n",
      "                                'hyperparameters': {'hidden_units': '256 128 '\n",
      "                                                                    '64',\n",
      "                                                    'train_batch_size': '165'},\n",
      "                                'trialId': '4'},\n",
      "                               {'finalMetric': {'objectiveValue': 0.9401000142097473,\n",
      "                                                'trainingStep': '4688'},\n",
      "                                'hyperparameters': {'hidden_units': '128 64 32',\n",
      "                                                    'train_batch_size': '314'},\n",
      "                                'trialId': '1'}]}}\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient import discovery\n",
    "from googleapiclient import errors\n",
    "from pprint import pprint\n",
    "\n",
    "jobname = os.environ['JOBNAME_HYPER']\n",
    "endpoint = 'projects/{project}/jobs/{jobname}'.format(project=PROJECT, jobname=jobname)\n",
    "print(\"API endpoint: {}\".format(endpoint))\n",
    "request = ml.projects().jobs().get(name=endpoint)\n",
    "# Make the call.\n",
    "try:\n",
    "    response = request.execute()\n",
    "    pprint(response)\n",
    "except errors.HttpError as err:\n",
    "    # Something went wrong, print out some information.\n",
    "    print('There was an error creating the model. Check the details:')\n",
    "    print(err._get_reason())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Excursus: Check Results in TensorBoard\n",
    "\n",
    "- metrics and variables are inspected from the logs, called checkpoints (`ckpt`)\n",
    "- Dashboard on localhost: `TensorBoard`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In Datalab Tensorboard is available using a special package. On your local machine, you can execute tensorflow using the command line.\n",
    "\n",
    "DATALAB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start(('{}/'+os.environ['PKG_NAME']).format(os.environ['PWD']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "  TensorBoard().stop(pid)\n",
    "  print('Stopped TensorBoard with pid {}'.format(pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "If the above step (to stop TensorBoard) appears stalled, just move on to the next step. You don't need to wait for it to return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Inspect Model trained on your machine:\n",
    "- `tensorboard --logdir trained/pkg_mnist_fnn/`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "!tensorboard --logdir trained/pkg_mnist_fnn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "%%bash\n",
    "tensorboard $PWD/$OUTDIR_LOCAL"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "!echo \"tensorboard --logdir $PWD/src/$PKG_NAME/trained\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Or trained on GCP, where results are store in Google Cloud Storage"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "%%bash\n",
    "#gcloud auth application-default login\n",
    "echo $OUTDIR\n",
    "tensorboard --logdir $OUTDIR"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "%%cmd\n",
    "echo %OUTDIR%\n",
    "tensorboard --logdir trained/pkg_mnist_fnn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Screenshot of Tensorboard\n",
    "![screenshot Tensorboard](Images/tensorboard_screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Excursus: Load data from the bucket\n",
    "\n",
    "- Binary Object has to be read by `BytesIO` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\google\\auth\\_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT) # use current gcloud PROJECT_ID\n",
    "bucket = storage_client.get_bucket(BUCKET)\n",
    "blob = bucket.blob(\"pkg_mnist_fnn/data/mnist.npz\")\n",
    "\n",
    "data = blob.download_as_string()\n",
    "data = BytesIO(data)\n",
    "data = np.load(data)\n",
    "with data as f:\n",
    "    x_train, y_train = f['x_train'], f['y_train']\n",
    "    x_test, y_test = f['x_test'], f['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#ToDo# Does only work under linux-> version?\n",
    "from io import BytesIO\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "f = BytesIO(file_io.read_file_to_string(\n",
    "    filename=DATA, #'gs://BUCKET/PKG_NAME/data/mnist.npz', \n",
    "    binary_mode=True\n",
    "))\n",
    "data = np.load(f)\n",
    "with data as f:\n",
    "    x_train, y_train = f['x_train'], f['y_train']\n",
    "    x_test, y_test = f['x_test'], f['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deploy model - from any previous step (DSP 2.5)\n",
    "\n",
    "- `tf.estimator.LatestExporter`is used to store a model for deployment in the cloud\n",
    "- See also:  `tf.estimator.export`, `tf.saved_model`\n",
    "\n",
    "[Link to Console](https://console.cloud.google.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Check that a model has been saved on your Bucket:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "%%bash\n",
    "#gcloud auth application-default login\n",
    "echo $OUTDIR\n",
    "gsutil ls ${OUTDIR}/export/exporter"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "%%cmd\n",
    "#gcloud auth application-default login\n",
    "echo %OUTDIR%\n",
    "gsutil ls %OUTDIR%/export/exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://presentation-38388/mnist_190417_132839/export/exporter/',\n",
       " 'gs://presentation-38388/mnist_190417_132839/export/exporter/1555500894/',\n",
       " 'gs://presentation-38388/mnist_190417_132839/export/exporter/1555500911/']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = !gsutil ls %OUTDIR%/export/exporter/\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODEL_LOCATION=gs://presentation-38388/mnist_190417_132839/export/exporter/1555500911/\n"
     ]
    }
   ],
   "source": [
    "%env MODEL_LOCATION={models[-1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Identifier for deployed model:\n",
    "- `MODEL_NAME`\n",
    "- `MODEL_VERSION`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"MNIST_MLENGINE\"\n",
    "MODEL_VERSION=\"v1\" \n",
    "MODEL_LOCATION=$(gsutil ls gs://${OUTDIR}/export/exporter | tail -1)\n",
    "echo \"Run these commands one-by-one (the very first time, you'll create a model and then create a version)\"\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models   create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} \\\n",
    "     --origin ${MODEL_LOCATION} \\\n",
    "     --runtime-version $TFVERSION \\\n",
    "     --python-version 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODEL_NAME=\"MNIST_MLENGINE\"\n",
      "env: MODEL_VERSION=\"v1\"\n"
     ]
    }
   ],
   "source": [
    "%env MODEL_NAME \"MNIST_MLENGINE\"\n",
    "%env MODEL_VERSION \"v1\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Create: A model (Dataset) has different versions (Tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>gcloud ml-engine models   create %MODEL_NAME% --regions %REGION%\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>gcloud ml-engine versions create %MODEL_VERSION% --model %MODEL_NAME% ^\n",
      "More?      --origin %MODEL_LOCATION% ^\n",
      "More?      --runtime-version %TFVERSION% ^\n",
      "More?      --python-version 3.5\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created ml engine model [projects/presentation-38388/models/MNIST_MLENGINE].\r\n",
      "Creating version (this might take a few minutes)......\r\n",
      ".............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.\r\n"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "gcloud ml-engine models   create %MODEL_NAME% --regions %REGION%\n",
    "gcloud ml-engine versions create %MODEL_VERSION% --model %MODEL_NAME% ^\n",
    "     --origin %MODEL_LOCATION% ^\n",
    "     --runtime-version %TFVERSION% ^\n",
    "     --python-version 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>gcloud ml-engine versions delete %MODEL_VERSION% --model %MODEL_NAME%\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This will delete version [v1]...\r\n",
      "\r\n",
      "Do you want to continue (Y/n)?  Please enter 'y' or 'n':  \r\n",
      "Deleting version [v1]......\r\n",
      "......................................................................................done.\r\n"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "gcloud ml-engine versions delete %MODEL_VERSION% --model %MODEL_NAME%\n",
    "gcloud ml-engine models delete %MODEL_NAME%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!gcloud ml-engine versions create --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Using the Model saved by Python Module\n",
    "2. Using Model saved by `ml-engine local`\n",
    "3. Using Model trained online"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Tools get predictions:\n",
    "- Command Line Interfaces\n",
    "    - `gcloud ml-engine local predict`\n",
    "    - `gcloud ml-engine predict`\n",
    "- Python Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Create an test-image in numpy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TEST_DATA_JSON=data/mnist/json/ml_engine_testdatafile_N4.json\n"
     ]
    }
   ],
   "source": [
    "N=4\n",
    "testdatafile = \"data/mnist/json/ml_engine_testdatafile_N{}.json\".format(N)\n",
    "with open(\"config.yaml\", \"r\", encoding = \"utf8\") as f:\n",
    "    config = yaml.load(f)\n",
    "with open(\"config.yaml\", \"w\", encoding = \"utf8\") as f:\n",
    "    config['testdatafile'] = testdatafile\n",
    "    yaml.dump(config, stream=f,  default_flow_style=False)\n",
    "TEST_DATA_JSON = testdatafile\n",
    "%env TEST_DATA_JSON $testdatafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from data\\mnist\\raw\\mnist.npz\n",
      "Wrote to data/mnist/json/ml_engine_testdatafile_N4.json\n"
     ]
    }
   ],
   "source": [
    "# Create a file with 4 test images\n",
    "import numpy as np\n",
    "import json\n",
    "from src.pkg_mnist_fnn.utils import load_data\n",
    "from src.pkg_mnist_fnn.model import parse_images\n",
    "(_,_), (x_test, y_test) = load_data(path='data/mnist/raw/mnist.npz')\n",
    "test_indices = np.random.randint(low=0, high=len(y_test), size=N)\n",
    "x_test, y_test = x_test[test_indices], y_test[test_indices]\n",
    "x_test = parse_images(x_test).tolist()\n",
    "\n",
    "#eol = os.linesep\n",
    "#print(eol)\n",
    "n_lines = len(y_test)\n",
    "with open(testdatafile, \"w\") as f:\n",
    "    for image, label in zip(x_test, y_test):\n",
    "        _dict = {\"x\": image} #, \"y\": int(label)}\n",
    "        f.write(json.dumps(_dict)+ \"\\n\")\n",
    "print(\"Wrote to {}\".format(testdatafile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Let's look at our four examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.utils.mnist_utils import plot_mnist_testdata\n",
    "plot_mnist_testdata(TEST_DATA_JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ML-Engine: `ml-engine local predict`\n",
    "- Using Model saved\n",
    "  - Python module\n",
    "  - `ml-engine local`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### `ML-Engine local` using Python 3 ...\n",
    "you still have to remove manually some compiled python files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flags.pyc', 'jobs_prep.pyc', 'jobs_util.pyc', 'local_predict.pyc', 'local_train.pyc', 'local_utils.pyc', 'log_utils.pyc', 'models_util.pyc', 'operations_util.pyc', 'predict_utilities.pyc', 'uploads.pyc', 'versions_util.pyc', '__init__.pyc']\n"
     ]
    }
   ],
   "source": [
    "#/usr/lib/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/\n",
    "folder = \"C:\\\\eplatform\\\\tools\\\\google-cloud-sdk\\\\lib\\\\googlecloudsdk\\\\command_lib\\\\ml_engine\\\\\"\n",
    "files = os.listdir(folder)\n",
    "files = [x for x in files if \".pyc\" in x]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "for x in files:\n",
    "    assert \".pyc\" in x\n",
    "    path_ = os.path.join(folder, x)\n",
    "    os.remove(path_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flags.py', 'jobs_prep.py', 'jobs_util.py', 'local_predict.py', 'local_train.py', 'local_utils.py', 'log_utils.py', 'models_util.py', 'operations_util.py', 'predict_utilities.py', 'resources.yaml', 'uploads.py', 'versions_util.py', '__init__.py', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "folder = \"C:\\\\eplatform\\\\tools\\\\google-cloud-sdk\\\\lib\\\\googlecloudsdk\\\\command_lib\\\\ml_engine\\\\\"\n",
    "files = os.listdir(folder)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In order to work with `Python 3`, delete the `*.pyc` files, see [post](https://stackoverflow.com/questions/48824381/gcloud-ml-engine-local-predict-runtimeerror-bad-magic-number-in-pyc-file)\n",
    "\n",
    "Default Datalab\n",
    "```\n",
    "rm /tools/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/*.pyc\n",
    "```\n",
    "Default UNIX:\n",
    "```\n",
    "sudo rm /usr/lib/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/*.pyc\n",
    "```\n",
    "\n",
    "> Process running Datalab or Jupyter Notebook needs admin rights. This is not always given for locally run notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: model_dir=1555329649\n"
     ]
    }
   ],
   "source": [
    "model_dir = os.listdir(\"{}/export/exporter\".format(OUTDIR_local))[-1]\n",
    "%env model_dir=$model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%cmd\n",
    "set MODEL_LOCATION=%OUTDIR_LOCAL%\\export\\exporter\\%model_dir%\\\n",
    "echo \"Selected Model:  %MODEL_LOCATION%\" \n",
    "gcloud ml-engine local predict ^\n",
    "    --model-dir=%MODEL_LOCATION% ^\n",
    "    --json-instances=%TEST_DATA_JSON% ^\n",
    "    --verbosity debug > data/test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%cmd\n",
    "notepad data/test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "model_dir=$(ls $OUTDIR_LOCAL/export/exporter/ | tail -1)\n",
    "echo \"Selected Model:  $model_dir\" \n",
    "gcloud ml-engine local predict \\\n",
    "    --model-dir=${PWD}/$OUTDIR_LOCAL/export/exporter/${model_dir} \\\n",
    "    --json-instances=$TEST_DATA_JSON \\\n",
    "    --verbosity debug > data/test_predictions\n",
    "cat data/test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME\n",
      "    gcloud ml-engine local predict - run prediction locally\n",
      "\n",
      "SYNOPSIS\n",
      "    gcloud ml-engine local predict --model-dir=MODEL_DIR\n",
      "        (--json-instances=JSON_INSTANCES | --text-instances=TEXT_INSTANCES)\n",
      "        [--framework=FRAMEWORK] [--signature-name=SIGNATURE_NAME]\n",
      "        [GCLOUD_WIDE_FLAG ...]\n",
      "\n",
      "DESCRIPTION\n",
      "    gcloud ml-engine local predict performs prediction locally with the given\n",
      "    instances. It requires the TensorFlow SDK be installed locally. The output\n",
      "    format mirrors gcloud ml-engine predict (online prediction)\n",
      "\n",
      "REQUIRED FLAGS\n",
      "     --model-dir=MODEL_DIR\n",
      "        Path to the model.\n",
      "\n",
      "     Exactly one of these must be specified:\n",
      "\n",
      "       --json-instances=JSON_INSTANCES\n",
      "          Path to a local file from which instances are read. Instances are in\n",
      "          JSON format; newline delimited.\n",
      "\n",
      "          An example of the JSON instances file:\n",
      "\n",
      "              {\"images\": [0.0, ..., 0.1], \"key\": 3}\n",
      "              {\"images\": [0.0, ..., 0.1], \"key\": 2}\n",
      "              ...\n",
      "\n",
      "          This flag accepts \"-\" for stdin.\n",
      "\n",
      "       --text-instances=TEXT_INSTANCES\n",
      "          Path to a local file from which instances are read. Instances are in\n",
      "          UTF-8 encoded text format; newline delimited.\n",
      "\n",
      "          An example of the text instances file:\n",
      "\n",
      "              107,4.9,2.5,4.5,1.7\n",
      "              100,5.7,2.8,4.1,1.3\n",
      "              ...\n",
      "\n",
      "          This flag accepts \"-\" for stdin.\n",
      "\n",
      "OPTIONAL FLAGS\n",
      "     --framework=FRAMEWORK\n",
      "        The ML framework used to train this version of the model. If not\n",
      "        specified, defaults to tensorflow. FRAMEWORK must be one of:\n",
      "        scikit-learn, tensorflow, xgboost.\n",
      "\n",
      "     --signature-name=SIGNATURE_NAME\n",
      "        The name of the signature defined in the SavedModel to use for this\n",
      "        job. Defaults to DEFAULT_SERVING_SIGNATURE_DEF_KEY in\n",
      "        https://www.tensorflow.org/api_docs/python/tf/saved_model/signature_constants,\n",
      "        which is \"serving_default\". Only applies to TensorFlow models.\n",
      "\n",
      "GCLOUD WIDE FLAGS\n",
      "    These flags are available to all commands: --account, --configuration,\n",
      "    --flags-file, --flatten, --format, --help, --log-http, --project, --quiet,\n",
      "    --trace-token, --user-output-enabled, --verbosity. Run $ gcloud help for\n",
      "    details.\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine local predict --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Online Prediction - Command Line\n",
    "\n",
    "- same output format as before,  check Console: [link](https://console.cloud.google.com/mlengine/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud ml-engine predict --model=MNIST_MLENGINE --version=v1 --json-instances=$TEST_DATA_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>gcloud ml-engine predict --model=MNIST_MLENGINE --version=v1 --json-instances=%TEST_DATA_JSON%\n",
      "CLASS_IDS  CLASSES  LOGITS                                                                                                                                                                                                  PROBABILITIES\r\n",
      "[6]        [u'6']   [14.841353416442871, 11.691999435424805, 17.271425247192383, 12.454808235168457, 27.320730209350586, 33.3737678527832, 46.4919319152832, 11.619453430175781, 2.0705859661102295, -0.08118200302124023]  [1.796089488346076e-14, 7.701577192691577e-16, 2.0403012504326135e-13, 1.6514434083610011e-15, 4.721195434598258e-09, 2.0084121388208587e-06, 0.9999979734420776, 7.162657244561357e-16, 5.1056873511003206e-20, 5.9368125811994605e-21]\r\n",
      "[5]        [u'5']   [19.24078369140625, -3.418696641921997, -12.680668830871582, 32.72875213623047, 7.14021110534668, 54.7695426940918, 17.188615798950195, 10.948305130004883, 32.959842681884766, 27.2398738861084]       [3.715831630953149e-16, 5.360044843016428e-26, 5.090327634879915e-30, 2.677973676146195e-10, 2.0646349329450793e-21, 1.0, 4.77322223280785e-17, 9.304202493239468e-20, 3.3741753835414556e-10, 1.106666407818535e-12]\r\n",
      "[4]        [u'4']   [-1.6974650621414185, 1.659282922744751, 5.615025997161865, -9.103403091430664, 13.932087898254395, -8.618605613708496, 2.085800886154175, 5.352936267852783, -0.08024734258651733, 5.92873477935791]   [1.628669821229778e-07, 4.6735835894651245e-06, 0.00024412221682723612, 9.896338609705069e-11, 0.9992210865020752, 1.6070146602320534e-10, 7.15953137842007e-06, 0.0001878380571724847, 8.206951633837889e-07, 0.0003340792318340391]\r\n",
      "[8]        [u'8']   [0.4420117139816284, 2.301677703857422, 1.9346401691436768, 3.994138717651367, 1.1992884874343872, 4.05784273147583, 0.39578577876091003, 0.9556518197059631, 9.092337608337402, 2.8936572074890137]    [0.0001720485306577757, 0.0011048251762986183, 0.0007654046639800072, 0.006002332549542189, 0.00036688667023554444, 0.006397147662937641, 0.00016427633818238974, 0.0002875557984225452, 0.982742428779602, 0.0019970412831753492]\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>"
     ]
    }
   ],
   "source": [
    "%%cmd  \n",
    "gcloud ml-engine predict --model=MNIST_MLENGINE --version=v1 --json-instances=%TEST_DATA_JSON%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.utils.mnist_utils import plot_mnist_testdata\n",
    "plot_mnist_testdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Online Predictions - Batch \n",
    "\n",
    "- cp [example](https://cloud.google.com/ml-engine/docs/tensorflow/batch-predict)\n",
    "- `data_format`= `'text'` for JSON-Format\n",
    "- `output-path`: GS folder where results will be saved \n",
    "- `input-paths`: File-Location (can be folder with several files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gs://ml-productive-pipeline-53122/pkg_mnist_fnn', 'trained')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.split(OUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBNAME_BATCH_PRED=BATCH_190417_142639\n",
      "env: DATA_FORMAT=text\n",
      "env: OUTPUT_PATH=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/batch_pred/\n",
      "env: TEST_DATA_GS=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/data/ml_engine_testdatafile_N4.json_\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "JOBNAME_BATCH_PRED = 'BATCH_' + datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "%env JOBNAME_BATCH_PRED {JOBNAME_BATCH_PRED}\n",
    "%env DATA_FORMAT text\n",
    "%env OUTPUT_PATH {'/'.join([os.path.split(OUTDIR)[0], \"batch_pred/\"])}\n",
    "%env TEST_DATA_GS {'/'.join([os.path.split(DATA)[0], os.path.split(TEST_DATA_JSON)[1]])}_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Copy files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://data\\mnist\\json\\ml_engine_testdatafile_N4.json [Content-Type=application/octet-stream]...\n",
      "/ [0 files][    0.0 B/ 16.4 KiB]                                                \n",
      "/ [1 files][ 16.4 KiB/ 16.4 KiB]                                                \n",
      "\n",
      "Operation completed over 1 objects/16.4 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp data/mnist/json/ml_engine_testdatafile_N4.json %TEST_DATA_GS%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Submit job using `gcloud` functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.15063]\r\n",
      "(c) 2017 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>gcloud ml-engine jobs submit prediction %JOBNAME_BATCH_PRED%  --model=MNIST_MLENGINE --version=v1 --input-paths=%TEST_DATA_GS% --output-path %OUTPUT_PATH%  --region %REGION% --data-format %DATA_FORMAT%\n",
      "jobId: BATCH_190417_142639\r\n",
      "state: QUEUED\r\n",
      "\r\n",
      "(env_gcp_dl) C:\\Users\\C219746\\gcp\\project>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [BATCH_190417_142639] submitted successfully.\r\n",
      "Your job is still active. You may view the status of your job with the command\r\n",
      "\r\n",
      "  $ gcloud ml-engine jobs describe BATCH_190417_142639\r\n",
      "\r\n",
      "or continue streaming the logs with the command\r\n",
      "\r\n",
      "  $ gcloud ml-engine jobs stream-logs BATCH_190417_142639\r\n"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "gcloud ml-engine jobs submit prediction %JOBNAME_BATCH_PRED%  --model=MNIST_MLENGINE --version=v1 --input-paths=%TEST_DATA_GS% --output-path %OUTPUT_PATH%  --region %REGION% --data-format %DATA_FORMAT%"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "!gcloud ml-engine jobs submit prediction $JOBNAME_BATCH_PRED  --model=MNIST_MLENGINE --version=v1 --input-paths=$TEST_DATA_GS --output-path $OUTPUT_PATH  --region $REGION --data-format $DATA_FORMAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Retrieve results from batch and parse them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gs://ml-productive-pipeline-53122/pkg_mnist_fnn/batch_pred/prediction.errors_stats-00000-of-00001', 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/batch_pred/prediction.results-00000-of-00001']\n"
     ]
    }
   ],
   "source": [
    "files = !gsutil ls %OUTPUT_PATH%\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\mnist\\lib\\site-packages\\google\\auth\\_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get file pkg_mnist_fnn/batch_pred/prediction.results-00000-of-00001\n",
      "{'probabilities': [1.796089488346076e-14, 7.701577192691577e-16, 2.0403012504326135e-13, 1.6514434083610011e-15, 4.721195434598258e-09, 2.0084121388208587e-06, 0.9999979734420776, 7.162657244561357e-16, 5.1056873511003206e-20, 5.9368125811994605e-21], 'class_ids': [6], 'classes': ['6'], 'logits': [14.841353416442871, 11.691999435424805, 17.271425247192383, 12.454808235168457, 27.320730209350586, 33.3737678527832, 46.4919319152832, 11.619453430175781, 2.0705859661102295, -0.08118200302124023]}\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "import json\n",
    "mybucket= storage.Client(project=PROJECT).get_bucket('{}'.format(BUCKET))\n",
    "file = files[1].split(\"{}\".format(BUCKET + \"/\"))[1]\n",
    "print(\"Get file {}\".format(file))\n",
    "blob= mybucket.blob(file)\n",
    "result = blob.download_as_string()\n",
    "\n",
    "result = [json.loads(x) for x in (result.decode().split(\"\\n\"))[:-1]]\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Online Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Get predictions using the [Python-Client-Library, see Tutorial](https://cloud.google.com/ml-engine/docs/tensorflow/python-client-library). \n",
    "\n",
    "- [API-Reference](https://cloud.google.com/ml-engine/reference/rest/)\n",
    "\n",
    "-  service account authentification:  [link](https://cloud.google.com/iam/docs/creating-managing-service-accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-productive-pipeline-53122\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'MNIST_MLENGINE' \n",
    "VERSION = 'v1'\n",
    "print(PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Load data** into python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "instances = []\n",
    "with open(TEST_DATA_JSON, \"r\") as f:\n",
    "    data = f.readlines()\n",
    "instances = [json.loads(x) for x in data]   # for discovery-client\n",
    "data = [image['x'] for  image in instances] # for requests-package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###  Using `requests`-package behind a proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Content-Type': 'application/json', 'Authorization': 'Bearer ya29.Gl3uBop6oW3Zvjfjands95CfHpHPNr-uzEXrdFghvllAq-mXygJuzApXN4RLs7DNimCZjChnB213ljqgiEtp-BHJ15kVdkPP65T8Z5Pj7ybbck9_6T2A2VnCj3EdryU'}\n",
      "{'predictions': [{'class_ids': [6],\n",
      "                  'classes': ['6'],\n",
      "                  'logits': [14.841353416442871,\n",
      "                             11.691999435424805,\n",
      "                             17.271425247192383,\n",
      "                             12.454808235168457,\n",
      "                             27.320730209350586,\n",
      "                             33.3737678527832,\n",
      "                             46.4919319152832,\n",
      "                             11.619453430175781,\n",
      "                             2.0705859661102295,\n",
      "                             -0.08118200302124023],\n",
      "                  'probabilities': [1.796089488346076e-14,\n",
      "                                    7.701577192691577e-16,\n",
      "                                    2.0403012504326135e-13,\n",
      "                                    1.6514434083610011e-15,\n",
      "                                    4.721195434598258e-09,\n",
      "                                    2.0084121388208587e-06,\n",
      "                                    0.9999979734420776,\n",
      "                                    7.162657244561357e-16,\n",
      "                                    5.1056873511003206e-20,\n",
      "                                    5.9368125811994605e-21]},\n",
      "                 {'class_ids': [5],\n",
      "                  'classes': ['5'],\n",
      "                  'logits': [19.24078369140625,\n",
      "                             -3.418696641921997,\n",
      "                             -12.680668830871582,\n",
      "                             32.72875213623047,\n",
      "                             7.14021110534668,\n",
      "                             54.7695426940918,\n",
      "                             17.188615798950195,\n",
      "                             10.948305130004883,\n",
      "                             32.959842681884766,\n",
      "                             27.2398738861084],\n",
      "                  'probabilities': [3.715831630953149e-16,\n",
      "                                    5.360044843016428e-26,\n",
      "                                    5.090327634879915e-30,\n",
      "                                    2.677973676146195e-10,\n",
      "                                    2.0646349329450793e-21,\n",
      "                                    1.0,\n",
      "                                    4.77322223280785e-17,\n",
      "                                    9.304202493239468e-20,\n",
      "                                    3.3741753835414556e-10,\n",
      "                                    1.106666407818535e-12]},\n",
      "                 {'class_ids': [4],\n",
      "                  'classes': ['4'],\n",
      "                  'logits': [-1.6974650621414185,\n",
      "                             1.659282922744751,\n",
      "                             5.615025997161865,\n",
      "                             -9.103403091430664,\n",
      "                             13.932087898254395,\n",
      "                             -8.618605613708496,\n",
      "                             2.085800886154175,\n",
      "                             5.352936267852783,\n",
      "                             -0.08024734258651733,\n",
      "                             5.92873477935791],\n",
      "                  'probabilities': [1.628669821229778e-07,\n",
      "                                    4.6735835894651245e-06,\n",
      "                                    0.00024412221682723612,\n",
      "                                    9.896338609705069e-11,\n",
      "                                    0.9992210865020752,\n",
      "                                    1.6070146602320534e-10,\n",
      "                                    7.15953137842007e-06,\n",
      "                                    0.0001878380571724847,\n",
      "                                    8.206951633837889e-07,\n",
      "                                    0.0003340792318340391]},\n",
      "                 {'class_ids': [8],\n",
      "                  'classes': ['8'],\n",
      "                  'logits': [0.4420117139816284,\n",
      "                             2.301677703857422,\n",
      "                             1.9346401691436768,\n",
      "                             3.994138717651367,\n",
      "                             1.1992884874343872,\n",
      "                             4.05784273147583,\n",
      "                             0.39578577876091003,\n",
      "                             0.9556518197059631,\n",
      "                             9.092337608337402,\n",
      "                             2.8936572074890137],\n",
      "                  'probabilities': [0.0001720485306577757,\n",
      "                                    0.0011048251762986183,\n",
      "                                    0.0007654046639800072,\n",
      "                                    0.006002332549542189,\n",
      "                                    0.00036688667023554444,\n",
      "                                    0.006397147662937641,\n",
      "                                    0.00016427633818238974,\n",
      "                                    0.0002875557984225452,\n",
      "                                    0.982742428779602,\n",
      "                                    0.0019970412831753492]}]}\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import requests\n",
    "from pprint import pprint\n",
    "url = 'https://ml.googleapis.com/v1/projects/{project}/models/{model}/versions/{version}:predict'.format(project=PROJECT,\n",
    "                                                                                                         model=MODEL_NAME,\n",
    "                                                                                                         version=VERSION)\n",
    "headers = {\n",
    "   'Content-Type': 'application/json',\n",
    "   'Authorization':  'Bearer {}'.format(subprocess.run('gcloud auth print-access-token', shell=True, check=True, \n",
    "                                                       stdout=subprocess.PIPE).stdout.decode().replace('\\r\\n', ''))\n",
    "}\n",
    "request_data = {\"instances\":\n",
    "    data\n",
    "}\n",
    "print(headers)\n",
    "json_response = requests.post(url=url, data=json.dumps(request_data), headers=headers)\n",
    "pprint(json.loads(json_response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Using `googleapiclient.discovery` \n",
    "- fails behind proxy due to SSL verification (which could not be deactivated)\n",
    "#### Authentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "#import json\n",
    "#import google.auth\n",
    "#cred, project = google.auth.default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "api = discovery.build(serviceName='ml', version='v1',\n",
    "                      #http= httplib2.Http(disable_ssl_certificate_validation=True),\n",
    "                      discoveryServiceUrl='https://www.googleapis.com/discovery/v1/apis/{api}/{apiVersion}/rest',\n",
    "                      #credentials=cred,  # SDK credentials\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```cmd\n",
    "UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. **If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error**. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
    "warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Get predictions for samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "project_id = 'projects/{project}/models/{model}/versions/{version}'.format(project=PROJECT, model=MODEL_NAME, version=VERSION)\n",
    "print(\"Endpoint to use: {}\\n\".format(project_id))\n",
    "request_data = {\"instances\":\n",
    "    instances\n",
    "}\n",
    "request = api.projects().predict(body=request_data, name=project_id).execute()\n",
    "pprint(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for i, pred in enumerate(request['predictions']):\n",
    "    print(\"Predicted class: {}, True Class:\\t{}\".format(\n",
    "        pred['classes'][0], \n",
    "        y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%pdoc discovery.build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "```\n",
    "Signature: discovery.build(serviceName, version, http=None, discoveryServiceUrl='https://www.googleapis.com/discovery/v1/apis/{api}/{apiVersion}/rest', developerKey=None, model=None, requestBuilder=<class 'googleapiclient.http.HttpRequest'>, credentials=None, cache_discovery=True, cache=None)\n",
    "Docstring:\n",
    "Construct a Resource for interacting with an API.\n",
    "\n",
    "Construct a Resource object for interacting with an API. The serviceName and\n",
    "version are the names from the Discovery service.\n",
    "\n",
    "Args:\n",
    "serviceName: string, name of the service.\n",
    "version: string, the version of the service.\n",
    "http: httplib2.Http, An instance of httplib2.Http or something that acts\n",
    "like it that HTTP requests will be made through.\n",
    "discoveryServiceUrl: string, a URI Template that points to the location of\n",
    "the discovery service. It should have two parameters {api} and\n",
    "{apiVersion} that when filled in produce an absolute URI to the discovery\n",
    "document for that service.\n",
    "developerKey: string, key obtained from\n",
    "https://code.google.com/apis/console.\n",
    "model: googleapiclient.Model, converts to and from the wire format.\n",
    "requestBuilder: googleapiclient.http.HttpRequest, encapsulator for an HTTP\n",
    "request.\n",
    "credentials: oauth2client.Credentials or\n",
    "google.auth.credentials.Credentials, credentials to be used for\n",
    "authentication.\n",
    "cache_discovery: Boolean, whether or not to cache the discovery doc.\n",
    "cache: googleapiclient.discovery_cache.base.CacheBase, an optional\n",
    "cache object for the discovery documents.\n",
    "\n",
    "Returns:\n",
    "A Resource object with methods for interacting with the service.\n",
    "File: /usr/local/envs/py3env/lib/python3.5/site-packages/googleapiclient/discovery.py\n",
    "Type: function\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![gcp_training_options-gcp_services.png](Images/gcp_training_options-gcp_services.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Outlook\n",
    "- Add different models types\n",
    "    - different layers of abstraction in tensorflow\n",
    "    - sklearn\n",
    "- Show how to use `ml-engine` in SQL in BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notes on **Jupyter Slides**\n",
    "- Activate: View -> Cell Toolbar -> Slideshow\n",
    "- [nbextensions](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/install.html)\n",
    "   - [split cells vertically](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/splitcell/readme.html)\n",
    "   - Code folding\n",
    "   - Table of Contents\n",
    "- [RISE](https://damianavila.github.io/RISE/installation.html) for interactive presentations\n",
    "  - using conda: `conda install -c conda-forge rise`\n",
    "  - activte scrolling in Notebook-Metadata, see [link](https://damianavila.github.io/RISE/customize.html#config-right-scroll) \n",
    "  - adapt width and height of your slides to your machine and needs. [link](https://damianavila.github.io/RISE/customize.html#change-the-width-and-height-of-slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (mnist)",
   "language": "python",
   "name": "mnist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "livereveal": {
   "scroll": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "598.438px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
