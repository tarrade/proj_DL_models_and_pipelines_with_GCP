{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hmUcc8Yl0IXa"
   },
   "source": [
    "# MNIST classification using TensorFlow Dataset and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Define the following env variable before starting Jupyter Lab:  \n",
       "`export DIR_PROJ=your_path_git_repository`  \n",
       "`export PYTHONPATH=$DIR_PROJ`  \n",
       "  \n",
       "Start Jupyter Lab:  \n",
       "`jupyter lab`  \n",
       "  \n",
       "Choose the proper Anaconda python environment:  \n",
       "`Python [conda env:env_tensorflow]`  \n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "with open('setup.md', 'r') as fh:\n",
    "    content = fh.read()\n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zARGqIvw1lj_"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vldnVmWSrFAt",
    "outputId": "1a3abd15-2aa3-4c94-9573-aaa0eef918c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-RZ6FKF_yqGb"
   },
   "source": [
    "## List of TensorFlow Datasets available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "BwlzG2Sy0LtU",
    "outputId": "5a79f624-a91f-4314-8412-aa7391bddb76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abstract_reasoning', 'aeslc', 'aflw2k3d', 'amazon_us_reviews', 'arc', 'bair_robot_pushing_small', 'big_patent', 'bigearthnet', 'billsum', 'binarized_mnist', 'binary_alpha_digits', 'c4', 'caltech101', 'caltech_birds2010', 'caltech_birds2011', 'cars196', 'cassava', 'cats_vs_dogs', 'celeb_a', 'celeb_a_hq', 'chexpert', 'cifar10', 'cifar100', 'cifar10_1', 'cifar10_corrupted', 'citrus_leaves', 'cityscapes', 'civil_comments', 'clevr', 'cmaterdb', 'cnn_dailymail', 'coco', 'coil100', 'colorectal_histology', 'colorectal_histology_large', 'cos_e', 'curated_breast_imaging_ddsm', 'cycle_gan', 'deep_weeds', 'definite_pronoun_resolution', 'diabetic_retinopathy_detection', 'dmlab', 'downsampled_imagenet', 'dsprites', 'dtd', 'duke_ultrasound', 'dummy_dataset_shared_generator', 'dummy_mnist', 'emnist', 'esnli', 'eurosat', 'fashion_mnist', 'flic', 'flores', 'food101', 'gap', 'gigaword', 'glue', 'groove', 'higgs', 'horses_or_humans', 'i_naturalist2017', 'image_label_folder', 'imagenet2012', 'imagenet2012_corrupted', 'imagenet_resized', 'imagenette', 'imdb_reviews', 'iris', 'kitti', 'kmnist', 'lfw', 'lm1b', 'lost_and_found', 'lsun', 'malaria', 'math_dataset', 'mnist', 'mnist_corrupted', 'movie_rationales', 'moving_mnist', 'multi_news', 'multi_nli', 'multi_nli_mismatch', 'newsroom', 'nsynth', 'omniglot', 'open_images_v4', 'oxford_flowers102', 'oxford_iiit_pet', 'para_crawl', 'patch_camelyon', 'pet_finder', 'places365_small', 'plant_leaves', 'plant_village', 'plantae_k', 'quickdraw_bitmap', 'reddit_tifu', 'resisc45', 'rock_paper_scissors', 'rock_you', 'scan', 'scene_parse150', 'scicite', 'scientific_papers', 'shapes3d', 'smallnorb', 'snli', 'so2sat', 'squad', 'stanford_dogs', 'stanford_online_products', 'starcraft_video', 'sun397', 'super_glue', 'svhn_cropped', 'ted_hrlr_translate', 'ted_multi_translate', 'tf_flowers', 'the300w_lp', 'titanic', 'trivia_qa', 'uc_merced', 'ucf101', 'vgg_face2', 'visual_domain_decathlon', 'voc', 'wider_face', 'wikihow', 'wikipedia', 'wmt14_translate', 'wmt15_translate', 'wmt16_translate', 'wmt17_translate', 'wmt18_translate', 'wmt19_translate', 'wmt_t2t_translate', 'wmt_translate', 'xnli', 'xsum']\n"
     ]
    }
   ],
   "source": [
    "# See available datasets\n",
    "print(tfds.list_builders())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration when using Proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For proxy be sure the above variable are setup\n",
    "#os.environ['HTTPS_PROXY']\n",
    "#os.environ['REQUESTS_CA_BUNDLE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading a TensorFlow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n",
      "drwxr-xr-x    4 tarrade  staff   128 Feb  5 21:17 \u001b[34m.\u001b[m\u001b[m/\n",
      "drwxr-xr-x@ 153 tarrade  staff  4896 Feb  7 09:27 \u001b[34m..\u001b[m\u001b[m/\n",
      "drwxr-xr-x    3 tarrade  staff    96 Feb  5 21:17 \u001b[34mdownloads\u001b[m\u001b[m/\n",
      "drwxr-xr-x    3 tarrade  staff    96 Feb  5 21:18 \u001b[34mmnist\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "ls -la ~/tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove old version, if needed\n",
    "#rm -r /Users/tarrade/tensorflow_datasets/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a given dataset by name, along with the DatasetInfo\n",
    "data, info = tfds.load(\"mnist\", with_info=True, data_dir='~/tensorflow_datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checks and data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='mnist',\n",
       "    version=3.0.0,\n",
       "    description='The MNIST database of handwritten digits.',\n",
       "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
       "    features=FeaturesDict({\n",
       "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
       "    }),\n",
       "    total_num_examples=70000,\n",
       "    splits={\n",
       "        'test': 10000,\n",
       "        'train': 60000,\n",
       "    },\n",
       "    supervised_keys=('image', 'label'),\n",
       "    citation=\"\"\"@article{lecun2010mnist,\n",
       "      title={MNIST handwritten digit database},\n",
       "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
       "      journal={ATT Labs [Online]. Available: http://yann. lecun. com/exdb/mnist},\n",
       "      volume={2},\n",
       "      year={2010}\n",
       "    }\"\"\",\n",
       "    redistribution_info=,\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': <DatasetV1Adapter shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>,\n",
       " 'train': <DatasetV1Adapter shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data['train'], data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making some sanity checks\n",
    "assert isinstance(train_data, tf.data.Dataset)\n",
    "assert info.features['label'].num_classes == 10\n",
    "assert info.splits['train'].num_examples == 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeaturesDict({\n",
      "    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "})\n",
      "10\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "print(info.features)\n",
    "print(info.features[\"label\"].num_classes)\n",
    "print(info.features[\"label\"].names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = tfds.show_examples(info, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iVjkKGvC1WI_"
   },
   "outputs": [],
   "source": [
    "# training dataset\n",
    "train_dataset = train_data.repeat().shuffle(1024).batch(128).prefetch(2)\n",
    "train_features = tf.compat.v1.data.make_one_shot_iterator(train_dataset).get_next()\n",
    "train_image, train_label = train_features['image'], train_features['label']\n",
    "# testing dataset\n",
    "test_dataset = test_data.repeat().shuffle(1024).batch(128).prefetch(2)\n",
    "test_features = tf.compat.v1.data.make_one_shot_iterator(test_dataset).get_next()\n",
    "test_image, test_label = test_features['image'], test_features['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image', 'label'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image=tf.cast(test_image, tf.float64)\n",
    "train_image=tf.cast(train_image, tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, 28, 28, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, 28, 28, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "9TRmd1df2Vrl",
    "outputId": "b4294f57-3495-4753-9fb5-14d66f52e7a9"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.4),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128 samples\n",
      "Epoch 1/10\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 132.2230 - accuracy: 0.1484\n",
      "Epoch 2/10\n",
      "128/128 [==============================] - 0s 99us/sample - loss: 46.3221 - accuracy: 0.6016\n",
      "Epoch 3/10\n",
      "128/128 [==============================] - 0s 98us/sample - loss: 30.2534 - accuracy: 0.6797\n",
      "Epoch 4/10\n",
      "128/128 [==============================] - 0s 78us/sample - loss: 12.6261 - accuracy: 0.8750\n",
      "Epoch 5/10\n",
      "128/128 [==============================] - 0s 100us/sample - loss: 9.5999 - accuracy: 0.8281\n",
      "Epoch 6/10\n",
      "128/128 [==============================] - 0s 98us/sample - loss: 6.2613 - accuracy: 0.9062\n",
      "Epoch 7/10\n",
      "128/128 [==============================] - 0s 113us/sample - loss: 2.1774 - accuracy: 0.9531\n",
      "Epoch 8/10\n",
      "128/128 [==============================] - 0s 100us/sample - loss: 1.0242 - accuracy: 0.9844\n",
      "Epoch 9/10\n",
      "128/128 [==============================] - 0s 107us/sample - loss: 1.2843 - accuracy: 0.9609\n",
      "Epoch 10/10\n",
      "128/128 [==============================] - 0s 105us/sample - loss: 1.9288 - accuracy: 0.9531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x147e85450>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_image, train_label, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "HE-BahRX208r",
    "outputId": "c3a1e075-2e4d-4393-f6a4-c5075b63596d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 698us/sample - loss: 22.1131 - accuracy: 0.7656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[22.113136291503906, 0.765625]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_image, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other way to loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a given dataset by name, along with the DatasetInfo\n",
    "mnist, info_mnist = tfds.load(\"mnist\", with_info=True, data_dir='~/tensorflow_datasets', as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'test': <DatasetV1Adapter shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>,\n",
       "  'train': <DatasetV1Adapter shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>},\n",
       " dict)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new\n",
    "mnist, type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'test': <DatasetV1Adapter shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>,\n",
       "  'train': <DatasetV1Adapter shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>},\n",
       " dict)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old\n",
    "data, type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = mnist['train'], mnist['test']\n",
    "mnist_train = mnist_train.repeat().shuffle(1024).batch(128).prefetch(2)\n",
    "mnist_test = mnist_test.repeat().shuffle(1024).batch(128).prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(img, label):\n",
    "    img = tf.cast(img, tf.float64) / 255.\n",
    "    return (img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train=mnist_train.map(normalize_img)\n",
    "mnist_test=mnist_test.map(normalize_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((None, 28, 28, 1), (None,)), types: (tf.float64, tf.int64)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((None, 28, 28, 1), (None,)), types: (tf.float64, tf.int64)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 468 steps\n",
      "Epoch 1/10\n",
      "468/468 [==============================] - 6s 13ms/step - loss: 0.8601 - accuracy: 0.7946\n",
      "Epoch 2/10\n",
      "468/468 [==============================] - 5s 10ms/step - loss: 0.4757 - accuracy: 0.8639\n",
      "Epoch 3/10\n",
      "468/468 [==============================] - 5s 10ms/step - loss: 0.3695 - accuracy: 0.8924\n",
      "Epoch 4/10\n",
      "468/468 [==============================] - 5s 10ms/step - loss: 0.3146 - accuracy: 0.9086\n",
      "Epoch 5/10\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.2731 - accuracy: 0.9200\n",
      "Epoch 6/10\n",
      "468/468 [==============================] - 5s 10ms/step - loss: 0.2415 - accuracy: 0.9294\n",
      "Epoch 7/10\n",
      "468/468 [==============================] - 5s 10ms/step - loss: 0.2161 - accuracy: 0.9375\n",
      "Epoch 8/10\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1946 - accuracy: 0.9431\n",
      "Epoch 9/10\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.1767 - accuracy: 0.9473\n",
      "Epoch 10/10\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1581 - accuracy: 0.9538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14723f810>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size = 128\n",
    "# nb epochs = 5\n",
    "# nb event = 60000\n",
    "model.fit(mnist_train, epochs=10, steps_per_epoch=468)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0561 - accuracy: 0.9844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05607721209526062, 0.984375]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(mnist_test, steps=1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TFDS example",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:env_tensorflow]",
   "language": "python",
   "name": "conda-env-env_tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
